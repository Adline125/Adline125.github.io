<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Adline125&#39;s Blog</title>
  
  <subtitle>NLP Engineer, Google Developers Expert</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2025-11-26T05:28:35.672Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Adline125</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习的数学基础-线性变换(五)</title>
    <link href="http://yoursite.com/2025/11/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%BA%94)/"/>
    <id>http://yoursite.com/2025/11/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%BA%94)/</id>
    <published>2025-11-21T04:09:01.000Z</published>
    <updated>2025-11-26T05:28:35.672Z</updated>
    
    <content type="html"><![CDATA[<p>把数学看作是一种解决问题的工具。解决问题的关键往往在于找到我们研究对象的恰当表示。将矩阵视为一种数据变换的方式，为我们提供了所需的几何视角，开辟了一条全新的方法之路。</p><p>通过前几次的对机器学习涉及到的线性知识的回顾，本次我们做一次全面的总结。并由此提出一系列相关问题留给读者思考。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>总结</strong></li><li><strong>问题</strong></li></ul><h2 id="总结">1 总结</h2><p>那么，第一次用眼睛的时候，你的眼睛会不会很痛？当我第一次学习矩阵作为线性变换时，我的眼睛确实很痛。这部分内容第一次体现了这种抽象的视角，但是相信我，以后它会带来更大的回报。</p><p>让我们快速回顾一下本章。</p><p>我们已经知道，除了形式是数字表之外，矩阵还可以表示线性变换：</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p154formula1.png" style="zoom:50%;" /></p><p>其中𝐴的列描述了基向量在线性变换𝐱 → 𝐴𝐱下的像。</p><p>这究竟对我们有什么用呢？把数学看作是一种解决问题的工具。解决问题的关键往往在于找到我们研究对象的恰当表示。将矩阵视为一种数据变换的方式，为我们提供了所需的几何视角，开辟了一条全新的方法之路。</p><p>以这种方式看待矩阵，我们很快就能理解为什么矩阵乘法是这样定义的。</p><p>定义</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p154formula2.png" style="zoom:50%;" /></p><p>乍一看令人望而生畏，但从线性变换的角度来看，这一切都是一个简单的组合：首先，我们应用变换𝐵，然后𝐴。</p><p>不过要注意：线性变换和矩阵并不完全相同，因为矩阵表示取决于向量空间的底层基。（瞧，我告诉过你，基会很有用。）</p><p>矩阵还有一个重要的量，叫做行列式，最初由一个极其复杂的公式定义</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p154formula3.png" style="zoom:50%;" /></p><p>但利用我们新发现的几何视角进行的一项研究表明，行列式仅仅描述了线性变换对域空间体积的扭曲程度，以及它如何改变基向量的方向。</p><p>对于我们机器学习从业者来说，从矩阵到线性变换的概念跳跃，才是更有趣的。（与理论相反，我们通常先学习线性变换，然后再学习矩阵。）例如，这使我们能够将神经网络中的某一层视为拉伸、旋转、剪切，并可能反映特征空间。</p><p>在下一章中，我们将从一个略有不同的视角——方程组——重新审视矩阵。当然，万物皆有联系，最终我们会回到起点，从更高的视角审视我们所知道的知识。这是因为学习是一个螺旋式的过程，而我们正在快速上升。</p><h2 id="问题">2 问题</h2><p>问题 1. 证明，若 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>为可逆矩阵，则</p><p>​ <span class="math inline">\((𝐴 ^{−1})^ 𝑇 = (𝐴 ^𝑇 ) ^{−1} .\)</span></p><p>问题 2. 令 <span class="math inline">\(𝑅_𝛼\)</span> 为二维旋转矩阵，其定义如下</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p155formula2.png" style="zoom:50%;" /></p><p>证明$ 𝑅_𝛼𝑅_𝛽 = 𝑅_{𝛼+𝛽}$。</p><p>问题 3. 设 <span class="math inline">\(𝐴 = (𝑎_{𝑖,𝑗})^𝑛_{𝑖,𝑗=1} ∈ ℝ^{𝑛×𝑛}\)</span> 为矩阵，设 <span class="math inline">\(𝐷 ∈ ℝ^{𝑛×𝑛}\)</span> 为对角矩阵，定义如下</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p155formula3.png" style="zoom:50%;" /></p><p>其中对角线外的所有元素均为零。证明</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p155formula4.png" style="zoom:50%;" /></p><p>以及</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p155formula5.png" style="zoom:50%;" /></p><p>问题 4. 令 ‖ ⋅ ‖ 为 <span class="math inline">\(ℝ^𝑛\)</span>上的范数，令 $𝐴 ∈ ℝ^{𝑛×𝑛} $为任意矩阵。证明 𝐴 可逆当且仅当函数</p><p>​ <span class="math inline">\(‖𝐱‖_∗ ∶= ‖𝐴𝐱‖\)</span></p><p>是<span class="math inline">\(ℝ^n\)</span>上的范数。</p><p>问题 5. 设 𝑈 为赋范空间，𝑓 ∶ 𝑈 → 𝑈 为线性变换。若</p><pre><code>                                                                                        $‖𝐱‖_∗ ∶= ‖𝑓 (𝐱)‖$</code></pre><p>是范数，𝑓 必然可逆吗？</p><p>提示：考虑向量空间 ℝ[𝑥]，其范数为</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p156formula3.png" style="zoom:50%;" /></p><p>以及线性变换 𝑓 ∶ 𝑝(𝑥) ↦ 𝑥𝑝(𝑥)。</p><p>问题 6. 令 ⟨⋅, ⋅⟩ 为$ ℝ^𝑛$上的内积。证明存在一个矩阵 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>使得</p><p>​ <span class="math inline">\(⟨𝐱, 𝐲⟩ = 𝐱^𝑇𝐴𝐲, 𝐱, 𝐲 ∈ ℝ^n\)</span></p><p>（回想一下，我们将向量 <span class="math inline">\(𝐱、𝐲 ∈ ℝ^𝑛\)</span>视为列向量。）</p><p>问题 7. 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span> 为一个矩阵。如果对于每个非零的 <span class="math inline">\(𝐱 ∈ ℝ^𝑛\)</span> ，<span class="math inline">\(𝐱^𝑇𝐴𝐱 &gt; 0\)</span>，则称 𝐴 为正定矩阵。</p><p>证明 𝐴 为正定矩阵当且仅当</p><p>​ <span class="math inline">\(⟨𝐱, 𝐲⟩ = 𝐱^𝑇𝐴𝐲\)</span></p><p>是内积。</p><p>问题 8. 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑚}\)</span> 为一个矩阵，其列记为 <span class="math inline">\(𝐚_1, … , 𝐚_𝑛 ∈ ℝ^𝑛\)</span>。</p><ol type="a"><li><p>证明，对于所有 <span class="math inline">\(𝐱 ∈ ℝ^𝑚\)</span>，<span class="math inline">\(𝐴𝐱 ∈ span(𝐚_1, … , 𝐚_𝑛)\)</span>。</p></li><li><p>设 <span class="math inline">\(𝐵 ∈ ℝ^{𝑚×𝑘}\)</span>，𝐴𝐵 的列记为 <span class="math inline">\(𝐯_1, … , 𝐯_𝑘 ∈ ℝ^𝑛\)</span>。证明</p></li></ol><p>​ <span class="math inline">\(𝐯_1, … , 𝐯_𝑘 ∈ span(𝐚_1, … , 𝐚_𝑛)\)</span>。</p><p>问题 9. 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span> 为一个矩阵。证明</p><p>​ <span class="math inline">\(⟨𝐴𝐱, 𝐲⟩ = ⟨𝐱, 𝐴^𝑇𝐲⟩\)</span></p><p>对所有 <span class="math inline">\(𝐱, 𝐲 ∈ ℝ^𝑛\)</span>成立，其中 ⟨⋅, ⋅⟩ 是欧氏内积。</p><p>问题 10. 计算行列式</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p157formmula3.png" style="zoom:50%;" /></p><p>问题 11. 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span> 为矩阵，𝑐 ∈ ℝ 为常数。</p><ol type="a"><li>证明</li></ol><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p157formula4.png" style="zoom:50%;" /></p><p>对所有𝑖 = 1, … , 𝑛 成立。</p><p>（b）证明</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p157formula5.png" style="zoom:50%;" /></p><p>对所有𝑖 = 1, … , 𝑛 成立，且</p><ol start="3" type="a"><li>证明</li></ol><p>​ <span class="math inline">\(det(𝑐𝐴) = 𝑐^𝑛det𝐴\)</span>。</p><p>问题 12. 设 $𝐴 ∈ ℝ^{𝑛×𝑛} $为上三角矩阵。（即对角线以下所有元素均为零。）</p><p>证明</p><p>​ <span class="math inline">\(det𝐴 =∏^n_{𝑖=1}𝑎_{𝑖,𝑖}\)</span></p><p>证明下三角矩阵（即对角线上方元素为零的矩阵）也同样成立。</p><p>问题 13. 设 <span class="math inline">\(𝑀 ∈ ℝ^{𝑛×𝑚}\)</span> 为具有分块结构的矩阵</p><p><img src="pics2/p158formula2.png" style="zoom:50%;" /></p><p>其中 <span class="math inline">\(𝐴 ∈ ℝ^{𝑘×𝑘}，𝐵 ∈ ℝ^{𝑘×𝑙}，𝐶 ∈ ℝ^{𝑙×𝑙}\)</span>。</p><p>证明</p><p>​ <span class="math inline">\(det 𝑀 = det𝐴det 𝐶\)</span>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;把数学看作是一种解决问题的工具。解决问题的关键往往在于找到我们研究对象的恰当表示。将矩阵视为一种数据变换的方式，为我们提供了所需的几何视角，开辟了一条全新的方法之路。&lt;/p&gt;
&lt;p&gt;通过前几次的对机器学习涉及到的线性知识的回顾，本次我们做一次全面的总结。并由此提出一系列相关问题留给读者思考。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习的数学基础-线性变换(四)</title>
    <link href="http://yoursite.com/2025/11/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E5%9B%9B)/"/>
    <id>http://yoursite.com/2025/11/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E5%9B%9B)/</id>
    <published>2025-11-01T02:04:11.000Z</published>
    <updated>2025-11-26T05:22:26.922Z</updated>
    
    <content type="html"><![CDATA[<p>在前面的章节中，我们已经看到，线性变换可以被认为是对由基向量确定的网格进行扭曲。</p><p>根据我们的几何直觉，我们推测测量变换对体积和距离的扭曲程度可以提供一些有价值的见解。正如我们将在本章中看到的，情况确实如此。保持距离或范数不变的变换很特殊，由此衍生出诸如主成分分析之类的方法。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>线性变换如何缩放区域</strong></li><li><strong>行列式的多重线性</strong></li><li><strong>行列式的基本性质</strong></li></ul><h2 id="行列式线性变换如何影响体积">1 行列式，线性变换如何影响体积</h2><p>在前面的章节中，我们已经看到，线性变换可以被认为是对由基向量确定的网格进行扭曲。</p><p>根据我们的几何直觉，我们推测测量变换对体积和距离的扭曲程度可以提供一些有价值的见解。正如我们将在本章中看到的，情况确实如此。保持距离或范数不变的变换很特殊，由此衍生出诸如主成分分析之类的方法。</p><h3 id="线性变换如何缩放区域">1.1 线性变换如何缩放区域</h3><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p140figure4.14.png" style="zoom:50%;" /></p><p>​ 图 4.14: 单位正方形在线性变换下的图像</p><p>这个平行四边形的面积描述了𝐴如何缩放单位正方形。我们暂时称之为𝜆；也就是说，</p><p>​ area(𝐴(𝐶)) = 𝜆 ⋅ area(𝐶),</p><p>其中 𝐶 = [0, 1] × [0, 1] 是单位正方形，𝐴(𝐶) 是其像</p><p>​ 𝐴(𝐶) ∶= {𝐴𝐱 ∶ 𝐱 ∈ 𝐶}</p><p>由于线性关系，𝜆 也等于任何矩形（其边与坐标轴平行）的面积与其在𝐴下像的缩放比。如图 4.15 所示，我们可以将任何平面物体近似为矩形的并集。</p><p>如果所有矩形都按𝜆 缩放，那么矩形的并集也会按该因子缩放。因此，𝜆 也是任何平面物体𝐸与其像𝐴(𝐸) = {𝐴𝐱 ∶ 𝐱 ∈ 𝐸} 的缩放比。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p141figure4.15.png" style="zoom:50%;" /></p><p>​ 图 4.15：用矩形并集近似平面物体</p><p>这个量 𝜆 揭示了很多关于变换本身的信息，但还有一个问题：我们如何计算它？</p><p>假设我们的线性变换如下</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p141formula1.png" style="zoom:50%;" /></p><p>因此，它的列<span class="math inline">\(𝐱 = (𝑥_1, 𝑥_2)\)</span> 和<span class="math inline">\(𝐲 = (𝑦_1, 𝑦_2)\)</span> 描述了平行四边形的两条边。这就是单位正方形的像。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p141figure4.16.png" style="zoom:50%;" /></p><p>​ 图 4.16: 单位正方形在线性变换下的图像</p><p>我们的面积缩放因子 𝜆 等于这个平行四边形的面积，所以我们的目标是计算出这个值。</p><p>任何平行四边形的面积都可以通过将底边长（在本例中为 ‖𝐱‖）乘以高<span class="math inline">\(h\)</span>来计算。（你可以很容易地通过在平行四边形的右侧切掉一个三角形并将其放在左侧，重新排列成一个矩形来看到这一点。）<span class="math inline">\(h\)</span>是未知的，但根据基本的三角学知识，我们可以看出<span class="math inline">\(ℎ = sin 𝛼‖𝐲‖\)</span>，其中 𝛼 是 𝐱 和 𝐲 之间的夹角。</p><p>因此， <span class="math inline">\(area=sin 𝛼‖𝐲‖‖𝐱‖\)</span></p><p>这几乎就是𝐱和𝐲的点积。（回想一下，点积可以写成<span class="math inline">\(⟨𝐱, 𝐲⟩ = ‖𝐱‖‖𝐲‖ cos 𝛼\)</span>。）然而，sin 𝛼部分并不匹配。</p><p>幸运的是，我们可以使用一个巧妙的技巧将其转换为点积！由于<span class="math inline">\(sin 𝛼 = cos (𝛼 −\frac𝜋2)\)</span>，我们得到</p><p>​ <span class="math inline">\(area = cos ( 𝛼 − \frac𝜋2 ) ‖𝐱‖‖𝐲‖\)</span>.</p><p>问题在于𝐱和𝐲之间的夹角不是<span class="math inline">\(𝛼-\frac𝜋2\)</span>。不过，我们可以通过应用旋转轻松解决这个问题（第 4.3.2 节）。应用变换</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p142formula3.png" style="zoom:50%;" /></p><p>我们得到 <span class="math inline">\(𝐲_{rot }= 𝑅𝐲 = (𝑦_2, −𝑦_1)\)</span></p><p>由于<span class="math inline">\(‖𝐲_{rot}‖ = ‖𝐲‖\)</span>，我们有</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p142formula4.png" style="zoom:50%;" /></p><p>仅使用矩阵 𝐴 的元素即可计算 <span class="math inline">\(⟨𝐱, 𝐲_{rot}⟩\)</span>：</p><p>​ <span class="math inline">\(⟨𝐱, 𝐲_{rot}⟩ = 𝑥_1𝑦_2 − 𝑥_2𝑦_1\)</span>.</p><p>注意，<span class="math inline">\(⟨𝐱, 𝐲_{rot}⟩\)</span> 可以为负数！当 <span class="math inline">\(𝐲 = 𝐴𝐞_2\)</span> 和 <span class="math inline">\(𝐱 = 𝐴𝐞_1\)</span> 之间的夹角（逆时针测量）大于 𝜋 时，就会发生这种情况，因为这意味着 <span class="math inline">\(cos(𝛼−\frac𝜋2 )&lt; 0\)</span>。</p><p>因此，<span class="math inline">\(⟨𝐱, 𝐲_{rot}⟩\)</span>这个量被称为平行四边形的有符号面积。</p><p>在二维中，我们称之为线性变换的行列式。也就是说，对于任何给定的线性变换/矩阵<span class="math inline">\(𝐴∈ℝ^{2×2}\)</span>，其行列式定义为</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p143formula1(4.9).png" style="zoom:50%;" /></p><p>行列式通常写为 |𝐴|，但我们将避免使用这种符号。我们要讨论任意矩阵 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span> 的行列式，但为了建立直观理解，我们先暂时以 2 × 2 的情况为例。</p><p>行列式还揭示了向量的方向：正行列式表示正方向，负行列式表示负方向。（直观地说，正方向表示从 𝐱 到 𝐲 逆时针测量的角度在 0 到 𝜋 之间；等效地，从 𝐱 到 𝐲 顺时针测量的角度在 𝜋 到 2𝜋 之间。）如下图 4.17 所示。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p143figure4.17.png" style="zoom:50%;" /></p><p>​ 图 4.17：平面中两个向量的方向</p><p>图片内容翻译：positively oriented: 正方向 negatively oriented:正方向</p><p>综上</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p143formula2(4.10).png" style="zoom:50%;" /></p><p>成立，其中<span class="math inline">\(𝐸⊆ℝ^2\)</span>是平面对象，并且</p><p>​ 𝐴(𝐸) = {𝐴𝐱 ∶ 𝐱 ∈ 𝐸}</p><p>是 𝐸 在变换 𝐴 下的像。</p><p>尽管我们只在二维中证明了 (4.10)，但这在高维情况下也是成立的。（尽管我们还不知道如何定义那里的行列式。）</p><p>因此，如果<span class="math inline">\(𝐞_1\)</span>和 <span class="math inline">\(𝐞_2\)</span> 是平面上的基，那么方程 (4.9) 和 (4.10) 告诉我们，二维中的行列式等于</p><p>​ <span class="math inline">\(det𝐴 = orientation(𝐴𝐞_1, 𝐴𝐞_2) × area(𝐴𝐞_1, 𝐴𝐞_2)\)</span></p><p>基于欧氏平面的例子，我们已经建立了足够的几何直觉，理解了线性变换如何扭曲体积并改变空间的方向。这些由行列式的概念描述，我们在特殊情况 (4.9) 中已经定义了它。我们将继续研究这个概念的普适性。</p><p>为了介绍行列式的正式定义，我们将采取一种不同于通常的思路。通常，线性变换𝐴的行列式会直接用一个复杂的公式定义，然后展示它的所有几何性质。</p><p>与此不同，我们将通过推广上一节中学到的几何概念来推导行列式公式。在这里，我们将大致遵循 Peter D. Lax 所著的《线性代数及其应用》的大纲。</p><p>我们通过介绍一些关键符号来奠定基础。设</p><p>​ <span class="math inline">\(𝐴 = (𝑎_{𝑖,𝑗})^𝑛_{𝑖,𝑗=1} ∈ ℝ^{𝑛×𝑛}\)</span></p><p>是一个列为<span class="math inline">\(𝐚_1，…，𝐚_𝑛\)</span>的矩阵。在4.1.1节中引入矩阵作为线性变换的概念时，我们看到第𝑖列是第𝑖个基向量的像。为简单起见，我们假设<span class="math inline">\(𝐞_1，𝐞_2，…，𝐞_𝑛\)</span>是标准正交基，也就是说，<span class="math inline">\(𝐞_𝑖\)</span>是第𝑖个坐标为1，其余坐标为0的向量。因此，<span class="math inline">\(𝐴𝐞_𝑖 = 𝐚_𝑖\)</span>。</p><p>在4.3节对欧氏平面的探索中，我们已经看到，行列式是基向量像的方向乘以它们所定义的平行四边形的面积。按照这个逻辑，我们可以定义𝑛 × 𝑛 矩阵的行列式为</p><p>​ <span class="math inline">\(det𝐴 = orientation(𝐴𝐞_1, … , 𝐴𝐞_𝑛) × volume(𝐴𝐞_1, … , 𝐴𝐞_𝑛)\)</span></p><p>两个问题立刻浮现出来。首先，我们如何定义𝑛维空间中多个向量的方向？其次，我们如何计算面积？</p><p>我们不会直接寻找这些问题的答案，而是要给故事增添一个转折：首先，我们会找到一个方便的行列式公式，然后用它来定义方向。</p><h3 id="行列式的多重线性">1.2 行列式的多重线性</h3><p>为了更明确地表达行列式与矩阵<span class="math inline">\(𝐚_𝑖 = 𝐴𝐞_𝑖\)</span>的列之间的关系，我们写成：</p><p>​ <span class="math inline">\(det𝐴 = det(𝐚_1, … , 𝐚_𝑛)\)</span>.</p><p>以这种方式思考行列式，det 只是多个变量的函数：</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p145formula2.png" style="zoom:50%;" /></p><p>好消息：$det(𝐚_1, … , 𝐚_𝑛) $在每个变量上都是线性的。也就是说，</p><p>​ <span class="math inline">\(det(𝐚_1, … , 𝛼𝐚_𝑖 + 𝛽𝐛_𝑖 , … 𝐚_𝑛) = 𝛼 det(𝐚_1, … , 𝐚_𝑖 , … 𝐚_𝑛) + 𝛽 det(𝐚_1, … , 𝐛_𝑖 , … 𝐚_𝑛)\)</span></p><p>成立。我们不打算证明这一点，但由于行列式表示有符号的体积，你可以通过查看图 4.18 来验证。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p145figure4.18.png" style="zoom:50%;" /></p><p>​ 图 4.18: <span class="math inline">\(det(𝐚_𝟏, 𝐚_𝟐)\)</span> 的多重线性</p><p>线性的一个结果是，我们可以将行列式表示为标准基向量<span class="math inline">\(𝐞_1, …,𝐞_𝑛\)</span>的行列式的线性组合。例如，考虑以下内容。由于</p><p>​ <span class="math inline">\(𝐴𝐞_1 = 𝐚_1 =∑^𝑛_{𝑖=1}𝑎_{𝑖,1}𝐞_𝑖 ,\)</span></p><p>我们有</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p146formula1.png" style="zoom:50%;" /></p><p>更进一步，利用这一点</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p146formula2.png" style="zoom:50%;" /></p><p>我们开始注意到一种模式。有了线性，我们</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p146formula3(4.11).png" style="zoom:50%;" /></p><p>我们可以看到，系数<span class="math inline">\(𝑎_{𝑖,1}𝑎_{𝑗,2}\)</span> 中的行索引与 <span class="math inline">\(det(𝐞_𝑖, 𝐞_𝑗, 𝐚_3, … , 𝐚_𝑛)\)</span> 中<span class="math inline">\(𝐞_𝑘\)</span>-s 的索引相匹配。一般情况下，这种模式可以用排列形式化表示；即集合 {1, 2, … , 𝑛} 的排序。</p><p>你可以将排列想象成一个函数𝜎，它将 {1, 2, … , 𝑛} 映射到自身，使得对于每个𝑗 ∈{1, 2, … , 𝑛}，都存在一个𝑖 ∈ {1, 2, … , 𝑛}，且𝜎(𝑖) = 𝑗。换句话说，你取 1 到 𝑛 之间的每个整数，并将它们按顺序排列。{1, 2, … , 𝑛} 上所有可能的排列的集合记为<span class="math inline">\(𝑆_𝑛\)</span>。</p><p>继续 (4.11) 并进一步展开𝐴的行列式，我们得到</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p146formula4.png" style="zoom:50%;" /></p><p>这个公式不太容易理解。你可以把每个项 <span class="math inline">\(∏^𝑛_{𝑖=1} 𝐚_{𝜎(𝑖),𝑖}\)</span> 想象成将 𝑛 个国际象棋车放在 𝑛 × 𝑛 的棋盘上，使得它们之间无法互相捕获。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p146figure4.19.png" style="zoom:50%;" /></p><p>​ 图 4.19: 项 <span class="math inline">\(𝐚_{𝜎(1)1} ⋯ 𝐚_{𝜎(𝑛)n}\)</span> 的解析结构</p><p>公式</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p147formula1.png" style="zoom:50%;" /></p><p>结合了所有可能的方法。</p><p>只剩下一件事：计算 <span class="math inline">\(det(𝐞_{𝜎(1)}, … , 𝐞_{𝜎(𝑛)})\)</span>。</p><p>还记得我们讨论过欧氏平面中反射和旋转的组合吗（第 4.3.4 节）？由$ 𝐞_𝑖 ↦ 𝐞_{𝜎(𝑖)}$ 确定的变换与此类似。谈到排列时，最好知道，每个排列都可以通过一次交换两个元素来获得。一个排列中，转置次数（即影响两个元素的排列）称为 sign(𝜎)。在我们的线性变换<span class="math inline">\(𝐞_𝑖 ↦𝐞_{𝜎(𝑖)}\)</span>中，𝜎中的转置次数就是所需的反射次数，而sign(𝜎)是<span class="math inline">\((𝐞_{𝜎(1)}, … ,𝐞_{𝜎(𝑛)})\)</span>的方向。</p><p>至此，有了这些，我们最终可以给出行列式和方向的正式定义。</p><blockquote><p>定义 4.4.1（行列式和方向）</p><p>设 𝐴 ∈ ℝ^{𝑛×𝑛} 为任意矩阵，<span class="math inline">\(𝐚_𝑖 ∈ ℝ^𝑛\)</span> 为其第 𝑖 列。𝐴 的行列式定义为</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p147formula2(4.12).png" style="zoom:50%;" /></p><p>向量<span class="math inline">\(𝐚_1, … , 𝐚_𝑛\)</span>的方向为 <span class="math inline">\(orientation(𝐚_1, … , 𝐚_𝑛) ∶= sign(det𝐴)\)</span></p></blockquote><p>当行列式表示法不方便时，我们会将矩阵元素放在一个很大的绝对值符号内来表示行列式：</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p147formula4.png" style="zoom:50%;" /></p><p>当我还是一名年轻的数学学生时，行列式公式 (4.12) 就在我的第一堂线性代数课上被原封不动地呈现了出来。由于没有解释它与体积和方向的联系，我花了好几年才真正理解它。我仍然认为行列式是线性代数中最复杂的概念之一，尤其是在没有几何学依据的情况下。</p><p>现在你已经对行列式有了基本的了解，你可能会问：我们该如何在实际中计算它？对所有排列的集合求和并计算它们的符号，从计算的角度来看并非易事。</p><p>好消息是：行列式有一个递归公式。坏消息是：对于一个 𝑛 × 𝑛 矩阵，它涉及 𝑛 个 (𝑛 − 1) × (𝑛 − 1) 矩阵。尽管如此，这与排列公式相比还已经好了很多。让我们来看一下！</p><blockquote><p>定理 4.4.1（行列式的递归公式）</p><p>设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>为任意方阵。则</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p148formula1(4.13).png" style="zoom:50%;" /></p><p>其中 <span class="math inline">\(𝐴_{𝑖,𝑗}\)</span> 是通过从 𝐴 中移除第 𝑖 行和第 𝑗 列得到的 (𝑛 − 1) × (𝑛 − 1) 矩阵。</p></blockquote><p>我们不会给出证明，而是提供一个例子来演示这个公式。对于 3 × 3 矩阵，它的形式如下：</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p148formula2.png" style="zoom:50%;" /></p><p>现在我们既掌握了几何直觉，又掌握了递归公式，让我们来看看行列式最重要的性质！</p><h3 id="行列式的基本性质">1.3 行列式的基本性质</h3><p>在处理行列式时，我们倾向于创建基本的构建块和组合规则。（正如我们在推导(4.12)时多次看到的，这种模式也适用。）这些规则体现在行列式的基本性质中，我们现在将对此进行讨论。</p><p>第一个性质与组合和行列式的关系有关。</p><blockquote><p>定理 4.4.2（行列式的乘积）</p><p><span class="math inline">\(A,B∈ℝ^{𝑛×𝑛}\)</span>是两个矩阵。则</p><p>​ <span class="math inline">\(det𝐴𝐵 = det𝐴det 𝐵\)</span> (4.14)</p></blockquote><p>方程 (4.14) 被称为行列式乘积法则，其证明需要基于公式 (4.12) 和 (4.13) 进行大量计算。我不会提供完整的证明，而是给出一个直观的解释。毕竟，我们想要用数学来构建算法，而不是构建数学。</p><p>因此，det𝐴𝐵 = det𝐴det 𝐵 的解释非常简单。如果我们将矩阵 <span class="math inline">\(𝐴, 𝐵 ∈ ℝ^{𝑛×𝑛}\)</span>视为线性变换，我们刚刚看到 det𝐴 和 det 𝐵 决定了它们如何缩放单位立方体。</p><p>由于这些线性变换的复合是矩阵乘积𝐴𝐵，线性变换𝐴𝐵将单位立方体缩放为一个平行六面体，其有符号的体积为det𝐴det𝐵。（因为应用𝐴𝐵等同于先应用𝐵，然后再对结果应用𝐴。）</p><p>因此，根据我们对行列式的理解，由于𝐴𝐵的缩放因子也是 det𝐴𝐵，所以（4.14）成立。</p><p>我们可以对此进行实际证明，例如，基于递归公式（4.13）进行归纳法，这将导致一个漫长而复杂的计算。</p><p>乘积法则的一个直接推论是矩阵的行列式与其逆矩阵之间存在一种特殊的关系。</p><blockquote><p>定理 4.4.3 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>为任意可逆矩阵。则</p><p><span class="math inline">\(det𝐴^{−1} = (det𝐴)^{−1}\)</span></p></blockquote><blockquote><p>证明。利用乘积法则，我们有 <span class="math inline">\(1 = det 𝐼 = det𝐴𝐴^{−1} = (det𝐴)(det𝐴^{−1})\)</span>， 由此可知定理成立。</p></blockquote><p>正因为如此，我们还可以得出结论，行列式由相似关系得到。</p><blockquote><p>定理 4.4.4 设 <span class="math inline">\(𝐴, 𝐵 ∈ ℝ^{𝑛×𝑛}\)</span>为两个相似矩阵，且 <span class="math inline">\(𝐵 = 𝑇^{−1}𝐴𝑇\)</span>，其中 <span class="math inline">\(𝑇 ∈ ℝ^{𝑛×𝑛}\)</span>。则 <span class="math inline">\(det𝐴 = det 𝐵\)</span>。</p></blockquote><blockquote><p>证明。这简单地从</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p150formula1.png" style="zoom:50%;" /></p><p>中得到，这个证明我必须要展示在这里的。</p></blockquote><p>另一个重要结果是，行列式与矩阵所在的基无关。如果<span class="math inline">\(𝐴 ∶ 𝑈 → 𝑈\)</span> 是线性变换，<span class="math inline">\(𝑃 = \{𝐩_1, … , 𝐩_𝑛\}\)</span> 和 <span class="math inline">\(𝑅 = \{𝐫_1, … , 𝐫_𝑛\}\)</span> 是 𝑈 的两个基，那么我们知道，该变换的矩阵通过以下关系相互关联（见第 4.2.1 节）：</p><p>​ $𝐴_𝑃 = 𝑇^{−1}𝐴_𝑅𝑇 $</p><p>其中<span class="math inline">\(𝐴_𝑆\)</span>是变换<span class="math inline">\(𝐴\)</span>在基<span class="math inline">\(𝑆\)</span>上的矩阵，<span class="math inline">\(𝑇 ∈ ℝ^{𝑛×𝑛}\)</span>是基变换矩阵（4.2.1节）。前定理表明<span class="math inline">\(det𝐴_𝑃 = det𝐴_𝑅\)</span>。因此，行列式的定义不仅适用于矩阵，也适用于线性变换！</p><p>行列式本质上存在一个对偶关系：你可以在交换矩阵的行和列的同时保持所有与行列式相关的恒等式成立。</p><blockquote><p>定理 4.4.5 设$ 𝐴 ∈ ℝ^{𝑛×𝑛}$为任意矩阵。则 <span class="math inline">\(det𝐴 = det𝐴^𝑇\)</span></p></blockquote><blockquote><p>证明。设<span class="math inline">\(𝐴 = (𝑎_{𝑖,𝑗})^𝑛_{𝑖,𝑗=1}\)</span>。设其转置矩阵的元素为<span class="math inline">\(𝑎^𝑡_{𝑖,𝑗} = 𝑎_{𝑗,𝑖}\)</span>。根据 (4.12)，我们有</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p150formula4.png" style="zoom:50%;" /></p><p>这里要注意，由于乘积 <span class="math inline">\(∏^𝑛_{𝑖=1} 𝑎_{𝑖,𝜎(𝑖)}\)</span>会遍历所有𝑖，并且项的顺序无关紧要，所以我们不妨将项的顺序设置为 <span class="math inline">\(𝑖=𝜎^{−1}(1),…,𝜎^{−1}(𝑛)\)</span>。因为</p><p>​ <span class="math inline">\(sign(𝜎^{−1}) =sign(𝜎)\)</span></p><p>继续上述计算，我们得到</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p151formula1.png" style="zoom:40%;" /></p><p>因为每个排列都是可逆的，并且 <span class="math inline">\(𝜎 ↦ 𝜎^{-1}\)</span> 是双射，所以对 <span class="math inline">\(𝜎 ∈ 𝑆_𝑛\)</span> 求和与对 <span class="math inline">\(𝜎^{-1} ∈ 𝑆_𝑛\)</span> 求和相同。</p><p>结合以上所有内容，我们得到</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p151formula2.png" style="zoom:50%;" /></p><p>这是我们必须要知道的。</p></blockquote><blockquote><p>定理 4.4.6 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>为任意矩阵，<span class="math inline">\(𝐴^{𝑖,𝑗}\)</span> 表示通过交换 𝐴 第 𝑖 列和第 𝑗 列得到的矩阵。则</p><p>​ <span class="math inline">\(det𝐴^{𝑖,𝑗} = − det𝐴\)</span>,</p><p>或者换句话说，交换𝐴的任意两列都会改变行列式的符号。同样，交换两行也会改变行列式的符号。</p></blockquote><blockquote><p>证明。这源于 (4.14) 的巧妙应用，注意到 <span class="math inline">\(𝐴^{𝑖,𝑗} = 𝐴𝐼^{𝑖,𝑗}\)</span>，其中 <span class="math inline">\(𝐼^{𝑖,𝑗}\)</span> 是通过交换单位矩阵的第 𝑖 列和第 𝑗 列得到的。<span class="math inline">\(det 𝐼^{𝑖,𝑗}\)</span> 是行列式，形式为 <span class="math inline">\(det(𝐞_{𝜎(1)}, … , 𝐞_{𝜎(𝑛)})\)</span>，其中 𝜎 是简单地交换 𝑖 和 𝑗 的排列。（也就是说，𝜎 是转置。）因此，</p><p>​ <span class="math inline">\(det𝐴^{𝑖,𝑗} = det𝐴det𝐼^{𝑖,𝑗} = − det𝐴\)</span></p><p>这就是我们要证明的。</p><p>关于交换行，我们可以应用之前的结果，因为转置矩阵保留了行列式。</p></blockquote><p>因此，具有两个相同行的矩阵具有零行列式。</p><blockquote><p>定理 4.4.7 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>为具有两个相同行或列的矩阵。则 det𝐴 = 0。</p></blockquote><blockquote><p>证明：假设第𝑖列和第𝑗列相同。由于两列相等，<span class="math inline">\(det𝐴^{𝑖,𝑗} =det𝐴\)</span>。然而，应用前面的定理（该定理指出交换两列会改变行列式的符号），我们得到 <span class="math inline">\(det𝐴^{𝑖,𝑗} = − det𝐴\)</span>。只有当 det𝐴 = 0 时，这才成立。</p><p>同样，转置这个矩阵可以证明矩阵的两个行相同时的情况。</p></blockquote><p>另一个结果是，我们获得了线性相关向量系统和行列式之间的本质联系。</p><blockquote><p>定理 4.4.8 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>为一个矩阵。则其列线性相关当且仅当 det𝐴 = 0。类似地，𝐴 的行线性相关当且仅当 det𝐴 = 0。</p></blockquote><blockquote><p>证明。(i) 首先，我们将证明线性相关的列（或行）意味着 det𝐴 = 0。照例，我们将𝐴的列表示为<span class="math inline">\(𝐚_1, … , 𝐚_𝑛\)</span>，为了简单起见，假设</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p152formula1.png" style="zoom:50%;" /></p><p>由于行列式是列的线性函数，因此我们有</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p152formula2.png" style="zoom:50%;" /></p><p>根据上一定理，所有项 $det(𝐚_1, 𝐚+2, … , 𝐚_𝑛) $均为零，这意味着 det𝐴 = 0，这正是我们要证明的。如果行是线性相关的，我们应用上述定理可得 <span class="math inline">\(det𝐴 = det𝐴^𝑇 = 0\)</span>。 (ii) 现在，我们来证明 det𝐴 = 0 表示列是线性相关的。与其给出相当复杂的精确证明，不如给出一个直观的解释。</p><p>回想一下，行列式是方向乘以由列给出的平行六面体的体积。由于方向为 ±1，det𝐴 意味着平行六面体的体积为 0。这只有当 𝑛列位于 𝑛 − 1 维子空间中时才会发生，这意味着它们是线性相关的。</p></blockquote><p>我们可以立即应用它来获得以下结果。</p><blockquote><p>推论 4.4.1 设 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>为具有常数零列（或行）的矩阵。则 det𝐴 = 0。</p></blockquote><p>由于行列式是基向量像的有符号体积，因此在某些情况下它可以为零。这些变换相当特殊。什么时候会发生这种情况？让我们回到欧几里德平面来建立一些直观的理解。</p><p>在那里，我们有</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p153formula1.png" style="zoom:50%;" /></p><p>或者换句话说，<span class="math inline">\(\frac{𝑥_1}{𝑦_1}=\frac{𝑥_2}{𝑦_2}\)</span>。对此还有一种解释：向量 <span class="math inline">\((𝑦_1, 𝑦_2)\)</span> 是<span class="math inline">\((𝑥_1, 𝑥_2)\)</span> 的标量倍数；也就是说，它们是共线的，这意味着它们位于通过原点的同一条直线上。从线性变换的角度思考，这意味着<span class="math inline">\(𝐞_1\)</span> 和<span class="math inline">\(𝐞_2\)</span> 的像位于<span class="math inline">\(ℝ^2\)</span> 的一个子空间上。正如我们接下来会看到的，这与变换的可逆性密切相关。</p><blockquote><p>定理 4.4.9（可逆性和行列式） 线性变换 <span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>可逆当且仅当 det𝐴 ≠ 0。</p></blockquote><blockquote><p>证明。当我们引入可逆性的概念（定义 4.1.2）时，我们发现𝐴可逆当且仅当它的列<span class="math inline">\(𝐚_1, …,𝐚_𝑛\)</span>构成一个基。因此，它们是线性独立的。 由于列的线性独立性（定义 1.2.1）等价于非零行列式，因此结论呼之欲出。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在前面的章节中，我们已经看到，线性变换可以被认为是对由基向量确定的网格进行扭曲。&lt;/p&gt;
&lt;p&gt;根据我们的几何直觉，我们推测测量变换对体积和距离的扭曲程度可以提供一些有价值的见解。正如我们将在本章中看到的，情况确实如此。保持距离或范数不变的变换很特殊，由此衍生出诸如主成分分析之类的方法。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习的数学基础-线性变换(三)</title>
    <link href="http://yoursite.com/2025/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%B8%89)/"/>
    <id>http://yoursite.com/2025/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%B8%89)/</id>
    <published>2025-10-10T06:54:36.000Z</published>
    <updated>2025-11-26T05:22:47.194Z</updated>
    
    <content type="html"><![CDATA[<p>在二维空间中，我们已经了解了一些几何映射的例子，例如缩放和旋转，它们都是线性变换。现在我们可以将它们转化为矩阵形式。我们将重点研究其中的五种：拉伸、剪切、旋转、反射和投影。</p><p>这些简单的变换不仅对于建立直觉至关重要，而且在计算机视觉中也经常应用。翻转、旋转和拉伸是图像增强流程的重要组成部分， 它们能够极大地提升模型的性能。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>欧氏平面中的线性变换</strong></li><li><strong>拉伸</strong></li><li><strong>旋转</strong></li><li><strong>剪切</strong></li><li><strong>反射</strong></li><li><strong>正交投影</strong></li></ul><h2 id="欧氏平面中的线性变换">1 欧氏平面中的线性变换</h2><p>我们刚刚看到，线性变换可以用基组的图像来描述。从几何角度来看，它们是将平行六面体映射到平行六面体的函数。</p><p>由于线性关系，你可以将其想象成扭曲了由基组确定的网格。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p133figure4.6.png" style="zoom:50%;" /></p><p>​ 图 4.6：线性变换如何扭曲由基向量确定的网格</p><p>在二维空间中，我们已经了解了一些几何映射的例子，例如缩放和旋转，它们都是线性变换。现在我们可以将它们转化为矩阵形式。我们将重点研究其中的五种：拉伸、剪切、旋转、反射和投影。</p><p>这些简单的变换不仅对于建立直觉至关重要，而且在计算机视觉中也经常应用。翻转、旋转和拉伸是图像增强流程的重要组成部分， 它们能够极大地提升模型的性能。</p><h3 id="拉伸">1.1 拉伸</h3><p>最简单的方法是广义的缩放。我们在上面的示例 1 中已经看到了它的变体（参见4.1 节）。以矩阵形式表示，它表示为</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p133formula1.png" style="zoom:50%;" /></p><p>此类线性变换可以通过绘制由标准基𝐞1 = (1, 0)、𝐞2 = (0, 1) 确定的单位正方形的图像来可视化。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p134figure4.7.png" style="zoom:50%;" /></p><p>​ 图 4.7：拉伸</p><h3 id="旋转">1.2 旋转</h3><p>旋转由矩阵给出</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p134formula1.png" style="zoom:50%;" /></p><p>要理解原因，请回想一下，变换矩阵的每一列都描述了基向量的像。(1, 0) 的旋转由 (cos 𝛼,sin 𝛼) 给出，而 (0, 1) 的旋转由 (cos(𝛼 + 𝜋/2),sin(𝛼 + 𝜋/2)) 给出。如图 4.8 所示。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p134figure4.8.png" style="zoom:50%;" /></p><p>​ 图 4.8：旋转矩阵解释</p><p>如上所述，我们可以将单位正方形的图像可视化，以获得对正在发生的事情的几何洞察力。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p135figure4.9.png" style="zoom:50%;" /></p><p>​ 图 4.9：旋转</p><h3 id="剪切">1.3 剪切</h3><p>另一个重要的几何变换是剪切，它在物理学中经常应用。剪切力(https://en.wikipedia.org/wiki/Shear_force) 是作用于同一物体的一对方向相反的力。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p135figure4.10.png" style="zoom:50%;" /></p><p>​ 图 4.10：剪切</p><p>其矩阵形式为</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p136formula1.png" style="zoom:50%;" /></p><p>其中 <span class="math inline">\(𝑆_𝑥\)</span> 、 <span class="math inline">\(𝑆_𝑦\)</span> 和 𝑆 表示 𝑥、𝑦 和两个方向上的剪切变换。</p><h3 id="反射">1.4 反射</h3><p>到目前为止，我们在欧氏平面上看到的所有变换都保留了空间的“方向”。然而，情况并非总是如此。矩阵给出的变换</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p136formula2.png" style="zoom:50%;" /></p><p>充当关于𝑥和𝑦轴的反射。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p136figure4.11.png" style="zoom:50%;" /></p><p>​ 图 4.11：反射</p><p>与旋转结合时，我们可以使用反射来翻转基。例如，变换将<span class="math inline">\(𝐞_1\)</span> 映射到<span class="math inline">\(𝐞_2\)</span>，将<span class="math inline">\(𝐞_2\)</span> 映射到<span class="math inline">\(𝐞_1\)</span>。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p136formula3.png" style="zoom:50%;" /></p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p137figure4.12.png" style="zoom:50%;" /></p><p>​ 图 4.12：交换<span class="math inline">\(𝐞_1\)</span> 和<span class="math inline">\(𝐞_2\)</span> 是反射和旋转</p><p>这些类型的变换在理解行列式中起着至关重要的作用，我们将在下一章中看到。</p><p>一般来说，在高维空间中，反射很容易定义。例如，</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p137formula1.png" style="zoom:50%;" /></p><p>是<span class="math inline">\(ℝ^3\)</span>的反射，将<span class="math inline">\(𝐞^3\)</span>翻转到相反方向。这就像照镜子一样：左边变右边，右边变左边。</p><p>反射可以多次翻转方向。变换如下</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p137formula2.png" style="zoom:50%;" /></p><p>翻转<span class="math inline">\(𝐞_2\)</span>和<span class="math inline">\(𝐞_3\)</span>，改变方向两次。稍后我们将看到，给定变换的“方向变化次数”是其基本描述之一。</p><h3 id="正交投影">1.5 正交投影</h3><p>最重要的变换之一（不仅在二维中）是正交投影。我们在2.2.3节讨论内积及其几何表示时已经见过它。仔细观察就会发现，它们其实是线性变换。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p138figure4.13.png" style="zoom:50%;" /></p><p>​ 图 4.13：正交投影</p><p>回想一下 (2.7)，𝑥 到某个 𝑦 的正交投影可以写成</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p138formula1.png" style="zoom:50%;" /></p><p>⟨⋅, ⋅⟩ 的双线性随即意味着 <span class="math inline">\(proj_𝐲(𝐱)\)</span> 也是线性的。借助一些代数知识，我们可以将其重写为矩阵形式。我们有</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p138formula2.png" style="zoom:50%;" /></p><p>因此，</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p139formula1.png" style="zoom:50%;" /></p><p>请注意</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p139formula2.png" style="zoom:50%;" /></p><p>标准基向量的像并非线性无关。因此，平面在<span class="math inline">\(proj_𝐲\)</span>下的像是span(𝐲)，它是一个一维子空间。从这个例子中，我们可以看出，向量空间在线性变换下的像不一定与起始空间的维数相同。</p><p>通过这些例子和知识的积累，我们对线性变换——神经网络最基本的组成部分——有了基本的了解。在下一节中，我们将研究线性变换如何影响向量空间的几何结构。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在二维空间中，我们已经了解了一些几何映射的例子，例如缩放和旋转，它们都是线性变换。现在我们可以将它们转化为矩阵形式。我们将重点研究其中的五种：拉伸、剪切、旋转、反射和投影。&lt;/p&gt;
&lt;p&gt;这些简单的变换不仅对于建立直觉至关重要，而且在计算机视觉中也经常应用。翻转、旋转和拉伸是图像增强流程的重要组成部分， 它们能够极大地提升模型的性能。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习的数学基础-线性变换(二)</title>
    <link href="http://yoursite.com/2025/09/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%BA%8C)/"/>
    <id>http://yoursite.com/2025/09/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%BA%8C)/</id>
    <published>2025-09-10T06:54:36.000Z</published>
    <updated>2025-11-26T05:23:01.305Z</updated>
    
    <content type="html"><![CDATA[<p>我们已经看到，任何线性变换都可以用基向量的像来描述。这给了我们经常使用的矩阵表示。然而，这很大程度上取决于基的选择。对于相同的变换，不同的基会产生不同的矩阵。这就涉及到基变换和变换矩阵。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>基变换</strong></li><li><strong>变换矩阵</strong></li></ul><h2 id="基变换">1 基变换</h2><p>在本节前面，我们已经看到，任何线性变换都可以用基向量的像来描述（参见 4.1.1 节）。这给了我们经常使用的矩阵表示。然而，这很大程度上取决于基的选择。对于相同的变换，不同的基会产生不同的矩阵。</p><p>例如，让我们看一下 <span class="math inline">\(𝑓 ∶ ℝ^2 → ℝ^2\)</span>，它将 <span class="math inline">\(𝐞_1 = (1, 0)\)</span> 映射到向量 (2, 1)，将 <span class="math inline">\(𝐞_2 = (0, 1)\)</span> 映射到(1, 2)。它在标准正交基 <span class="math inline">\(𝐸 = {𝐞_1, 𝐞_2}\)</span> 中的矩阵为</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p128formula1(4.5).png" style="zoom:50%;" /></p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p128figure4.3.png" style="zoom:50%;" /></p><p>​ 图 4.3：线性变换 𝑓， 由(4.5)定义</p><p>图 4.3 直观地显示了 𝑓 的效果。</p><p>如果我们选择不同的基，比如<span class="math inline">\(𝑃 = {𝐩_1 = (1, 1), 𝐩_2 = (−1, 1)}\)</span>，结果会怎样？通过快速计算，我们可以得出</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p129formula1.png" style="zoom:50%;" /></p><p>换句话说，<span class="math inline">\(𝑓 (𝐩_1) = 3𝐩_1 + 0𝐩_2\)</span> 且 <span class="math inline">\(𝑓 (𝐩_2) = 0𝐩_1 + 𝐩_2\)</span>。图 4.4 直观地展示了这一点。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p129figure4.4.png" style="zoom:50%;" /></p><p>​ 图 4.4：𝑓 对 $𝑝_1 = (1, 1) $和 <span class="math inline">\(𝑝_2 = (−1, 1)\)</span> 的影响</p><p>这意味着，如果 <span class="math inline">\(𝑃 = \{𝐩_1, 𝐩_2\}\)</span> 是我们的基（因此，如果写 (𝑎, 𝑏) 意味着 <span class="math inline">\(𝑎𝐩_1 + 𝑏𝐩_2\)</span>），𝑓 矩阵就变成</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p129formula2.png" style="zoom:50%;" /></p><p>在这个形式中，<span class="math inline">\(𝐴_{𝑓 ,𝑃}\)</span> 是一个对角矩阵。（也就是说，对角线以下和以上的元素均为零。）正如你所见，拥有正确的基可以显著简化线性变换。例如，在 𝑛 维中，应用对角形式的变换只需要 𝑛 次运算，如下所示</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p129formula3.png" style="zoom:50%;" /></p><p>否则，需要<span class="math inline">\(𝑛^2\)</span>次运算。因此，我们可以利用这一点节省很多计算。</p><p>##2 变换矩阵</p><p>我们刚刚看到，线性变换的矩阵取决于我们选择的基。然而，同一变换的矩阵之间存在着一种特殊的关系。我们接下来将对此进行探讨。设𝑓 ∶𝑈 → 𝑈为一个线性变换，<span class="math inline">\(𝑃 = \{𝐩_1, … ,𝐩_𝑛\}\)</span> 和<span class="math inline">\(𝑄 =\{𝐪_1, … ,𝐪_𝑛\}\)</span>为两个基。与前面一样，<span class="math inline">\(𝐴_{𝑓 ,𝑆}\)</span> 表示𝑓在某个基𝑆上的矩阵。</p><p>假设我们知道<span class="math inline">\(𝐴_{𝑓，𝑃}\)</span>，但我们的向量是用另一个基𝑄表示的。那么，我们如何计算向量在线性变换下的像呢？一个自然的想法是，先将向量表示从𝑄变换为𝑃，应用<span class="math inline">\(𝐴_{𝑓,𝑃}\)</span>后，再将表示变换回来。接下来，我们将对此进行精确计算。</p><p>令 𝑡 ∶ 𝑈 → 𝑈 为一个变换，其定义为 <span class="math inline">\(𝐩_𝑖 ↦ 𝐪_𝑖\)</span>，其中 𝑖 ∈ {1, … , 𝑛}。（换句话说，𝑡 将一组基向量映射到另一组。）由于 𝑃 和 𝑄 是基（因此这两个集合线性无关），𝑡 可逆。假设矩阵 <span class="math inline">\(𝐴_{𝑓 ,𝑄} = (𝑎^𝑄_{𝑖,𝑗})^𝑛_{𝑖,𝑗=1}\)</span> 为已知，即</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p130formula1.png" style="zoom:50%;" /></p><p>对所有𝑗都成立。因此，我们有</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p130formula2.png" style="zoom:50%;" /></p><p>换句话说，复合变换$𝑡^{−1}𝑓 𝑡 $在基𝑃上的矩阵与𝑓 在𝑄上的矩阵相同。用公式来表达，</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p130formula3(4.6).png" style="zoom:50%;" /></p><p>其中𝑇表示𝑡在𝑃上的矩阵。（为了简化符号，我们省略了下标。）</p><p>我们将𝑇称为基变换矩阵。这类关系在线性代数中很常见，因此我们将花点时间正式引入一个定义。</p><blockquote><p>定义 4.2.1（相似矩阵）</p><p>设 <span class="math inline">\(𝐴, 𝐵 ∈ ℝ^{𝑛×𝑛}\)</span> 为两个任意矩阵。如果存在一个矩阵 <span class="math inline">\(𝑇 ∈ ℝ^{𝑛×𝑛}\)</span>，使得</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p131formula1.png" style="zoom:50%;" /></p><p>成立，则称 𝐴 和 𝐵 相似。我们称形式为 <span class="math inline">\(𝐴 ↦ 𝑇^{−1}𝐴𝑇\)</span> 的映射为相似变换。</p></blockquote><p>用上面的术语来说，(4.6) 表示给定线性变换的矩阵彼此相似。</p><p>掌握了这些知识后，我们可以完成示例 (4.5)。在这种情况下，<span class="math inline">\(𝑇\)</span> 和 <span class="math inline">\(𝑇^{-1}\)</span> 可以写成</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p131formula2.png" style="zoom:50%;" /></p><p>（稍后，我们将看到计算任何矩阵逆的通用方法，但现在你可以手动验证。）因此，</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p131formula3.png" style="zoom:50%;" /></p><p>或者等价地，</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p131formula4.png" style="zoom:50%;" /></p><p>图 4.5 以几何形式显示了 (4.8)。</p><p><img src="/Users/adline/翻译/机器学习的数学基础/pics2/p132figure4.5.png" style="zoom:50%;" /></p><p>​ 图 4.5：基的变更（图示）</p><p>从这个例子中，我们可以看到，适当选择的相似变换可以使某些矩阵对角化。这是巧合吗？剧透警告：不是。在第七章中，我们将确切地看到何时以及如何做到这一点。</p><p>我知道，这有点太抽象了。一如既往，例子最能说明概念，所以让我们来看一些例子！</p><h2 id="section"></h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们已经看到，任何线性变换都可以用基向量的像来描述。这给了我们经常使用的矩阵表示。然而，这很大程度上取决于基的选择。对于相同的变换，不同的基会产生不同的矩阵。这就涉及到基变换和变换矩阵。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习的数学基础-线性变换(一)</title>
    <link href="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%B8%80)/"/>
    <id>http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%B8%80)/</id>
    <published>2025-08-10T06:54:36.000Z</published>
    <updated>2025-11-26T06:04:06.718Z</updated>
    
    <content type="html"><![CDATA[<p>在大多数线性代数课程中，矩阵是课程的核心。而在机器学习中，我们则始终与矩阵打交道。问题是：矩阵并不能说明一切。仅仅看矩阵很难理解其中的规律。例如，为什么矩阵乘法的定义如此复杂？为什么像<span class="math inline">\(𝐵 = 𝑇^{−1}𝐴𝑇\)</span>这样的关系很重要？为什么有些矩阵可逆，而有些则不可逆？</p><p>为了真正理解其中的奥秘，我们必须探究矩阵的起源：线性变换。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>什么是线性变换？</strong></li><li><strong>线性变换和矩阵</strong></li><li><strong>矩阵运算回顾</strong></li><li><strong>逆线性变换</strong></li><li><strong>核与像</strong></li></ul><p>“我的眼睛为什么会痛？” “你以前从来没用过。” ——莫菲斯第一次从“母体”醒来时对尼奥说</p><p>我们必须探究矩阵的起源：线性变换。就像尼奥一样，理解其中的奥秘可能会有点痛苦，但它会在以后给我们带来巨大的回报。让我们开始吧！</p><h2 id="什么是线性变换">1 什么是线性变换？</h2><p>随着内积、正交性和正交/标准正交基的引入，我们对特征空间的结构有了全面的了解。然而，在机器学习中，我们的兴趣主要在于数据的变换。</p><p>从这个角度来看，神经网络只是一个由更小的部分（称为层）组成的函数，每一步都将数据变换到一个新的特征空间。线性变换是机器学习模型的关键组成部分之一。</p><p>你可能见过形式为𝑓 (𝐱) = 𝐴𝐱的函数，但这只是看待它们的其中一种方式。本节将从几何角度开始，然后转向你可能已经熟悉的代数表示。为了理解神经网络如何学习强大的高级数据表示，了解变换的几何学至关重要。</p><p>那么，什么是线性变换？让我们不要犹豫，立即进入定义！</p><blockquote><p>定义 4.1.1（线性变换）</p><p>设 𝑈 和 𝑉 是两个向量空间（在同一个标量场上），𝑓 ∶ 𝑈 → 𝑉 是它们之间的函数。如果满足以下条件，则称 𝑓 是线性的</p><p><img src="./机器学习的数学基础-线性变换(一)/page118formula1.png" style="zoom:50%;" /></p><p>对所有向量 𝐱、𝐲 ∈ 𝑈 和所有标量 𝑎、𝑏成立。</p></blockquote><p>这就是线性代数被称为线性代数的原因。本质上，线性变换是两个向量空间之间的映射，它保留了代数结构：加法和标量乘法。（向量空间之间的函数通常被称为变换，因此我们将使用这个术语。）</p><blockquote><p>备注 4.1.1 线性本质上是将两个性质合二为一：对于所有向量 𝐱、𝐲 和所有标量 𝑎，𝑓 (𝐱 + 𝐲) = 𝑓 (𝐱) + 𝑓 (𝐲) 和 𝑓 (𝑎𝐱) = 𝑎𝑓 (𝐱)。由此可知 (4.1)可进一步写成</p><p><img src="./pics2/page118formula2.png" style="zoom:50%;" /></p></blockquote><p>从定义中可以立即看出两个性质。首先，由于</p><p><img src="./pics2/page118formula3.png" style="zoom:50%;" /></p><p>𝑓 (𝟎) = 𝟎 对每个线性变换都成立。此外，线性变换的复合仍然是线性的，正如</p><p><img src="./pics2/page118formula4.png" style="zoom:50%;" /></p><p>显示了任何线性 𝑓 和 𝑔 以及标量 𝑎 和 𝑏。</p><p>像往常一样，让我们看一些例子来建立直觉。</p><p><strong>例 1.</strong> 对于任何标量 𝑐，缩放变换 𝑓 (𝐱) = 𝑐𝐱 是线性的</p><p>这可能是最简单的例子，它可以在所有向量空间中定义。</p><p><img src="./pics2/page119figure4.1.png" style="zoom:50%;" /></p><p>​ 图 4.1：缩放作为线性变换</p><p>很容易看出缩放是线性的：</p><p><img src="./pics2/page119formula1.png" style="zoom:50%;" /></p><p><strong>例 2.</strong> 在<span class="math inline">\(ℝ^2\)</span>中，绕原点旋转𝛼角度也是线性的</p><p><img src="./pics2/page119figure4.2.png" style="zoom:50%;" /></p><p>​ 图 4.2：欧氏平面中的旋转作为线性变换</p><p>为了证明旋转确实是线性的，我们先直接看一个定义：平面向量<span class="math inline">\(𝐱 = (𝑥_1, 𝑥_2)\)</span> 的旋转角为 𝛼，其表达式为</p><p><img src="./pics2/page120formula1.png" style="zoom:50%;" /></p><p>由 (4.1) 式很容易得到证明。我知道这看起来有点突然，但相信我，旋转公式将会详细解释。你可以用一些基本的三角学知识来解释，或者等到我们稍后用矩阵来解释。</p><p>一般来说，线性变换与空间几何有着密切的联系。稍后，我们将详细研究<span class="math inline">\(ℝ^2\)</span>的线性变换，重点关注像这样的几何变换。（注意，旋转在高维空间中会稍微复杂一些，因为它们需要一个旋转轴。）</p><p><strong>例3：</strong>在任何向量空间𝑉和非零向量𝐯∈𝑉中，由𝑓 (𝐱) = 𝐱 + 𝐯定义的平移不是线性的，正如𝑓 (𝟎) = 𝐯 ≠ 𝟎。</p><p>我们将在本节后面看到更多示例。现在，我们来讨论线性变换的一些一般性质。对于任何线性变换 𝑓 ∶ 𝑈 → 𝑉，图像</p><p><img src="./pics2/page120formula2.png" style="zoom:50%;" /></p><p>始终是𝐕的子空间（参见第 1.2.7 节）。这很容易验证：如果 <span class="math inline">\(𝐯_1, 𝐯_2 ∈ im 𝑓\)</span>，则存在 <span class="math inline">\(𝐮_1, 𝐮_2 ∈ 𝑈\)</span>，使得 <span class="math inline">\(𝑓 (𝐮_1) = 𝐯1\)</span> 且 <span class="math inline">\(𝑓 (𝐮_2) = 𝐯_2\)</span>，如下式所示</p><p><img src="./pics2/page120formula3.png" style="zoom:50%;" /></p><p>为了增加一个抽象层次，我们将看到所有线性变换的集合形成一个向量空间。</p><blockquote><p>定理 4.1.1 设 𝑈 和 𝑉 是同一域 𝐹 上的两个向量空间。则所有线性变换的集合</p><p><img src="./pics2/page120formula4.png" style="zoom:50%;" /></p><p>也是 𝐹 上的向量空间，具有函数加法和标量乘法的通常定义。</p></blockquote><p>它的证明只是一个枯燥的清单，只是简单回顾了向量空间定义（定义 1.1.1）中的各项内容。我建议你至少过一遍，巩固一下对向量空间的理解，但其实没什么特别的。</p><h3 id="线性变换和矩阵">1.1 线性变换和矩阵</h3><p>正如我们所见，线性变换的定义有点抽象。然而，有一种简单而富有表现力的方法来刻画它们。</p><p>为了说明这一点，设 𝑓 ∶ 𝑈 → 𝑉 是两个向量空间 𝑈 和 𝑉 之间的线性变换。假设<span class="math inline">\(\{𝐮_1, … , 𝐮_𝑚\}\)</span> 是 𝑈 中的基，而 <span class="math inline">\(\{𝐯_1, … , 𝐯_𝑛\}\)</span> 是 𝑉 中的基。由于每个 𝐱 ∈ 𝑈 都可以写成如下形式</p><p><img src="./pics2/page121formula1.png" style="zoom:50%;" /></p><p>𝑓 的线性意味着</p><p><img src="./pics2/page121formula2(4.3).png" style="zoom:50%;" /></p><p>这意味着<span class="math inline">\(𝑓 (𝐱)\)</span> 是<span class="math inline">\(𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑚)\)</span> 的线性组合。换句话说，每个线性变换都完全由基向量的像决定。为了扩展这个想法，假设对于每个<span class="math inline">\(𝐮_𝑗\)</span>，对于某些标量<span class="math inline">\(𝑎_{𝑖,𝑗}\)</span>，我们有</p><p><img src="./pics2/page121formula3.png" style="zoom:50%;" /></p><p>这些𝑛 × 𝑚 数完全描述了𝑓。为了符号简单，我们将它们存储在一个𝑛 × 𝑚 大小的表中，称为矩阵，我们将其表示为<span class="math inline">\(𝐴_𝑓\)</span>：</p><p><img src="./pics2/p121formula4.png" style="zoom:50%;" /></p><p>这意味着线性变换可以用矩阵来表示。这种联系在机器学习中被广泛应用。</p><p>进一步展开（4.3），对于每个<span class="math inline">\(𝐱 = ∑^𝑚_{𝑗=1} 𝑥_𝑗𝐮_𝑗\)</span>，我们有</p><p><img src="./pics2/p122formula1.png" style="zoom:50%;" /></p><p>因此，𝐱 的图像可以表示为<span class="math inline">\(𝐴_𝑓 𝐱\)</span>：</p><p><img src="./pics2/p122formula2.png" style="zoom:50%;" /></p><p>这里需要注意两点。首先，我们隐式地选择将向量表示为列而不是行。这是一个影响深远的决定，将影响本书后面的许多计算。我们会继续指出这一点。</p><p>其次，矩阵表示取决于基的选择！假设<span class="math inline">\(𝑃 = \{𝐩_1, … , 𝐩_𝑛\} ⊂ 𝑈\)</span> 是矩阵的基，我们将这种依赖关系表示为下标，写作<span class="math inline">\(𝐴_{𝑓,𝑃}\)</span>。</p><p>为了避免混淆，我们几乎只用标准正交基来定义线性变换。在实际场景中，这更容易理解正在发生的事情。所以，每当我写下“设𝐴是线性变换𝑓的矩阵”这样的话，就隐含地假设了𝐴的基函数形式为<span class="math inline">\(𝐞_1 = (1, 0, … , 0), 𝐞_2 = (0, 1, … , 0), … , 𝐞_𝑛 = (0, 0, … , 1)\)</span>。</p><p>从哲学角度来说，你听说过柏拉图的洞穴寓言吗？在这个思想实验中，人们被假设生活在一个洞穴中，始终面朝一面墙，只能观察身后火焰投射的影子。他们所观察到的并用来构建世界内部表征的东西，与现实截然不同。将这个类比应用到线性代数中，矩阵就是我们在实际场景中观察和使用的影子。在许多入门课程中，线性变换是隐藏的，只教授矩阵微积分。我第一次接触这个主题的经历也类似：我上的第一门线性代数课就只讲矩阵。这门课复杂得令人困惑，简直是数学课里最复杂的了。（我可以向你保证，这门课确实非常复杂和令人困惑。）后来，当我发现可以从线性变换的角度来看待矩阵时，一切都豁然开朗了。</p><p>不了解矩阵背后的原理，就不可能掌握线性代数。如果你觉得我的方法太抽象，请记住：多年以后，当你成为一名实践数据科学家/机器学习工程师/研究员或其他任何职位时，深入研究这些原理将会带来巨大的回报。</p><p>让我们回到正题，继续讨论线性变换。最常用的矩阵是恒等变换 id ∶ 𝐱 ↦ 𝐱 的矩阵。我们将其表示为 𝐼。很容易看出</p><p><img src="./pics2/p123formula1(4.4).png" style="zoom:50%;" /></p><p>总而言之，对于矩阵 𝐴，线性变换可以通过 𝐱 ↦ 𝐴𝐱 给出。实际上，映射</p><p><img src="./pics2/p123formula2.png" style="zoom:50%;" /></p><p>定义了由 (4.2) 定义的线性变换空间 𝐿(𝑈, 𝑉) 与 𝑛 × 𝑚 矩阵集之间的一一对应关系，其中 𝑛 和 𝑚 是对应的维度。</p><h3 id="矩阵运算回顾">1.2 矩阵运算回顾</h3><p>函数可以相加和复合。由于线性变换和矩阵之间的联系，矩阵运算继承自相应的函数运算。</p><p>基于这一原则，我们定义了矩阵加法，使得两个线性变换之和的矩阵等于对应矩阵之和。</p><p>从数学上讲，如果 𝑓 , 𝑔 ∶ 𝑈 → 𝑉 是两个带矩阵的线性变换，𝑓 ↔︎ 𝐴 和 𝑔 ↔︎ 𝐵，那么</p><p><img src="./pics2/p123formula3.png" style="zoom:50%;" /></p><p>因此，相应的矩阵可以按元素相加：</p><p><img src="./pics2/p123formula4.png" style="zoom:50%;" /></p><p>矩阵之间的乘法由相应变换的组合来定义。</p><p>为了弄明白如何操作，我们先研究一个特殊情况。（一般来说，先研究特殊情况是个好主意，因为它们通常可以降低复杂性，并让你在不造成信息过载的情况下发现规律。）因此，设 𝑓 , 𝑔 ∶ 𝑈 → 𝑈 为两个线性变换，将 𝑈 映射到自身上。为了确定与𝑓 ◦ 𝑔 对应的矩阵元素，我们必须用所有基向量 <span class="math inline">\(𝐮_1, … , 𝐮_𝑛\)</span> 来表示 <span class="math inline">\(𝑓 (𝑔(𝐮_𝑗))\)</span>。为此，我们有</p><p><img src="./pics2/p124formula1.png" style="zoom:50%;" /></p><p>考虑我们如何定义变换矩阵，标量$ (∑^𝑛_{𝑘=1} 𝑎_{𝑖,𝑘}𝑏_{𝑘,𝑗}) $是 𝑓 ◦ 𝑔 矩阵第 𝑖 行第 𝑗 列的元素。因此，矩阵乘法可以定义为</p><p><img src="./pics2/p124formula2.png" style="zoom:50%;" /></p><p>一般情况下，只有当相应的线性变换可以组合时，我们才能定义矩阵的乘积。也就是说，如果𝑓 ∶ 𝑈 → 𝑉，则𝑔 必须从𝑉开始。将其转化为矩阵的语言，𝐴 的列数必须与𝐵 的行数匹配。因此，对于任何<span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑚}\)</span> 和<span class="math inline">\(𝐵 ∈ ℝ^{𝑚×𝑙}\)</span>，它们的乘积定义为</p><p><img src="./pics2/p124formula3.png" style="zoom:50%;" /></p><h3 id="逆线性变换">1.3 逆线性变换</h3><p>对于线性变换，可逆性问题非常重要。例如，你遇到过这样的方程组吗？</p><p><img src="./pics2/p124formula4.png" style="zoom:50%;" /></p><p>如果我们定义</p><p><img src="./pics2/p125formula1.png" style="zoom:50%;" /></p><p>上述系统可以写成𝐴𝐱 = 𝐛的形式。这些被称为线性方程，用于建模从金融到生物学的各种过程。你会如何写出这样一个方程的解？如果存在一个矩阵<span class="math inline">\(𝐴^{-1}\)</span>，使得<span class="math inline">\(𝐴^{-1}𝐴\)</span>是单位矩阵𝐼（由(4.4)式定义），那么将方程𝐴𝐱 = 𝐛从左乘以<span class="math inline">\(𝐴^{-1}\)</span>，将得到<span class="math inline">\(𝐱 = 𝐴^{-1}𝐛\)</span>形式的解。</p><p>矩阵<span class="math inline">\(𝐴^{-1}\)</span>被称为𝐴的逆矩阵。它可能并不总是存在，但当它存在时，由于多种原因，它极其重要。我们稍后会讨论线性方程，但首先，让我们学习一下可逆性的基础知识！以下是一般定义。</p><blockquote><p>定义 4.1.2（线性变换的逆）</p><p>设 𝑓 ∶ 𝑈 → 𝑉 是向量空间 𝑈 和 𝑉 之间的线性变换。如果存在一个线性变换 <span class="math inline">\(𝑓^{-1}\)</span> 使得 <span class="math inline">\(𝑓^{-1}◦ 𝑓\)</span> 和 <span class="math inline">\(𝑓 ◦ 𝑓^{-1}\)</span> 为恒等函数，则称 𝑓 可逆；即</p><p><img src="./pics2/p125formula2.png" style="zoom:50%;" /></p><p>对所有𝐮∈𝑈、𝐯∈𝑉成立。 <span class="math inline">\(𝑓^{-1}\)</span>称为𝑓的逆。</p></blockquote><p>并非所有线性变换都是可逆的。例如，如果𝑓将所有向量映射到零向量，则无法定义逆变换。</p><p>逆变换的存在需要满足某些条件。其中最重要的一个条件是将基的概念与可逆性联系起来。</p><blockquote><p>定理 4.1.2（线性变换的可逆性）</p><p>设 𝑓 ∶ 𝑈 → 𝑉 为线性变换，<span class="math inline">\(𝐮_1, … , 𝐮_𝑛\)</span> 为 𝑈 中的基。则 𝑓 可逆当且仅当$𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) $为 𝑉 中的基。</p></blockquote><p>以下证明很简单，但可能有点让人一时无法接受。第一次阅读时可以跳过，以后可以随时重新阅读。</p><blockquote><p>证明。与往常一样，“当且仅当"这类定理的证明由两部分组成，因为这些命题涉及两个蕴涵式。</p><ol type="a"><li>首先，我们证明𝑓可逆，则$𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) <span class="math inline">\(是一个基。也就是说，我们需要证明\)</span>𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛)$ 线性无关，且每个𝐲 ∈ 𝑉都可以写成它们的线性组合。由于𝑓可逆，𝑓 (𝟎) = 𝟎，而且不存在非零向量𝐱 ∈ 𝑈 使得𝑓 (𝐱) = 𝟎。换句话说，𝟎 不能写成 $𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) $的非平凡线性组合，由此定理 1.2.2推断出它们之间的线性独立性。</li></ol><p>另一方面，可逆性意味着每个 𝐲 ∈ 𝑉 都可以表示为 𝐲 = 𝑓 (𝐱)，其中 𝐱 ∈ 𝑈。（假设 <span class="math inline">\(𝐱 = 𝑓^{−1}(𝐲)\)</span>。）由于 $𝐮_1, … ，𝐮_𝑛 <span class="math inline">\(是一个基，\)</span>𝐱 = ∑^𝑛_{𝑖=1} 𝑥_𝑖𝐮_𝑖$。因此，</p><p><img src="./pics2/p126formula1.png" style="zoom:50%;" /></p><p>可以证明 <span class="math inline">\(span(𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛)) = 𝑉\)</span>。</p><p>$𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) $的线性独立性以及它张成 𝑉 的事实表明它确实是基。</p><ol start="2" type="a"><li>现在我们证明另一个蕴涵式：如果 <span class="math inline">\(𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛)\)</span> 是基，则 𝑓 可逆。</li></ol><p>如果$ 𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) $确实是基，则每个 𝐲 ∈ 𝑉 都可以写成</p><p><img src="pics2/p126formula2.png" style="zoom:50%;" /></p><p>这证明了全射性。关于单射性，如果对于某个𝐚，𝐛∈𝑈，𝐲 = 𝑓 (𝐚) = 𝑓 (𝐛)，那么，由于𝐚 和 𝐛 都可以写成<span class="math inline">\(𝐮_𝑖\)</span>基向量的线性组合，因此我们有</p><p><img src="./pics2/p126formula3.png" style="zoom:50%;" /></p><p>和</p><p><img src="./pics2/p126formula4.png" style="zoom:50%;" /></p><p>因此，<span class="math inline">\(𝟎 = ∑^𝑛_{𝑖=1}(𝑎_𝑖 − 𝑏_𝑖)𝐮_𝑖\)</span>，且由于$𝐮_1, … , 𝐮_𝑛 <span class="math inline">\(是 U 中的一个基，\)</span>𝑎_𝑖 = 𝑏_𝑖$ 必定成立。因此𝑓 是单射。</p></blockquote><p>该定理的一个推论是，如果𝑈和𝑉的维数不同，则线性变换𝑓 ∶ 𝑈 → 𝑉不可逆。我们也可以从矩阵的角度来看待可逆性。对于任何<span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>，如果相应的线性变换可逆，则存在一个矩阵<span class="math inline">\(𝐴^{−1} ∈ ℝ^{𝑛×𝑛}\)</span>使得<span class="math inline">\(𝐴^{−1}𝐴 = 𝐴𝐴^{−1} = 𝐼\)</span>。如果一个矩阵不是方阵，那么它在经典意义上不可逆。</p><h3 id="核与像">1.4 核与像</h3><p>关于线性变换的可逆性，有两个特殊的集合起着至关重要的作用：核和像。让我们来看一下！</p><blockquote><p>定义 4.1.3（线性变换的核和像）</p><p>设 𝑓 ∶ 𝑈 → 𝑉 为线性变换。其像和核定义为</p><p><img src="./pics2/p127formula1.png" style="zoom:50%;" /></p><p>和</p><p><img src="./pics2/p127formula2.png" style="zoom:50%;" /></p></blockquote><p>通常，我们将某个矩阵 𝐴 写为 im 𝐴 和 ker𝐴，指的是由 𝐱 ↦ 𝐴𝐱 定义的线性变换。</p><p>由于 𝑓 的线性性，很容易看出 im 𝑓 是 𝑉 的子空间，而 ker 𝑓 是 𝑈 的子空间。如上所述，它们与可逆性密切相关，我们接下来会看到。</p><blockquote><p>定理 4.1.3（线性变换的可逆性）</p><p>设 𝑓 ∶ 𝑈 → 𝑉 为线性变换。</p><p>（a）𝐴 为单射当且仅当 ker 𝑓 = {𝟎}。</p><p>（b）𝐴 为全射当且仅当 im 𝑓 = 𝑉。</p><p>（c）𝐴 为双射（即可逆），当且仅当 ker 𝑓 = {𝟎} 且 im 𝑓 = 𝑉。</p></blockquote><blockquote><p>证明：(a) 如果 𝑓 是单射，则 𝑈 中只能有一个向量映射到 𝟎。由于对于任何线性变换，𝑓 (𝟎) = 𝟎，因此 ker 𝑓 = {𝟎}。另一方面，如果有两个不同的向量 𝐱，𝐲 ∈ 𝑈，使得 𝑓 (𝐱) = 𝑓 (𝐲)，则 𝑓 (𝐱 − 𝐲) =𝑓 (𝐱) − 𝑓 (𝐲) = 𝟎，因此 𝐱 − 𝐲 ∈ ker 𝑓。因此，ker 𝑓 = {𝟎} 蕴涵 𝐱 = 𝐲，从而给出单射性。 （b）这只是全射性的定义。</p><p>（c）这是由上面（a）和（b）的结合立即得出的。</p></blockquote><p>因为矩阵定义了线性变换，所以讨论矩阵的逆是有意义的。</p><p>从代数角度来说，<span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>的逆是矩阵<span class="math inline">\(𝐴^{−1} ∈ ℝ^{𝑛×𝑛}\)</span>，使得<span class="math inline">\(𝐴^{−1}𝐴 = 𝐴𝐴^{−1} = 𝐼\)</span>成立。线性变换和矩阵之间的联系意味着<span class="math inline">\(𝐴^{−1}\)</span> 是<span class="math inline">\(𝑓^{−1}\)</span>的矩阵，所以这并不奇怪。</p><p>如果本节关于可逆性的内容感觉涉及太多代数，不用担心。稍后，在讨论变换的行列式时，我们将在本章后面从几何角度研究可逆性。关于矩阵，稍后我们将在5.1.6节中看到计算逆矩阵的通用方法。我们很快就会讲到这一点，但首先，我们先来看看基的选择如何决定矩阵的表示。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在大多数线性代数课程中，矩阵是课程的核心。而在机器学习中，我们则始终与矩阵打交道。问题是：矩阵并不能说明一切。仅仅看矩阵很难理解其中的规律。例如，为什么矩阵乘法的定义如此复杂？为什么像&lt;span class=&quot;math inline&quot;&gt;\(𝐵 = 𝑇^{−1}𝐴𝑇\)&lt;/span&gt;这样的关系很重要？为什么有些矩阵可逆，而有些则不可逆？&lt;/p&gt;
&lt;p&gt;为了真正理解其中的奥秘，我们必须探究矩阵的起源：线性变换。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习和深度学习概述(四)</title>
    <link href="http://yoursite.com/2025/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E5%9B%9B/"/>
    <id>http://yoursite.com/2025/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E5%9B%9B/</id>
    <published>2025-02-10T06:54:36.000Z</published>
    <updated>2024-12-31T08:37:23.461Z</updated>
    
    <content type="html"><![CDATA[<p>本文是基于《深度学习中的数学》一书中的思想，旨在从本文起系列阐述深度学习技术背后的数学原理，给想要对深度学习更进一步了解的读者提供一个可以查阅的底层原理资料。本文共分为四个部分，此为第四部分。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>线性和非线性模型</strong></li><li><strong>通过多个非线性层实现更高的表达能力：深度神经网络</strong></li></ul><h4 id="线性和非线性模型">1.6 线性和非线性模型</h4><p>在图1.2中，我们面临一个相当简单的情况，即类别可以用一条线（高维曲面中的超平面）分隔。这在现实生活中并不常见。如果不同类别的点无法用一条线分开，如图1.4所示，该怎么办？在这种情况下，我们的模型架构不应再是简单的加权组合。它应是一个非线性函数。例如，请看图1.4中的曲线分隔符。从函数逼近的角度来看，非线性模型也是有意义的。最终，我们的目标是近似非常复杂且高度非线性的函数，以模拟生活中所需的分类或估计过程。直观地说，使用非线性函数来建模它们似乎会更好。</p><img src="/2025/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E5%9B%9B/figure1.3.png" class="" alt="图片"><p><strong>图1.3 模型将输入（特征）空间中的点映射到输出空间，在输出空间中更容易进行类别划分。例如，在该图中，属于两个类（红色（+）和绿色（-））的输入特征点分布在三维特征空间中的圆柱体体积上。该模型将圆柱体展开为矩形。特征点被映射到二维平面输出空间，在输出空间中，可以使用简单的线性分离器区分这两个类。</strong></p><img src="/2025/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E5%9B%9B/figure1.4.png" class="" alt="图片"><p><strong>图1.4两个类别（用浅色和深色表示）不能用线分开，需要用曲线分隔符。在三维空间中，这相当于说没有平面可以分开表面；需要一个曲面分隔符。在静止的空间中，这相当于说没有超平面可以分开类别；需要一个弯曲的超曲面。</strong></p><p>机器学习中非常流行的非线性函数是Sigmoid函数，因为它看起来像字母 S，所以也叫S 型函数。Sigmoid函数通常用希腊字母𝜎表示。它的定义如下 <span class="math inline">\(\sigma^2(x)=\frac1{1+e^{-x}}\)</span> (1.5)</p><p>图1.5显示了 Sigmoid函数的图形。因此，我们可以使用等式1.6，这是个非常流行的模型架构，叫做逻辑回归（仍然比较简单），该架构采用输入加权和的Sigmoid函数（无参数）：</p><p><span class="math inline">\(y=\sigma\left(\vec{w}^T\vec{x}+b\right) (1.6)\)</span></p><img src="/2025/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E5%9B%9B/figure1.5.png" class="" alt="图片"><p>​ <strong>图1.5 Sigmoid函数图形</strong></p><p>Sigmoid函数赋予了非线性。与单独的加权和相比，这种架构可以处理相对更复杂的分类任务。事实上，等式1.6描述了神经网络的基本构建块。</p><h4 id="通过多个非线性层实现更高的表达能力深度神经网络">1.7 通过多个非线性层实现更高的表达能力：深度神经网络</h4><p>在第1.6节中，我们指出，在基本加权和模型中添加非线性可以产生能够处理更复杂任务的模型架构。用机器学习术语来说，非线性模型具有更强的表达能力。</p><p>现在考虑一个现实生活中的问题：比如，构建一个狗识别器。输入空间包括像素位置和像素颜色（x、y、r、g、b，其中 r、g、b 表示像素颜色的红色、绿色和蓝色成分）。输入维度很大（与图像中的像素数量成比例）。图1.6简要介绍了典型的深度学习系统（例如狗图像识别器）必须处理的背景和前景的可能变化。我们需要一台具有极高表达能力的机器。我们如何以原则性的方式创建这样的机器？</p><img src="/2025/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E5%9B%9B/figure1.6.png" class="" alt="图片"><p>​ <strong>图1.6 非典型深度学习系统（此处为狗图像识别器）需要处理的背景和前景变化一览</strong></p><p>与其一步一步地从输入生成输出，不如采用级联方法？我们将从输入中生成一组中间或隐藏输出，其中每个隐藏输出本质上是一个逻辑回归单元。然后我们添加另一层，将前一层的输出作为输入，依此类推。最后，我们将最外层的隐藏层输出合并到总输出中。</p><img src="/2025/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E5%9B%9B/figure1.7.png" class="" alt="图片"><p>​ <strong>图1.7 多层神经网络</strong></p><p>我们用以下等式来描述该系统。请注意，我们在权重上添加了一个上标来标识层（层0 最接近输入；层 L 是最后一层，距离输入最远）。我们还将下标设为二维（因此给定层的权重是一个矩阵）。第一个下标标识目标节点，第二个下标标识源节点（见图1.7）。</p><p>精明的读者可能会注意到，以下等式没有明确的偏差项。这是因为，为了简化符号，我们将其并入权重集并假设其中一个输入（例如，<span class="math inline">\(x_0\)</span>= 1）和相应的权重（例如<span class="math inline">\(w_0\)</span>）是偏差。</p><p>第0层：从n+1个输入生成<span class="math inline">\(n_0\)</span>个隐藏输出</p><p><span class="math inline">\(\begin{aligned}&amp;h_0^{(0)}&amp;&amp;=\sigma\left(w_{00}^{(0)}x_0+w_{01}^{(0)}x_1+\cdots w_{0n}^{(0)}x_n\right)\\ &amp;h_1^{(0)}&amp;&amp; =\sigma\left(w_{10}^{(0)}x_0+w_{11}^{(0)}x_1+\cdots w_{1n}^{(0)}x_n\right) \\ &amp;h_{n_0}^{(0)}&amp;&amp; =\sigma\left(w_{n_00}^{(0)}x_0+w_{n_01}^{(0)}x_1+\cdots w_{n_0n}^{(0)}x_n\right) \end{aligned}\)</span> （1.7）</p><p>第1层：从第0 层的<span class="math inline">\(n_0\)</span>个隐藏输出生成<span class="math inline">\(n_1\)</span>个隐藏输出</p><p><span class="math inline">\(\begin{aligned} &amp;h_0^{(1)}&amp;&amp; =\sigma\left(w_{00}^{(1)}h_0^{(0)}+w_{01}^{(1)}h_1^{(0)}+\cdots w_{0n_0}^{(1)}h_{n_0}^{(0)}\right) \\ &amp;h_1^{(1)}&amp;&amp; =\sigma\left(w_{10}^{(1)}h_0^{(0)}+w_{11}^{(1)}h_1^{(0)}+\cdots w_{1n_0}^{(1)}h_{n_0}^{(0)}\right) \\ &amp;h_{n_1}^{(1)}&amp;&amp; =\sigma\left(w_{n_10}^{(1)}h_0^{(0)}+w_{n_11}^{(1)}h_1^{(0)}+\cdots w_{n_1n_0}^{(1)}h_{n_0}^{(0)}\right) \end{aligned}\)</span>（1.8）</p><p>最后一层（L）：从前一层<span class="math inline">\(n_{L-1}\)</span>个隐藏输出生成m+1个可见输出</p><p><span class="math inline">\(\begin{aligned} h_0^{(L)}&amp; =\sigma\left(w_{00}^{(L)}h_0^{(L-1)}+w_{01}^{(L)}h_1^{(L-1)}+\cdots w_{0n_{L-1}}^{(L)}h_{n_{L-1}}^{(L-1)}\right) \\ h_1^{(L)}&amp; =\sigma\left(w_{10}^{(L)}h_0^{(L-1)}+w_{11}^{(L)}h_1^{(L-1)}+\cdots w_{1n_{L-1}}^{(L)}h_{n_{L-1}}^{(L-1)}\right) \\ \begin{array}{cc}\vdots\\\end{array}&amp;&amp; \\ h_m^{(L)}&amp; =\sigma\left(w_{m0}^{(L)}h_0^{(L-1)}+w_{m1}^{(L)}h_1^{(L-1)}+\cdots w_{mn_{L-1}}^{(L)}h_{n_{L-1}}^{(L-1)}\right) \end{aligned}\)</span> （1.9）</p><p>这些等式如图1.7 所示。图1.7 所示的机器可能非常强大，具有巨大的表达能力。我们可以系统地调整其表达能力以适应手头的问题。它是一个神经网络。我们将用本书的其余部分来研究这一点。</p><h4 id="小结">小结</h4><p>在本章中，我们概述了机器学习，并一直延伸到深度学习。我们用玩具猫脑示例说明了这些想法。本章使用了一些数学概念（例如向量），但没有进行适当的介绍，我们鼓励您在介绍向量和矩阵后重新阅读本章。</p><p>我们希望您能从本章中得到以下的收获：</p><ul><li>机器学习是一种完全不同的计算范式。在传统计算中，我们向计算机提供分步指令序列，告诉它要做什么。在机器学习中，我们建立一个数学模型，试图逼近从输入生成分类或估计的未知函数。</li><li>模型函数的数学性质由分类或估计任务的物理性质和复杂性决定。模型具有参数。参数值是根据训练数据（具有已知输出的输入）估计的。参数值经过优化，以使模型输出尽可能接近训练输入上的训练输出。</li><li>机器学习模型可以从另一个角度理解，即几何视角，它是将多维输入空间中的点映射到输出空间中的点的变换。</li><li>分类/估计任务越复杂，近似函数就越复杂。用机器学习术语来说，复杂的任务需要具有更强表达能力的机器。更高的表达能力来自非线性（例如，S 型函数；参见公式1.5）和更简单机器的分层组合。这让我们想到了深度学习，它只不过是一个多层非线性机器。</li><li>复杂的模型函数通常通过组合较简单的基函数来构建。</li></ul><p>请系好安全带：学习乐趣即将变得更加激烈。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是基于《深度学习中的数学》一书中的思想，旨在从本文起系列阐述深度学习技术背后的数学原理，给想要对深度学习更进一步了解的读者提供一个可以查阅的底层原理资料。本文共分为四个部分，此为第四部分。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习和深度学习概述(三)</title>
    <link href="http://yoursite.com/2025/01/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E4%B8%89/"/>
    <id>http://yoursite.com/2025/01/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E4%B8%89/</id>
    <published>2025-01-10T06:54:36.000Z</published>
    <updated>2024-12-31T08:22:46.761Z</updated>
    
    <content type="html"><![CDATA[<p>本文是基于《深度学习中的数学》一书中的思想，旨在从本文起系列阐述深度学习技术背后的数学原理，给想要对深度学习更进一步了解的读者提供一个可以查阅的底层原理资料。本文共分为四个部分，此为第三部分。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>机器学习的几何视角</strong></li><li><strong>机器学习中的回归和分类</strong></li></ul><h4 id="机器学习的几何视角">1.4 机器学习的几何视角</h4><p>猫脑模型的每个输入都是一个由两个数字组成的数组：<span class="math inline">\(x_0\)</span>（表示物体的硬度）、<span class="math inline">\(x_1\)</span>（表示物体的锋利度），或者等效地，一个2 ×1向量<span class="math inline">\(\vec{x}\)</span>。直觉上，您可以在头脑里想象将输入视为高维空间中的一个点。输入空间通常称为特征空间——一个表示模型要检查的所有特征的空间。在本例中，特征空间维度为2，但在实际问题中，它将有数百、数千或更多。输入的确切维度因问题而异，但它是一个点的直觉仍然存在。</p><p>输出<span class="math inline">\(y\)</span>也应被视为另一个高维空间中的一个点。在猫脑模型问题中，输出空间的维数为1，但在实际问题中，它会更高。然而，通常情况下，输出维数比输入维数小得多。</p><p>从几何学上讲，机器学习模型本质上是将特征空间中的一个点映射到输出空间中的一个点。模型在输出空间中执行的分类或估计工作比在特征空间中更容易。具体来说，对于分类工作，属于不同类别的输入点预计会映射到输出空间中的不同簇。</p><p>让我们继续使用猫脑模型示例来说明这个想法。如前所述，我们的特征空间是二维的，两个坐标轴<span class="math inline">\(X_0\)</span>表示硬度，<span class="math inline">\(X_1\)</span>表示锋利度。<sup>3</sup> 此二维空间中的各个点用小写的坐标值(<span class="math inline">\(x_0\)</span>,<span class="math inline">\(x_1\)</span>)表示（见图1.2）。如图所示，对威胁评分进行建模的一个好方法是测量与线<span class="math inline">\(x_0\)</span>+<span class="math inline">\(x_1\)</span>= 1 的距离。</p><p>从坐标几何学来看，在具有坐标轴 <span class="math inline">\(X_0\)</span> 和 <span class="math inline">\(X_1\)</span> 的二维空间中，点(a, b)与直线<span class="math inline">\(x_0\)</span>+<span class="math inline">\(x_1\)</span>= 1的有符号距离为<span class="math inline">\(y=\frac{a+b-1}{\sqrt{2}}\)</span>。通过检查<span class="math inline">\(y\)</span>的符号，我们可以确定输入点属于分隔线的哪一侧。在图1.2 所示的简单情况下，观察告诉我们，威胁分数可以用与对角线<span class="math inline">\(x_0\)</span>+<span class="math inline">\(x_1\)</span>−1 = 0 的有符号距离<span class="math inline">\(y\)</span>来表示。我们可以通过对 <span class="math inline">\(y\)</span> 进行阈值化来做出逃跑/忽略/接近的决定。接近零的值表示忽略，正值表示逃跑，负值表示接近并发出呼噜声。</p><img src="/2025/01/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E4%B8%89/figure1.2.jpg" class="" alt="图片"><p><strong>图1.2 猫脑模型的二维输入点空间。左下角显示的是硬度低且锋利度低的物体(-)，而右上角显示的是硬度高且锋利度高的物体(+)。中间值在对角线附近($)</strong></p><blockquote><p>第11页脚注：3 我们用<span class="math inline">\(X_0\)</span>和<span class="math inline">\(X_1\)</span>作为坐标符号，而不是我们更熟悉的X，Y，这样在进入高维空间时就不会出现符号耗尽的情况。</p></blockquote><p>从高中几何学中可知，任意输入点(<span class="math inline">\(x_0\)</span>= a,<span class="math inline">\(x_1\)</span>=$ b<span class="math inline">\()到直线\)</span>x_0<span class="math inline">\(+\)</span>x_1<span class="math inline">\(−1 = 0 的距离为\)</span><span class="math inline">\(因此，函数\)</span>y(x_0,x_1)=<span class="math inline">\(是猫脑威胁估计函数的一个可能模型。训练应收敛到\)</span>w_0=,w_1=和b=-$。 因此，我们简化的猫脑威胁评分模型为</p><p>​ <span class="math inline">\(y\left(x_0,x_1\right)=\frac1{\sqrt{2}}x_0+\frac1{\sqrt{2}}x_1-\frac1{\sqrt{2}}\)</span></p><p>它将表示猫前方物体硬度和锋利度的二维输入点，映射到与分隔线有符号距离对应的一维值。该距离在物理上可解释为威胁分数，可通过阈值划分类别（负面威胁、中性威胁、正面威胁），如公式1.2 所示。划分的类别在输出空间中形成不同的簇，在输出空间中用+、-和<span class="math inline">\(\mathbb{\$}\)</span>符号表示。输出值越低，表示负面威胁越确定（猫会靠近并发出呼噜声）：例如，<span class="math inline">\(y\left(0,0\right)=-\frac{1}{\sqrt{2}}\)</span>。输出值越高，表示威胁越大（猫会逃跑）：例如，<span class="math inline">\(y\left(1,1\right)=\frac{1}{\sqrt{2}}\)</span>。中等输入值产生的威胁接近于零（猫会忽略该物体）：例如，<span class="math inline">\(y (0.5,0.5)=0\)</span>。当然，因为问题非常简单，我们可以通过简单的观察得出模型参数。而在现实问题中，这是需要训练的。</p><p>几何视角在更高维度上也适用。一般来说，n维输入向量<span class="math inline">\(\vec{x}\)</span>被映射到m维输出向量（通常 m &lt; n），这样，问题在输出空间中就变得简单得多。图1.3显示了具有三维特征空间的示例。</p><h4 id="机器学习中的回归和分类">1.5 机器学习中的回归和分类</h4><p>如第1.1节简要概述的那样，机器学习模型有两种类型：回归器和分类器。</p><p>在回归器中，模型试图在给定特定输入的情况下输出期望值。例如，第1.3 节中猫脑模型的第一阶段（威胁分数估计器）就是回归器模型。</p><p>另一方面，分类器有一组预先指定的类。给定一个特定的输入，它们会尝试输出输入所属的类。例如，完整的猫脑模型有三个类：（1）逃跑，（2）忽略，（3）靠近并发出呼噜声。因此，它接受输入（硬度和锐度值）并给出输出决策（又称类）。</p><p>在此示例中，我们通过对回归器的输出进行阈值处理将回归器转换为分类器（参见公式1.2）。也可以创建直接输出类的模型，而无需中间的回归器。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是基于《深度学习中的数学》一书中的思想，旨在从本文起系列阐述深度学习技术背后的数学原理，给想要对深度学习更进一步了解的读者提供一个可以查阅的底层原理资料。本文共分为四个部分，此为第三部分。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习和深度学习概述(二)</title>
    <link href="http://yoursite.com/2024/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yoursite.com/2024/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</id>
    <published>2024-08-10T06:54:36.000Z</published>
    <updated>2024-12-31T07:01:55.250Z</updated>
    
    <content type="html"><![CDATA[<p>本文是基于《深度学习中的数学》一书中的思想，旨在从本文起系列阐述深度学习技术背后的数学原理，给想要对深度学习更进一步了解的读者提供一个可以查阅的底层原理资料。本文共分为四个部分，此为第二部分。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>机器学习的函数逼近视角</strong></li><li><strong>一个简单的机器学习模型：猫脑</strong></li></ul><h4 id="机器学习的函数逼近视角模型和训练">1.2 机器学习的函数逼近视角：模型和训练</h4><p>如第1.1 节所述，要创建一个能够进行分类或估计的类脑机器，我们必须找到一个数学函数（模型），将输入转换为对应的期望输出。然而，遗憾的是，在典型的现实生活中，我们不知道这个转换函数是什么。例如，我们并不知道能接受历史价格、新闻事件等特征并能估计出股票未来价格的函数——这就让我们建立股票价格估算器来致富变得很困难。我们拥有的只是训练数据——一组已知输出的输入。那么我们该怎样利用好它们来完成上面的任务呢？答案是，我们将尝试对这个未知函数进行建模。这意味着我们将创建一个函数作为那个未知函数的近似代理或替代品。从这个角度来看，机器学习只不过是函数近似——我们只是试图逼近那个未知的分类或估计函数。</p><p>让我们简要回顾一下上一节的主要思想。在机器学习中，我们试图解决的问题可以抽象地看作是将一组输入转换为输出。输出要么是一个类，要么是一个估计值。由于我们不知道真正的转换函数，我们试图提出一个模型函数。我们首先利用我们对问题的物理理解，设计一个具有可调参数值的模型函数，该模型函数可以作为真实函数的代理。这就是模型架构，可调参数也称为权重。最简单的模型架构是输出等于输入值的加权和。确定模型架构并不能完全确定模型——我们仍然需要确定实际的参数值（权重）。这就是训练的用武之地。在训练过程中，我们找到一组最佳权重，将该组权重应用到模型架构中确定一个模型，通过该模型将训练输入转换为模型输出，使模型输出尽可能接近训练输入在训练样本中对应的训练输出。训练完成后，我们部署好训练好的模型：它的权重已经确定，模型也因此已经确定，因此对于任何输入，它只需应用该模型并生成输出，这便是推理。当然，训练输入只是所有可能输入的一小部分，因此不能保证推理会在所有实际输入上产生所需的结果。模型的成功取决于所选模型架构的适当性以及训练数据的质量和数量。</p><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>获取训练数据<br/>掌握机器学习后，最大的困难就是获取训练数据。当从业者能够负担得起时，通常的做法是使用人工手动生成与训练数据输入相对应的输出（这些目标输出有时被称为基本事实）。这个过程被称为人工标记或人工管理，需要一大群人查看大量的训练数据输入并生成相应的基本事实输出。对于一些经过充分研究的问题，我们可能很幸运地能够在互联网上获得训练数据；否则它将成为一项艰巨的挑战。稍后会详细介绍。</th></tr></thead><tbody></tbody></table><p>现在我们通过一个具体的例子来研究一下模型构建的过程：参见图1.1所示的猫脑。</p><h4 id="一个简单的机器学习模型猫脑">1.3 一个简单的机器学习模型：猫脑</h4><p>为了简单和具体，我们将以一只假想的猫为例，它一生中只需要做出一个决定：是逃离面前的物体、忽略它，还是靠近并发出呼噜声。它仅根据与面前物体有关的两个定量输入来做出这一决定（如图1.1 所示）。注意：本章是对机器/深度学习的轻量级概述。因此，它依赖于我们稍后将介绍的一些数学概念。尽管如此，我们还是鼓励您现在阅读本章，并在消化关于向量和矩阵的章节后再回来重新复习本章。</p><h5 id="输入特征">1.31 输入特征</h5><p>输入特征为<span class="math inline">\(x_0\)</span>表示硬度和$ x_1<span class="math inline">\(表示锋利度。在不失一般性的情况下，我们可以对输入进行归一化。这是一个非常流行的技巧，即将介于最小可能值\)</span>v_{min}<span class="math inline">\(和最大可能值\)</span>v_{max}<span class="math inline">\(之间的输入值转换为0 到1 之间的值。要将任意输入值\)</span>v$转换为归一化值 <span class="math inline">\(v_{norm}\)</span>，我们使用公式</p><p>​ <span class="math inline">\(v_{\text {norm }}=\frac{\left(v-v_{\min }\right)}{\left(v_{\max }-v_{\min }\right)}\)</span> (1.1)</p><p>用数学术语来说，通过公式1.1 的变换，<span class="math inline">\(v\in[v_{min},v_{max}]\to v_{norm}\in [0,1]\)</span>将输入域<span class="math inline">\([v_{min},v_{max}]\)</span>中的值<span class="math inline">\(v\)</span>映射到范围为[0,1]的输出值<span class="math inline">\(v_{norm}\)</span>。 用一个二维向量<span class="math inline">\(\vec{x}=\begin{bmatrix}x_0\\x_1\end{bmatrix}\in[0,1]^2\)</span>简洁地表示单个输入实例。</p><h5 id="输出决策">1.3.2 输出决策</h5><p>本例是一个多分类任务，可以采用以下三个可能值之一：0，表示逃离猫面前的物体；1，表示忽略物体；2，表示靠近物体并发出呼噜声。在机器学习中，本例可以按分类任务直接计算类别。但是，在这个例子中，我们将让模型估计一个威胁分数。它被解释如下：威胁分数为较大的正数= 逃跑，威胁接近零= 忽略，威胁为较小的负数= 接近并发出呼噜声（威胁分数为较小的负数表明该物体对猫具有吸引力）。</p><p>我们可以根据威胁分数做出最终的决策（逃跑/忽略/接近），通过将威胁分数 y 与阈值𝛿进行比较，如下所示：</p><p><span class="math inline">\(y\left\{\begin{array}{l}&gt;\delta \rightarrow \text {高威胁,逃跑}\\ &gt;=-\delta \text { and }&lt;=\delta \rightarrow \text {威胁接近零,忽略}\\ &lt;-\delta \rightarrow \text {没有威胁,靠近并发出呼噜声}\end{array}\right.\)</span></p><h5 id="模型估计">1.3.3 模型估计</h5><p>现在到了最重要的一步：我们需要估计出一个函数用来将输入向量转换为输出。我们将用<span class="math inline">\(y\)</span>表示该函数的输出。用数学符号来表示的话，我们要估计的就是<span class="math inline">\(y(\vec{x})\)</span>。</p><p>当然，我们不知道理想的函数是什么。我们将尝试从训练数据中估计出这个未知函数，使其接近理想函数。这分为两个步骤：</p><p>1.模型架构选择——设计一个我们期望的参数化函数，它是未知理想函数的近似代理</p><p>2.训练——估计所选函数的参数，使得训练输入通过该函数的输出尽可能接近其对应的期望输出</p><h5 id="模型架构选择">1.3.4 模型架构选择</h5><p>这是各种机器学习方法之所以成为不同方法的关键步骤。在这个简单猫脑示例中，我们将使用最简单的模型。我们的模型有三个参数，<span class="math inline">\(w_0\)</span>、<span class="math inline">\(w_1\)</span>、<span class="math inline">\(b\)</span>。它们可以用一个二维向量紧凑地表示为<span class="math inline">\(w =\vec{w}=\left[\begin{array}{l}w_0 \\ w_1\end{array}\right]\in \mathbb{R}^2\)</span>和一个常数偏差<span class="math inline">\(b\)</span>∈ℝ（这里，ℝ表示所有实数的集合，<span class="math inline">\(ℝ_2\)</span>表示两个元素都是实数的二维向量的集合，依此类推）。这个模型可以输出威胁分数 y，计算如下$ y(x_0, x_1)=w_0 x_0+w_1 x_1+b=+b=^T +b$ (1.3)</p><p>请注意，<span class="math inline">\(b\)</span>是一个特殊的参数。它是一个常数，不会与任何输入相乘。在机器学习中，通常将其称为偏差；其他参数作为权重与输入相乘。</p><h5 id="模型训练">1.3.5 模型训练</h5><p>一旦选择了模型架构，我们就知道了确定的参数化函数，我们将使用该参数化函数来建模未知函数<span class="math inline">\(y(\vec{x})\)</span>，从而将输入转换为输出。我们在这里仍然需要估计函数的参数。现在，我们有一个具有未知参数的函数，并且这些参数将会从一组具有已知输出（训练数据）的输入中估计出来。我们最终将选择一组最优参数，使得训练数据的输入通过具有最优参数的模型后，产出的模型输出尽可能接近训练数据中的输出。</p><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>迭代训练<br/>这个问题已经被数学家研究过，在数学中被称为函数拟合问题。然而，随着机器学习的出现，其规模发生了变化。在机器学习中，我们处理的训练数据包括数以百万计的样本。这就需要解决方案的理念也随之改变。数学家使用闭式解作为解决方案，通过直接求解涉及所有训练数据项的方程来估计参数。在机器学习中，我们寻求迭代解决方案，一次处理几个训练数据项（或者可能只有一个）。在迭代解决方案中，没有必要将所有训练数据保存在计算机的内存中。我们只需一次加载一小部分并仅处理该部分。我们将以猫脑为例来说明这一点。</th></tr></thead><tbody></tbody></table><p>具体来说，训练过程的目标是估计参数<span class="math inline">\(w_0\)</span>、<span class="math inline">\(w_1\)</span>、<span class="math inline">\(b\)</span>，或者，根据公式1.3 估计向量<span class="math inline">\(\vec{w}\)</span>和常数<span class="math inline">\(b\)</span>，使得训练数据的输入<span class="math inline">\((x_0, x_1)\)</span>对应的输出<span class="math inline">\(y(x_0, x_1)\)</span>尽可能与相应的已知训练数据输出（又称基本事实[GT]）匹配。</p><p>假设训练数据由N +1个输入<span class="math inline">\(\vec{x}^{(0)},\vec{x}^{(1)},···\vec{x}^{(N)}\)</span>组成。这里，每个<span class="math inline">\(\vec{x}^{(i)}\)</span>都是一个2 ×1 向量，表示单个训练数据输入实例。其对应的威胁值（输出）为<span class="math inline">\(y_{g t}^{(0)}, y_{g t}^{(1)},··· y_{g t}^{(N)}\)</span>（这里，下标 gt 表示基本事实）。同样，我们可以说训练数据由 N +1 个(输入，输出)对组成：</p><p>​ <span class="math inline">\(\left(\vec{x}^{(0)}, y_{g t}^{(0)}\right),\left(\vec{x}^{(1)}, y_{g t}^{(1)}\right)\cdots\left(\vec{x}^{(N)}, y_{g t}^{(N)}\right)\)</span></p><p>假设<span class="math inline">\(\vec{w}\)</span>表示模型的（目前未知的）最佳参数。然后，给定任意输入<span class="math inline">\(\vec{x}\)</span>，机器将估计出威胁值$ y_{predicted}=<sup>T+b<span class="math inline">\(。在第 i 个训练数据对\)</span>(</sup>{(i)},y_{gt}^{(i)})$上，机器将给出估计</p><p>​ <span class="math inline">\(y_{\text {predicted }}^{(i)}=\vec{w}^T \vec{x}^{(i)}+b\)</span></p><p>而期望输出是<span class="math inline">\(y_{\text {gt}}^{(i)}\)</span>。因此，机器在第 i 个训练数据实例上产生的平方误差（又称损失）是 <span class="math inline">\(e_i^2=\left(y_{\text {predicted }}^{(i)}-y_{g t}^{(i)}\right)^2\)</span></p><p>整个训练数据集的总体损失是通过将每个单独的训练数据实例的损失相加而获得的：<span class="math inline">\(E^2=\sum_{i=0}^{i=N} e_i^2=\sum_{i=0}^{i=N}\left(y_{\text {predicted }}^{(i)}-y_{g t}^{(i)}\right)^2=\sum_{i=0}^{i=N}\left(\vec{w}^T \vec{x}_i+b-y_{g t}^{(i)}\right)^2\)</span></p><p>训练的目标是找到一组模型参数（又称权重）<span class="math inline">\(\vec{w}\)</span>，使总误差 E 最小化。具体如何做到这一点将在后面描述。</p><p>在大多数情况下，不可能得出最优<span class="math inline">\(\vec{w}\)</span>、b 的闭式解。因此，我们采用算法1.1 中描述的迭代方法。</p><blockquote><p>第9页脚注：2 在这种情况下，请注意，将误差/损失做平方，以使其与符号无关是一种常见做法。如果我们希望输出为10，那么如果输出为9.5 或10.5，我们会同样高兴/不高兴。因此，+5 或−5 的误差实际上是相同的；因此我们要使误差与符号无关。</p></blockquote><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>算法1.1 训练一个监督模型</th></tr></thead><tbody><tr class="odd"><td>用随机值初始化参数 w,b，当误差不够小时进行迭代<br><span class="math inline">\(\mathbf{while}\quad(E^2=\sum_{i=0}^{i=N}\left(\vec{w}^T\vec{x}_i+b-y_{gt}^{(i)}\right)^2&gt;threshold)\quad\mathbf{do}\)</span><br> 迭代所有训练数据实例 <br/> <span class="math inline">\(\text{for }\forall i\in[0,N]\quad\mathbf{do}\)</span><br/> 第3.3 节提供了详细信息，引入梯度后，调整<span class="math inline">\(\vec{w}\)</span>，b 以减少<span class="math inline">\(E^2\)</span><br/> <span class="math inline">\(\mathbf{end}\ \mathbf{for}\)</span><br/><span class="math inline">\(\mathbf{end}\ \mathbf{while}\)</span><br/>记住最终参数值为最优<br/><span class="math inline">\(\vec{w}_*\leftarrow\vec{w},\ b_*\leftarrow b\)</span></td></tr></tbody></table><p>在这个算法中，我们从随机参数值开始，并不断调整参数，这样总误差至少会下降一点。我们一直这样做，直到误差变得足够小。从纯粹的数学意义上讲，我们继续迭代，直到误差最小。但在实践中，我们经常在结果对于要解决的问题足够准确时停止。值得再次强调的是，这里的误差仅指训练数据上的误差。</p><h5 id="推理">1.3.6 推理</h5><p>最后，一个经过训练的模型（具有最优参数<span class="math inline">\(\vec{w}_∗\)</span><span class="math inline">\(b_∗\)</span>）被部署到现实世界中。它将接收新的输入<span class="math inline">\(\vec{x}\)</span>并推断出 <span class="math inline">\(y_{predicted}\left(\vec{x}\right)=\vec{w}_{*}^{T}\vec{x}+b_{*}\)</span>.分类将通过对<span class="math inline">\(y_{predicted}\)</span>进行阈值处理来实现，如公式1.2 所示。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是基于《深度学习中的数学》一书中的思想，旨在从本文起系列阐述深度学习技术背后的数学原理，给想要对深度学习更进一步了解的读者提供一个可以查阅的底层原理资料。本文共分为四个部分，此为第二部分。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习和深度学习概述(一)</title>
    <link href="http://yoursite.com/2024/07/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E4%B8%80/"/>
    <id>http://yoursite.com/2024/07/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E4%B8%80/</id>
    <published>2024-07-10T06:54:36.000Z</published>
    <updated>2024-12-31T08:07:08.182Z</updated>
    
    <content type="html"><![CDATA[<p>本文是基于《深度学习中的数学》一书中的思想，旨在从本文起系列阐述深度学习技术背后的数学原理，给想要对深度学习更进一步了解的读者提供一个可以查阅的底层原理资料。本文共分为四个部分，此为第一部分。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>机器学习/深度学习初探</strong></li><li><strong>计算范式转变</strong></li></ul><p>深度学习已经彻底改变了计算机视觉，尤其是自然语言处理和语音处理，进而改变了整个人工智能领域。人工智能已经从无法令人满意地解决实际问题的浅层技巧，转变成了可以大规模解决行业面临的实际问题的强大工具。这无异于是一场发生在我们眼皮底下的革命。要引领这场革命潮流，不仅仅是简单地记住一些入门指南上的”操作”步骤，还要理解其基本原理和抽象概念。这些至关重要的环节正是数学发挥作用的地方。</p><p>在第一章中，我们概述了深度学习。这将要求我们使用后续章节中解释的一些概念。如果本章末尾有一些未解决的问题，请不要担心：它只是旨在引导您的思维先转到我们的主题上来。随着后续章节中各个概念变得更加清晰，您可以考虑回过头来重新阅读本章。</p><h4 id="机器学习深度学习初探计算范式转变"><strong>1.1 机器学习/深度学习初探：计算范式转变</strong></h4><p>做出决定和/或预测是生活的一个核心诉求。这样做在本质上涉及到接收一组感官或知识输入并对其进行处理以生成决策或估计。</p><p>例如，猫的大脑经常试图在以下选项之间进行选择：逃离它面前的物体，忽略它面前的物体，接近它面前的物体并发出呼噜声。猫的大脑通过处理感官输入来做出决定，例如感知到的它面前物体的硬度、感知到的它面前物体的锋利度等。这是一个分类问题的例子，其输出是一组可能的类别之一。</p><p>生活中的分类问题还有如下的一些其他例子：</p><ul><li><p>根据股票价格历史和近期股票价格变化等输入，判断买入、持有还是卖出某只股票</p></li><li><p>物体识别（图像）： –这是汽车还是长颈鹿？ –这是人类还是非人类？ –这是无生命物体还是生物？ –人脸识别——这是汤姆、迪克、玛丽、爱因斯坦还是梅西？</p></li><li><p>视频中的动作识别： –这个人是在跑步还是没跑步？ –这个人是在捡东西还是没捡东西？ –这个人是在做暴力的事情还是没做暴力的事情？</p></li><li><p>数字文档中的自然语言处理(NLP)： –这篇新闻文章属于政治还是体育领域？ –这个查询短语是否与档案中的特定文章匹配？</p></li></ul><p>有时生活需要定量估计而不是分类。狮子的大脑需要通过处理猎物的速度和与猎物的距离等输入信息来估计要跳多远才能落在猎物身上。定量估计的另一个例子是根据房主的当前收入、街区的犯罪统计数据等输入信息来估计房价。这种定量估计的工具称为回归器。</p><p>以下是日常生活中需要定量估计的其他一些例子：</p><ul><li>从图像中进行物体定位：识别物体位置的矩形边界</li><li>根据历史股价和其他新闻事件进行股价预测</li><li>一对文档之间的相似度得分</li></ul><p>有时，分类输出可以从定量估计中生成。例如，前面描述的猫脑可以结合输入（硬度、锋利度等）来生成定量威胁分数。如果威胁分数很高，猫就会逃跑。如果威胁分数接近零，猫就会忽略它面前的物体。如果威胁分数为负，猫就会接近物体并发出呼噜声。 图1.1 显示了许多这样的示例。在每个实例中，机器（即大脑）将感官或知识输入转化为决策或定量估计。机器学习的目标是模拟该机器。</p><img src="/2024/07/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E4%B8%80/figure1.jpg" class="" alt="图片"><p>​</p><p><strong>Figure1.1 生活中的决策定量估计模型</strong></p><p>​ 请注意，机器学习还有很长的路要走才能赶上人脑。人脑可以独自处理数千甚至数百万个这样的问题。另一方面，在目前的发展状态下，机器学习几乎无法创建一台能够做出所有决策和估计的通用型机器。我们目前主要是试图分别制造单个的机器来针对性解决单个任务（例如选股器或汽车识别器）。此时，您可能会问：“等等，将输入转换为输出——这不正是计算机在过去30 多年里一直在做的事情吗？这里提到的范式转换是什么？”答案是，范式转换就是，我们没有向机器提供分步指令集（即程序）来将输入转换为输出。相反，我们是为该问题开发了一个数学模型。</p><p>​ 让我们用一个例子来说明这个想法。为了简单和具体，我们将考虑一个假设的猫脑，它在生活中只需要做出一个决定：是逃离它面前的物体，还是忽略物体，还是走近并发出呼噜声。这个决定就是我们将要讨论的模型的输出。在这个示例中，决定仅基于两个定量输入（又称特征）：即感知到的物体的硬度和锋利度（如图1.1 所示）。我们不会通过提供分步指令来实现这一点，例如“如果锐度大于某个阈值，则逃跑”。相反，我们会尝试确定一个参数化函数，该函数接受输入并将其转换为所需的决策或估计值。而最简单的此类函数就是输入的加权和：</p><p>​ <em>y (hardness, sharpness</em>)= <em>w</em><sub>0</sub> ×<em>hardness</em>+<em>w</em><sub>1</sub>×<em>sharpness</em>+ <em>b</em></p><p>权重<em>w</em><sub>0</sub>、<em>w</em><sub>1</sub> 和偏差<em>b</em>是函数的参数。输出<em>y</em>可以解释为威胁分数。如果威胁分数超过阈值，猫就会逃跑。如果接近0，猫就会忽略该物体。如果威胁分数为负，猫就会靠近并发出呼噜声。对于更复杂的任务，我们将使用更复杂的函数。请注意，权重最初是未知的；我们需要估计它们。这是通过称为模型训练的过程完成的。</p><p>​ 总体而言，通过机器学习解决问题有以下几个阶段：</p><ul><li>我们设计一个具有未知参数（权重）的参数化模型函数（例如加权和）。这构成了模型架构。选择正确的模型架构是机器学习工程师的专业知识发挥作用的地方。</li><li>然后我们通过模型训练估计权重。</li><li>一旦估计出权重，我们就有了一个完整的模型。这个模型可以接受以前不一定见过的任意输入并生成输出。利用训练好的模型处理任意真实输入并产生输出的过程称为推理。</li></ul><p>这个被称为监督学习的过程是最常用的机器学习种类。在这里，我们在开始训练之前要准备好训练数据。训练数据包括示例输入项，每个输入项都有其对应的期望输出。训练数据通常是手动创建的：人工检查每一个输入项并标注好期望输出（又称目标输出）。这通常是机器学习中最艰巨繁琐的部分。</p><p>例如，在我们假设的猫脑示例中，一些可能的训练数据样本如下</p><blockquote><p>第4页脚注: 1 如果你有机器学习的经验，你就会意识到我们这里讨论的是“监督”学习。另外还有一种机器学习方式不需要已知输出，即所谓的“无监督”学习，我们稍后会讨论这种方式。</p></blockquote><p>输入：（硬度=0.01，锋利度=0.02）→威胁=-0.90 →决策：“靠近并发出呼噜声“ 输入：（硬度=0.50，锋利度=0.60）→威胁=-0.01 →决策：“忽略“ 输入：（硬度=0.99，锋利度=0.97）→威胁=0.90 →决策：“逃跑“</p><p>其中硬度和锋利度的输入值假设介于0 和1 之间。</p><p>训练过程中究竟发生了什么？答案：我们迭代处理输入的训练数据样本。对于每个输入项，我们都有期望的（又称目标）输出结果。在每次迭代中，我们都会调整模型权重值，使得模型函数对该特定输入项的输出尽可能地更接近其对应的目标输出。例如，假设在给定的迭代中，权重值为<span class="math inline">\(w_0\)</span>= 20 和<span class="math inline">\(w_1\)</span>= 10，<span class="math inline">\(b\)</span>= 50。在输入（硬度= 0.01，锐度= 0.02）中，我们得到输出威胁分数<span class="math inline">\(y\)</span>= 50.3，这与我们期望的 y = −0.9 有很大不同。我们将调整权重：例如，减少偏差，使<span class="math inline">\(w_0\)</span>= 20、<span class="math inline">\(w_1\)</span>= 10 和$ b<span class="math inline">\(= 40。那么相应的威胁分数\)</span> y$= 40.3 仍然远未达到期望值，但已经更接近了。在我们对许多训练数据样本执行此操作后，权重将开始接近其理想值。请注意，如何识别对权重值的调整不在此处讨论；它需要更深层次的数学知识，稍后将进行讨论。</p><p>如前所述，这种迭代调整权重的过程称为训练或学习。在学习开始时，权重具有随机值，因此机器输出通常与期望输出不匹配。但随着时间的推移，更多的训练迭代发生，机器“学会”了如何生成我们期望的输出。这时模型就可以在现实世界中部署了。给定任意输入，模型将在推理过程中产出更接近人们想要的结果。</p><p>仔细想想，这可能就是活体大脑的工作方式。它们包含各种任务的数学模型的等价物。在这里，权重是大脑中不同神经元之间连接（又称突触）的强度。一开始，参数未调整；大脑反复犯错。例如，婴儿的大脑经常在识别可食用物体时犯错误——任何有过孩子的人都能明白我们在说什么。但每个大脑都会调整参数（吃带有$符号的绿色和白色矩形物体会招致很多责骂-以后不应该吃它们，等等）。最终，这台大脑机器会调整好参数以产生更好的结果。</p><p>这里应该注意一个微妙的点。在训练过程中，机器会调整其参数，以便仅根据训练数据输入产生所需的结果。当然，在训练过程中，它只看到所有可能输入的一小部分——我们不会构建从已知输入到已知输出的查找表。因此，当这台机器在真实世界发布时，它主要运行在从未见过的输入数据上。我们用什么来保证它会在从未见过的数据上产生期望的结果？坦率地说，没有任何保证。只是，在大多数现实生活的问题中，输入并不是真正随机的。它们会有一个模式。我们希望机器在训练期间能看到足够多的数据来捕捉这种模式。这样它在没有见过的输入上的输出将会接近所需的值。训练数据的分布越接近现实生活，就越有可能实现。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是基于《深度学习中的数学》一书中的思想，旨在从本文起系列阐述深度学习技术背后的数学原理，给想要对深度学习更进一步了解的读者提供一个可以查阅的底层原理资料。本文共分为四个部分，此为第一部分。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>基于 LangChain 构建智能客服 AI Agent 案例实践</title>
    <link href="http://yoursite.com/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/"/>
    <id>http://yoursite.com/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/</id>
    <published>2024-05-10T06:54:36.000Z</published>
    <updated>2024-06-18T06:59:35.509Z</updated>
    
    <content type="html"><![CDATA[<p>本文是基于上篇LangChain应用开发框架学习路径, 构建智能客服AI Agent 案例。通过该案例实践，引发进一步的思考并最终总结出开发AI Agent必备技能。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><p><strong>基于 LangChain 构建智能客服 AI Agent 案例实践</strong></p></li><li><p><strong>基于 AI Agent 案例实践几个思考</strong></p></li><li><p><strong>开发 Agent 必备技能</strong></p></li></ul><h3 id="基于-langchain-构建智能客服-ai-agent-案例实践"><strong>基于 LangChain 构建智能客服 AI Agent 案例实践</strong></h3><hr /><p><strong>AI Agent 是什么？</strong></p><p>LLM + Planning + Memory + Tools +Action</p><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618121434109.png" class="" alt="图片"><p><strong>LangChain 实现智能客服Agent架构设计</strong></p><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618121509608.png" class="" alt="图片"><p><strong>LangChain 实现智能客服Agent架构设计</strong></p><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618121612215.png" class="" alt="图片"><p><strong>LangChain 实现智能客服Agent核心代码</strong></p><ul><li><p><strong>大语言模型配置</strong></p></li><li><p><strong>工具列表注册</strong></p></li><li><p><strong>Agent 创建</strong></p></li><li><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618121712931.png" class="" alt="图片"></li></ul><p><strong>Agent 执行步骤一：模型做出规划</strong></p><ul><li><strong>Planning</strong></li></ul><p>​ l <strong>第一步：获取商品售价</strong></p><p>​ l <strong>第二部：获取商品优惠信息</strong></p><p>​ l <strong>第三步：计算最终售价</strong></p><ul><li><strong>Thought</strong></li></ul><p>​ l <strong>需要获得商品售价</strong></p><ul><li><strong>Action</strong></li></ul><p>​ l <strong>行动：商品价格查询工具</strong></p><p>​ l <strong>输入：商品ID</strong></p><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618121858903.png" class="" alt="图片"><p><strong>Agent 执行步骤二：调用”商品价格查询工具“</strong></p><ul><li><p><strong>调用查询商品价格工具</strong></p></li><li><p><strong>返回：7980</strong></p></li><li><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618122000320.png" class="" alt="图片"></li></ul><p><strong>Agent 执行步骤三：模型观察结果后思考决定下一步行动</strong></p><ul><li><strong>会话上下文</strong></li></ul><p>​ l <strong>① 原始问题</strong></p><p>​ l <strong>② 语言模型的规划和第一步行动</strong></p><ul><li><strong>Obversation</strong></li></ul><p>​ l <strong>③ 商品售价</strong></p><ul><li><strong>Thought</strong></li></ul><p>​ l <strong>需要获取商品优惠信息</strong></p><ul><li><strong>Action</strong></li></ul><p>​ l <strong>行动：商品优惠信息查询工具</strong></p><p>​ l <strong>输入：商品ID</strong></p><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618124008453.png" class="" alt="图片"><p><strong>Agent 执行步骤四：调用”商品优惠信息查询工具“</strong></p><ul><li><p><strong>调用查询商品优惠信息”工具”</strong></p></li><li><p><strong>返回：“折扣信息：0.85”</strong></p></li><li><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618124109949.png" class="" alt="图片"><p><strong>Agent 执行步骤五：模型观察结果后思考决定下一步行动</strong></p><ul><li><strong>会话上下文</strong></li></ul><p>​ l <strong>① 原始问题</strong></p><p>​ l <strong>② 历史执行步骤</strong></p><ul><li><strong>Obversation</strong></li></ul><p>​ l <strong>③ 优惠信息</strong></p><ul><li><strong>Thought</strong></li></ul><p>​ l <strong>需要计算商品最低售价</strong></p><ul><li><strong>Action</strong></li></ul><p>​ l <strong>行动：计算器工具</strong></p><p>​ l <strong>输入：算式</strong></p><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618124255394.png" class=""></li></ul><p><strong>Agent 执行步骤六：调用”计算器工具“</strong></p><ul><li><p><strong>调用计算器”工具”</strong></p></li><li><p><strong>返回：6783</strong></p><img src="/2024/05/10/%E5%9F%BA%E4%BA%8E-LangChain-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-AI-Agent-%E6%A1%88%E4%BE%8B%E5%AE%9E%E8%B7%B5/image-20240618124356633.png" class="" alt="图片"></li></ul><p><strong>Agent 执行步骤七：得到最终结果任务执行结束</strong></p><ul><li><strong>会话上下文</strong></li></ul><p>​ l <strong>① 原始问题</strong></p><p>​ l <strong>② 历史执行步骤</strong></p><ul><li><strong>Obversation</strong></li></ul><p>​ l <strong>③ 最终售价计算结果</strong></p><ul><li><strong>Thought</strong></li></ul><p>​ l <strong>得到商品的最低售价，任务结束</strong></p><ul><li><strong>Action</strong></li></ul><p>​ l <strong>行动：Final Answer</strong></p><p>​ l <strong>输入：任务最终结果</strong></p><h3 id="基于-ai-agent-案例实践几个思考"><strong>基于 AI Agent 案例实践几个思考</strong></h3><hr /><ul><li><p><strong>Token 超出如何解决</strong></p></li><li><p><strong>语言模型推理结果解析失败</strong></p></li><li><p><strong>系统吞吐量如何保证</strong></p></li><li><p><strong>系统运行成本</strong></p></li><li><p><strong>智能客服回答问题质量</strong></p></li></ul><h3 id="开发-agent-必备技能"><strong>开发 Agent 必备技能</strong></h3><hr /><p><strong>开发 Agent 必备技能</strong></p><ul><li><strong>LLM交互</strong></li></ul><p>​ l <strong>开发框架—LangChain</strong></p><p>​ l <strong>Function_calling</strong></p><p>​ l <strong>Prompt Engneering</strong></p><ul><li><strong>Fine-tuning</strong></li></ul><p>​ l <strong>使模型具备领域知识</strong></p><p>​ l <strong>LoRA、Prefix-tuning</strong></p><ul><li><strong>向量数据库</strong></li></ul><p>l <strong>非结构化数据存储</strong></p><p>​ l <strong>语言相似度检索</strong></p><p>​ l <strong>RAG</strong></p><ul><li><strong>架构设计能力</strong></li></ul><p>​ l <strong>系统高可用设计</strong></p><p>​ l <strong>系统高扩展设计</strong></p><ul><li><strong>系统调优</strong></li></ul><p>​ l <strong>LLM 性能调优</strong></p><p>​ l <strong>向量数据库索引调优</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是基于上篇LangChain应用开发框架学习路径, 构建智能客服AI Agent 案例。通过该案例实践，引发进一步的思考并最终总结出开发AI Agent必备技能。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>LangChain开发框架学习路径</title>
    <link href="http://yoursite.com/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/"/>
    <id>http://yoursite.com/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/</id>
    <published>2024-04-26T06:45:12.000Z</published>
    <updated>2024-06-18T07:23:50.758Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对LangChain应用开发框架的总体架构和关键技术的解读。以大纲的形式，辅以图形展示出LangChain开发框架的主要技术学习路径，做为初始接触该技术的学习者的入门指南。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li><strong>LangChain 总体架构深度剖析</strong></li><li><strong>LangChain 核心模块关键技术解读</strong></li><li><strong>基于 LangChain 构建智能客服 AI Agent 案例实践</strong></li></ul><h3 id="langchain-总体架构深度剖析"><strong>LangChain 总体架构深度剖析</strong></h3><hr /><p>LangChian是将 LLM 模型、向量数据库、交互层 Prompt、外部知识、外部工具整合到一起，进而可以自由构建 LLM 应用的应用开发框架。</p><p><strong>为什么需要 LangChain？</strong></p><ul><li><p>提供了RAG过程中的所需模块的支持</p></li><li><p>帮助开发者快速开发LLM应用</p></li><li><p>Model I/O、 Retrieval、Chains、 Memory、Agents、Callbacks</p></li></ul><p><strong>LangChain 整体组成部分</strong></p><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618112519688.png" class="" title="This is an test image"><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618112519688.png" class="" alt="图片"><ul><li><strong>LangSmith</strong></li></ul><p>​ l <strong>LLMOPS 平台</strong></p><ul><li><strong>LangServe</strong></li></ul><p>​ l <strong>快速将应用部署为 REST API 的服务</strong></p><ul><li><strong>Templates</strong></li></ul><p>​ l <strong>Langchain 的应用模版</strong></p><p><strong>LangChain 整体架构剖析</strong></p><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618112809604.png" class="" alt="图片"><ul><li><p><strong>模块更加独立</strong></p></li><li><p><strong>职责更加明确</strong></p></li><li><p><strong>保证核心部分的稳定性</strong></p></li><li><p><strong>减少外部依赖</strong></p></li><li><p><strong>维护更为容易</strong></p></li></ul><h3 id="langchain-核心模块关键技术解读"><strong>LangChain 核心模块关键技术解读</strong></h3><hr /><p><strong>LangChain 关键技术之—Retrieval</strong></p><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618113123519.png" class="" alt="图片"><ul><li><strong>文档加载器（Document loaders）</strong></li></ul><p>​ l <strong>csv、html、json、md、PDF文件读取</strong></p><p>​ l <strong>转化为document格式</strong></p><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618113218406.png" class="" alt="图片"><ul><li><strong>文档转换器（Document transformers）</strong></li></ul><p>​ l <strong>将文档数据结构化/分块(Text Splitter</strong>)</p><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618113330215.png" class="" alt="图片"><ul><li><strong>文档转换器（Document transformers)</strong></li></ul><p>​ l <strong>自定义字符</strong></p><p>​ l <strong>基于句子</strong></p><p>​ l <strong>基于语义</strong></p><ul><li><strong>文本嵌入模型（Embed）</strong></li></ul><p>​ l <strong>将文档向量化</strong></p><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618113624028.png" class="" alt="图片"><ul><li><strong>文本嵌入模型（Embed）</strong></li></ul><p>​ l <strong>将文档向量化</strong></p><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618113733790.png" class="" alt="图片"><ul><li><p><strong>向量存储&amp;检索（Vector stores）</strong></p></li><li><img src="/2024/04/26/LangChain%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/image-20240618113857413.png" class="" alt="图片"><ul><li><strong>MultiQueryRetriever</strong></li></ul><p>​ l <strong>使用 LLM 从不同角度为给定的查询生成多个查询</strong></p><ul><li><strong>上下文压缩</strong></li></ul><p>​ l <strong>将检索结果进行压缩缩率</strong></p><ul><li><strong>MultiVector Retriever</strong></li></ul><p>l <strong>分块/摘要/文档加假设问题</strong></p><ul><li><strong>Time-weighted vector store retriever</strong></li></ul><p>​ l <strong>语义相似性 + 时间衰减</strong></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是对LangChain应用开发框架的总体架构和关键技术的解读。以大纲的形式，辅以图形展示出LangChain开发框架的主要技术学习路径，做为初始接触该技术的学习者的入门指南。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Paper reading: Gemma: Open Models Based on Gemini Research and Technology</title>
    <link href="http://yoursite.com/2024/03/19/Paper-reading-Gemma-Open-Models-Based-on-GeminiResearch-and-Technology/"/>
    <id>http://yoursite.com/2024/03/19/Paper-reading-Gemma-Open-Models-Based-on-GeminiResearch-and-Technology/</id>
    <published>2024-03-19T05:16:23.000Z</published>
    <updated>2024-06-19T05:21:19.675Z</updated>
    
    <content type="html"><![CDATA[<p>Google DeepMind has released Gemma, a series of open models inspired by the same research and technology used for Gemini. This article summarized the main parts of paper Gemma: Open Models Based on Gemini Research and Technology and shown the basic way for running this model on local devices. Then give a conclusion on this model.</p><a id="more"></a><p><strong>Main Contents</strong>：</p><ul><li><strong>First Impression on Gemma</strong></li><li><strong>Model Architecture</strong></li><li><strong>Training Data</strong></li><li><strong>Performance on Public Test Data</strong></li><li><strong>Running Gemma 2B and 7B</strong></li><li><strong>Conclusion</strong></li></ul><h3 id="first-impression-on-gemma"><strong>First Impression on Gemma</strong></h3><hr /><img src="/2024/03/19/Paper-reading-Gemma-Open-Models-Based-on-GeminiResearch-and-Technology/image-20240619112105533.png" class="" alt="image-20240619112105533"><p>Google DeepMind has released Gemma, a series of open models inspired by the same research and technology used for Gemini. The open model lends itself to a variety of use cases, which is a very smart move by Google. There are 2B (trained on 2T tokens) and 7B (trained on 6T tokens) models, including base and instruction-tuned versions. Training is performed on a context length of 8192 tokens. Commercial use permitted. These are not multimodal models and are superior to Llama 2 7B and Mistral 7B based on reported experimental results.</p><p>Gemma models improve performance in a wide range of domains including conversation, reasoning, mathematics, and code generation. The results of MMLU (64.3%) and MBPP (44.4%) not only demonstrate the high performance of Gemma, but also show that there is still room for improvement in the performance of open and available large models.</p><p>Gemma draws on many experiences from the Gemini model project, including code, data, architecture, instruction tuning, reinforcement learning from human feedback, and evaluation.</p><h3 id="model-architecture"><strong>Model Architecture</strong></h3><hr /><p>The Gemma model architecture is a transformer-based decoder. The core parameters of the architecture are summarized in Table 1 below. The model is trained on a context length of 8192 tokens. We also take advantage of several improvements proposed since the original transformer paper. Below we list the included improvements:</p><p>Multi-Query Attention: The 7B model uses multi-query attention, while the 2B checkpoint uses multi-query attention (num_kv_heads=1). Based on the ablation study results, the respective attention variants are at their respective scales Improved performance.</p><p>RoPE Embeddings: Instead of using absolute position embeddings, rotational position embeddings are used in each layer; in order to reduce model size, embeddings are also shared between input and output.</p><p>GeGLU Activations: The standard ReLU nonlinearity is replaced by the GeGLU activation function.</p><p>Normalizer Location: Normalizes both the input and output of each transformer sublayer, deviating from the standard practice of normalizing only one of them. Use RMSNorm as the normalization layer.</p><img src="/2024/03/19/Paper-reading-Gemma-Open-Models-Based-on-GeminiResearch-and-Technology/image-20240619112628921.png" class="" alt="image-20240619112628921"><h3 id="training-data"><strong>Training Data</strong></h3><hr /><p>Gemma2B and 7B are trained on 2T and 6T of main English web document, mathematics and code data respectively. Unlike Gemini, these models are neither multimodal nor trained for optimal performance on multilingual tasks. For compatibility, a subset of the Gemini SentencePiece tokenizer is used. It splits numbers without removing extra whitespace, and relies on byte-level encoding to handle unknown tokens, following techniques used by (Chowdhery et al., 2022) and (Gemini Team, 2023). The vocabulary size is 256k tokens.</p><p>Since the vocabulary is very large, the model needs to be trained longer to better learn embeddings for all tokens in the vocabulary. The loss should still decrease after expanding the training tokens, which also corresponds to the very large vocabulary. We can understand that the larger the vocabulary, the more training tokens may be needed, and of course the performance may be better.</p><p>For the instruction version of the model, they performed supervised fine-tuning on an instruction dataset consisting of human and synthetic data, followed by reinforcement learning with human feedback (RLHF).</p><img src="/2024/03/19/Paper-reading-Gemma-Open-Models-Based-on-GeminiResearch-and-Technology/image-20240619125626270.png" class="" alt="image-20240619125626270"><h3 id="performance-on-public-test-data"><strong>Performance on public test data</strong></h3><hr /><img src="/2024/03/19/Paper-reading-Gemma-Open-Models-Based-on-GeminiResearch-and-Technology/image-20240619130028360.png" class="" alt="image-20240619130028360"><h3 id="running-gemma-2b-and-7b"><strong>Running Gemma 2B and 7B</strong></h3><hr /><p>Hugging Face's Transformers and vLLM already support the Gemma model, and the hardware requirement is an 18gb GPU.</p><p>Let’s first introduce vLLM</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> <span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"> prompts = [</span><br><span class="line">     <span class="string">"The best recipe for pasta is"</span></span><br><span class="line"> ]</span><br><span class="line"> sampling_params = SamplingParams(temperature=<span class="number">0.7</span>, top_p=<span class="number">0.8</span>, top_k=<span class="number">20</span>, max_tokens=<span class="number">150</span>)</span><br><span class="line"> loading_start = time.time()</span><br><span class="line"> llm = LLM(model=<span class="string">"google/gemma-7b"</span>)</span><br><span class="line"> print(<span class="string">"--- Loading time: %s seconds ---"</span> % (time.time() - loading_start))</span><br><span class="line"> generation_time = time.time()</span><br><span class="line"> outputs = llm.generate(prompts, sampling_params)</span><br><span class="line"> print(<span class="string">"--- Generation time: %s seconds ---"</span> % (time.time() - generation_time))</span><br><span class="line"> <span class="keyword">for</span> output <span class="keyword">in</span> outputs:</span><br><span class="line">     generated_text = output.outputs[<span class="number">0</span>].text</span><br><span class="line">     print(generated_text)</span><br><span class="line">     print(<span class="string">'------'</span>)</span><br></pre></td></tr></table></figure><p>Transformers then</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"> <span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM, set_seed</span><br><span class="line"> set_seed(<span class="number">1234</span>)  <span class="comment"># For reproducibility</span></span><br><span class="line"> prompt = <span class="string">"The best recipe for pasta is"</span></span><br><span class="line"> checkpoint = <span class="string">"google/gemma-7b"</span></span><br><span class="line"> tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span><br><span class="line"> model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.float16, device_map=<span class="string">"cuda"</span>)</span><br><span class="line"> inputs = tokenizer(prompt, return_tensors=<span class="string">"pt"</span>).to(<span class="string">'cuda'</span>)</span><br><span class="line"> outputs = model.generate(**inputs, do_sample=<span class="literal">True</span>, max_new_tokens=<span class="number">150</span>)</span><br><span class="line"> result = tokenizer.decode(outputs[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line"> print(result)</span><br></pre></td></tr></table></figure><h3 id="conclusion"><strong>Conclusion</strong></h3><hr /><p>Many frameworks already support Gemma models well, and quantization of GPTQ and AWQ will be released soon. After quantization, Gemma 7B can be used on 8gb GPU.</p><p>It is undeniable that releasing the Gemma model is a step forward for Google. Gemma 7B looks like a good competitor to Mistral 7B, but let's not forget that it also has 1 billion more parameters than Mistral 7B. In addition, I have never figured out what the use cases of Gemma 2B are. Its performance is surpassed by other models of similar size (this 2B may be really 2B), and it can be seen that the performance of these two Google models with few parameters is not good, but the performance is good. There are many more parameters. This kind of word play shows that Google is indeed lagging behind and anxious on the AI track, and there is currently no way to surpass it.</p><p>Here is the gemma-report officially released by Google. If you are interested, you can check it out.</p><p>https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Google DeepMind has released Gemma, a series of open models inspired by the same research and technology used for Gemini. This article summarized the main parts of paper Gemma: Open Models Based on Gemini Research and Technology and shown the basic way for running this model on local devices. Then give a conclusion on this model.&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2023年大模型研究现状综述</title>
    <link href="http://yoursite.com/2024/01/19/2023%E5%B9%B4%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E7%BB%BC%E8%BF%B0/"/>
    <id>http://yoursite.com/2024/01/19/2023%E5%B9%B4%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E7%BB%BC%E8%BF%B0/</id>
    <published>2024-01-19T11:30:38.000Z</published>
    <updated>2024-06-19T12:04:03.263Z</updated>
    
    <content type="html"><![CDATA[<p>This article reviews the current status of large model research in 2023. It summarizes the various stages of large model development this year and the contributions of major research institutions to large model research. It also summarizes and summarizes the current mainstream types of large models. On this basis, some thoughts and prospects about the future development of large-model technology were made.</p><a id="more"></a><p>The main contents of this article include:：</p><ul><li><p>Current status of basic model research</p></li><li><p>Introduction to LLM model types</p></li><li><p>Summary and future directions</p></li></ul><h2 id="current-status-of-basic-model-research">Current status of basic model research</h2><hr /><p>In 2023, with the development of LLM technology, the open source models of Chinese model research institutions will usher in explosive growth:</p><ul><li><p>In March 2023, Zhipu AI first released the ChatGLM-6B series in the Magic Community. ChatGLM-6B is an open source dialogue language model that supports Chinese and English bilingual question and answer. It is based on the General Language Model (GLM) architecture and has 62 billion parameters. Combined with model quantization technology, users can deploy it locally on consumer-grade graphics cards (a minimum of 6GB of video memory is required at the INT4 quantization level). Now, Zhipu AI's ChatGLM-6B has been updated to the third generation. At the same time, it has launched the CogVLM series in multi-modal mode, as well as CogVLM that supports visual agents, and launched the CodeGeex series models in the code field, while exploring both agent and math. and open source models and technologies.</p></li><li><p>In June 2023, Baichuan first released the Baichuan-7B model in the Moda community. baichuan-7B is an open source large-scale pre-training model developed by Baichuan Intelligence. Based on the Transformer structure, the 7 billion parameter model is trained on approximately 1.2 trillion tokens, supports Chinese and English bilinguals, and has a context window length of 4096. Baichuan is also one of the first companies to launch pre-trained models, and jokingly claims to provide developers with better “rough houses” so that developers can better “decorate” them, thus promoting the development of domestic pre-trained base models. Subsequently, Baichuan released the 13B model and Baichuan 2 series models, with both open source base and chat versions simultaneously.</p></li><li><p>In July 2023, at the opening ceremony of WAIC 2023 and the Scientific Frontier Plenary Meeting, the Shanghai Artificial Intelligence Laboratory teamed up with a number of institutions to release a newly upgraded "Scholar General Large Model System", including Scholar·Multimodal, Scholar·Puyu He Shusheng·Tianji and other three basic models, as well as the first full-chain open source system for the development and application of large models. Shanghai Artificial Intelligence Laboratory not only makes model weights open source, but also conducts all-round open source at the model, data, tools and evaluation levels to promote technological innovation and industrial progress. Subsequently, the Shanghai Artificial Intelligence Laboratory successively released the Scholar·Puyu 20B model and the Scholar·Lingbi multi-modal model.</p></li><li><p>In August 2023, Alibaba open sourced the Tongyi Qianwen 7B model, and subsequently open sourced the 1.8B, 14B, and 72B base and chat models, and provided the corresponding quantized versions of int4 and int8, which can be used in multi-modal scenarios. , Qianwen has also open sourced two visual and speech multi-modal models, qwen-vl and qwen-audio, achieving "full-size, full-modality" open source. Qwen-72B has improved the size and performance of open source large models. Since its release, it has remained at the top of the major charts, filling a gap in the country. Based on Qwen-72B, large and medium-sized enterprises can develop commercial applications, and universities and research institutes can carry out scientific research such as AI for Science.</p></li><li><p>In October 2023, Kunlun Wanwei released the "Tiangong" Skywork-13B series of tens of billions of large language models, and rare open sourced a large high-quality open source Chinese data set of 600GB and 150B Tokens Skypile/Chinese-Web-Text -150B dataset. High-quality data filtered from Chinese web pages by Kunlun's carefully filtered data processing process. The size is approximately 600GB, and the total number of tokens is approximately (150 billion). It is currently one of the largest open source Chinese data sets.</p></li><li><p>In November 2023, 01-AI company released the Yi series of models, with parameter sizes ranging from 6 billion to 34 billion, and the amount of training data reaching 30 billion tokens. These models outperform previous models on public leaderboards such as the Open LLM leaderboard and on some challenging benchmarks such as Skill-Mix.</p></li></ul><h2 id="introduction-to-llm-model-types">Introduction to LLM model types</h2><hr /><h4 id="base-model-and-chat-model">Base model and Chat model</h4><p>We usually see a model research and development institution open source the base model and chat model. So what is the difference between the base model and the chat model?</p><p>First, all large language models (LLMs) work by taking in some text and predicting the text that is most likely to follow it.</p><ul><li>The base model, also known as the basic model, is a model trained on massive amounts of different texts to predict subsequent texts. Subsequent text is not necessarily a response to instructions and dialogue.</li></ul><img src="/2024/01/19/2023%E5%B9%B4%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E7%BB%BC%E8%BF%B0/image-20240619191246661.png" class="" alt="image-20240619191246661"><ul><li>The chat model, also known as the dialogue model, is based on the base and continues to do fine-tuning and reinforcement learning through conversation records (instructions-responses). When it accepts instructions and talks with the user, it continues to write assistants that follow the instructions and are expected by humans. response content</li></ul><img src="/2024/01/19/2023%E5%B9%B4%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E7%BB%BC%E8%BF%B0/image-20240619191401263.png" class="" alt="image-20240619191401263"><h4 id="multimodal-model">multimodal model</h4><p>Multimodal LLM combines information from text and other modalities, such as images, videos, audios, and other sensory data. Multimodal LLM is trained on multiple types of data, helping the transformer find the differences between different modalities. relationship, and complete some tasks that the new LLM cannot complete, such as picture description, music interpretation, video understanding, etc.</p><img src="/2024/01/19/2023%E5%B9%B4%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E7%BB%BC%E8%BF%B0/image-20240619191640496.png" class="" alt="image-20240619191640496"><h4 id="agent-model">Agent model</h4><p>LLM has the capabilities of an agent brain and collaborates with several key components, including,</p><p>Planning: dismantling sub-goals, correcting errors, reflecting and improving.</p><p>Memory: short-term memory (context, long window), long-term memory (implemented through search or vector engine)</p><p>Tool use: The model learns to call external APIs to obtain additional capabilities.</p><img src="/2024/01/19/2023%E5%B9%B4%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E7%BB%BC%E8%BF%B0/image-20240619191724150.png" class="" alt="image-20240619191724150"><h4 id="code-model">Code model</h4><p>The Code model adds more code data to the model's pre-training and SFT, and performs a series of tasks in the code, such as code completion, code error correction, and zero-sample completion of programming task instructions. At the same time, according to different code languages, there will also be more professional language code models such as python and java.</p><h2 id="summary-and-future-directions">Summary and future directions</h2><hr /><p><strong>Theory and principles:：</strong>In order to understand the basic working mechanism of LLM, one of the biggest mysteries is how information is distributed, organized and utilized through very large deep neural networks. It is important to reveal the underlying principles or elements that build the basis of LLMs' capabilities. In particular, scaling appears to play an important role in improving the capabilities of LLMs. Existing research has shown that when the parameter size of a language model increases to a critical point (such as 10B), some emerging capabilities will appear in an unexpected way (sudden leap in performance), typically including context learning, instruction following and Step-by-step reasoning. These “emergent” abilities are fascinating but also puzzling: when and how do LLMs acquire them? Some recent research has either conducted broad-scale experiments investigating the effects of emerging abilities and the enablers of those abilities, or used existing theoretical frameworks to explain specific abilities. An insightful technical post targeting the GPT family of models also deals specifically with this topic, however more formal theories and principles to understand, describe and explain the capabilities or behavior of LLMs are still lacking. Since emergent capabilities have close similarities to phase transitions in nature, interdisciplinary theories or principles (such as whether LLMs can be considered some kind of complex systems) may be helpful in explaining and understanding the behavior of LLMs. These fundamental questions deserve exploration by the research community and are important for developing the next generation of LLMs.</p><p><strong>Model architecture：</strong>Transformers, consisting of stacked multi-head self-attention layers, have become a common architecture for building LLMs due to their scalability and effectiveness. Various strategies have been proposed to improve the performance of this architecture, such as neural network configuration and scalable parallel training (see discussion in Section 4.2.2). In order to further improve the capacity of the model (such as multi-turn dialogue capability), existing LLMs usually maintain a long context length. For example, GPT-4-32k has an extremely large context length of 32768 tokens. Therefore, a practical consideration is to reduce the time complexity (primitive quadratic cost) incurred by standard self-attention mechanisms.</p><p>Furthermore, it will be important to study the impact of more efficient Transformer variants on building LLMs, such as sparse attention has been used for GPT-3. Catastrophic forgetting has also been a challenge for neural networks, which has also negatively impacted LLMs. When LLMs are tuned with new data, the previously learned knowledge is likely to be destroyed. For example, fine-tuning LLMs for some specific tasks will affect their general capabilities. A similar situation occurs when LLMs are aligned with human values, which is called an alignment tax. Therefore, it is necessary to consider extending the existing architecture with more flexible mechanisms or modules to effectively support data updates and task specialization.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article reviews the current status of large model research in 2023. It summarizes the various stages of large model development this year and the contributions of major research institutions to large model research. It also summarizes and summarizes the current mainstream types of large models. On this basis, some thoughts and prospects about the future development of large-model technology were made.&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Paper Reading: Cramming- Training a Language Model on a Single GPU in One Day</title>
    <link href="http://yoursite.com/2023/07/24/Paper%20Reading:%20Cramming-%20Training%20a%20Language%20Model%20on%20a%20Single%20GPU%20in%20One%20Day/"/>
    <id>http://yoursite.com/2023/07/24/Paper%20Reading:%20Cramming-%20Training%20a%20Language%20Model%20on%20a%20Single%20GPU%20in%20One%20Day/</id>
    <published>2023-07-24T06:05:15.839Z</published>
    <updated>2023-07-24T06:16:28.872Z</updated>
    
    <content type="html"><![CDATA[<p>IBM's NLP research expert Leshem Choshen commented on Twitter, "This paper summarizes all the big model training trips you can think of.</p><a id="more"></a><p>###Limited resources</p><p>In order to simulate the resource environment of ordinary practitioners and researchers, this study first constructed a resource constrained research environment:</p><ul><li><p>A transformer based language model of any size, trained entirely from scratch using masked language modeling;</p></li><li><p>The pipeline cannot contain existing pre trained models;</p></li><li><p>Any raw text (excluding downstream data) can be included in the training, which means that acceleration can be achieved by wisely selecting how and when to sample the data, provided that the sampling mechanism does not require pre training the model;</p></li><li><p>The download and pre-processing of original data are not included in the total budget. The pre-processing here includes CPU based tokenizer construction, tokenization and filtering, but does not include Feature learning;</p></li><li><p>Training is only conducted on a single GPU for 24 hours;</p></li><li><p>Downstream performance is evaluated on GLUE, and downstream fine-tuning on GLUE is limited to simple training using only training data from downstream tasks (5 epochs or less), and requires the use of global hyperparameters set for all GLUE tasks. Downstream fine-tuning is not included in the total budget.</p></li></ul><p>###Improvement methods</p><p>The researchers implemented and tested some modification directions proposed by existing work, including general implementation and initial data settings, and attempted to modify the architecture, train, and modify the dataset methods.</p><p>The experiment was conducted in PyTorch, without using idiosyncratic implementations to be as fair as possible. All content was kept at the implementation level of the PyTorch framework, and only automatic operator fusion that could be applied to all components was allowed. In addition, the efficient attention kernel would only be re enabled after selecting the final architectural variant.</p><p>The first method we think of to improve performance is definitely modifying the model architecture. Intuitively, smaller/lower capacity models seem to be optimal in a one card per day training session. However, after studying the relationship between model type and training efficiency, researchers found that the scaling law poses a huge obstacle to scaling down. The training efficiency of each token largely depends on the model size, rather than the type of transformer.</p><p>In addition, smaller models have lower learning efficiency, which largely slows down the increase in throughput. Fortunately, the fact that training efficiency remains almost constant in models of the same size means that we can find suitable designs in architectures with similar parameter quantities, mainly based on the calculation time that affects individual gradient steps.</p><p>###summary</p><p>Overall, using the method in the paper, the training results are already very close to the original BERT, but it should be noted that the total FLOPS used by the latter is 45-136 times that of the new method (which takes four days on 16 TPUs). When the training time was extended by 16 times (trained on 8 GPUs for two days), the performance of the new method actually improved significantly compared to the original BERT, reaching the level of RoBERTA.</p><p>In this work, people discussed how much performance a transformer based language model can achieve in environments with very limited computational complexity. Fortunately, several modification directions can enable us to achieve good downstream performance on GLUE. Researchers expressed the hope that this work can provide a baseline for further improvement and provide theoretical support for many improvements and techniques proposed for Transformer architecture in recent years.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;IBM&#39;s NLP research expert Leshem Choshen commented on Twitter, &quot;This paper summarizes all the big model training trips you can think of.&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>6 Artificial Intelligence Tools for Chat</title>
    <link href="http://yoursite.com/2023/07/24/6%20Artificial%20Intelligence%20Tools%20for%20Chat/"/>
    <id>http://yoursite.com/2023/07/24/6%20Artificial%20Intelligence%20Tools%20for%20Chat/</id>
    <published>2023-07-24T04:55:36.142Z</published>
    <updated>2023-07-24T05:28:11.659Z</updated>
    
    <content type="html"><![CDATA[<p>This article will introduce 6 practical and efficient <strong>free</strong> AI chat tools.</p><ol type="1"><li><p>ChatGPT: The Chatbot program developed by OpenAI in the United States, released on November 30, 2022. ChatGPT is a Natural language processing tool driven by artificial intelligence technology. It can communicate by understanding and learning human language, and interact according to the context of chat, so as to chat and communicate like human beings. Conversational artificial intelligence is trained based on a large amount of text from 2021 and before, and its use is free, but accelerating response and usage during peak demand periods requires a monthly payment of $20.</p><a id="more"></a></li><li><p>The new Bing: Microsoft's powerful cloud infrastructure requires ChatGPT based conversations and searches in Bing to access this website. It is currently under testing and needs to be added to the waiting list if you want to use The new Bing earlier.</p></li><li><p>Perplexity.ai: The world's first session search engine. Perplexity AI combines ChatGPT with Bing Search, which is a stunning four seater platform with both ChatGPT style Q&amp;A and the ability to provide links like regular search engines. It can be used for free without any restrictions.</p></li><li><p>YouChat: YouChat can provide annotated answers for various types of queries, and create article abstracts from the internet, generate code, write papers, type code, and chat with you. Ask it questions and follow up on answers. It has ChatGPT like functions and can participate in and experience ChatGPT style conversations. It is also free, but you need to register and log in before using it.</p></li><li><p>NeevaAI: Small search engine, first launched in the United States in December 2022, founded by Sridhar Ramaswamy (former Senior Vice President of Advertising at Google) and Vivek Raghunathan (former Vice President of Monetization at YouTube). It creates an AI driven and completely user created ad free search engine. We can obtain corresponding answers directly generated by AI with references and annotations. Similarly, it is completely free and requires login.</p></li><li><p>Poe: a conversational AI Chatbot from Quora, which can be accessed by users at will. Users can ask questions to it, and Poe can get answers from a variety of AI Chatbot, including the parent company OpenAI behind ChatGPT and robots from other companies such as Anthropic. Free, but currently only available for iPhone use.</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article will introduce 6 practical and efficient &lt;strong&gt;free&lt;/strong&gt; AI chat tools.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;ChatGPT: The Chatbot program developed by OpenAI in the United States, released on November 30, 2022. ChatGPT is a Natural language processing tool driven by artificial intelligence technology. It can communicate by understanding and learning human language, and interact according to the context of chat, so as to chat and communicate like human beings. Conversational artificial intelligence is trained based on a large amount of text from 2021 and before, and its use is free, but accelerating response and usage during peak demand periods requires a monthly payment of $20.&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Rasa NLU SKLearn Classifier解析</title>
    <link href="http://yoursite.com/2022/10/21/Rasa%20NLU%20SKLearn%20Classifier%E8%A7%A3%E6%9E%90/"/>
    <id>http://yoursite.com/2022/10/21/Rasa%20NLU%20SKLearn%20Classifier%E8%A7%A3%E6%9E%90/</id>
    <published>2022-10-21T05:05:18.440Z</published>
    <updated>2022-10-21T05:14:12.238Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对著名对话机器人开源框架Rasa NLU Sklearn classifier架构的解析。Rasa是一套开源机器学习框架，用于构建基于上下文的AI小助手和聊天机器人。Rasa有两个主要模块：Rasa NLU 用于对用户消息内容的语义理解；Rasa Core 用于对话管理（Dialogue management）。本文主要针对Rasa NLU Sklearn classifier做细节上的说明。</p><p>本文更多关注算法，主要内容如下：</p><a id="more"></a><ul><li>Sklearn classifier架构</li><li>模型支持说明</li><li>配置样例</li><li>核心代码解析</li></ul><h3 id="sklearn-classifier架构">Sklearn classifier架构</h3><p>313</p><h3 id="模型支持说明">模型支持说明</h3><p>Rasa 对 Sklearn中的所有分类器都支持，包括并不限于以下：</p><table><thead><tr class="header"><th>模型名称</th><th>是否支持</th></tr></thead><tbody><tr class="odd"><td>LogisticRegression</td><td>支持</td></tr><tr class="even"><td>RandomForestClassifier</td><td>支持</td></tr><tr class="odd"><td>DecisionTreeClassifier</td><td>支持</td></tr><tr class="even"><td>MultinomialNB</td><td>支持</td></tr><tr class="odd"><td>GradientBoostingClassifier</td><td>支持</td></tr></tbody></table><p>SVM原理简介：</p><p>SVM是找到不同类别之间的分界面，使得两类样本尽量落在面的两边，而且离分界面尽量远。SVM是平面的，局限很大， 这时就利用到核函数。</p><p>核函数在解决线性不可分问题的时候，采取的方式是：使用低维特征空间上的计算来避免在高维特征空间中向量内积的恐怖计算量；也就是说此时SVM模型可以应用在高维特征空间中数据可线性分割的优点，同时又避免了引入这个高维特征空间恐怖的内积计算量。</p><p>本质： 核函数是一个低纬的计算结果，并没有采用低纬到高维的映射。只不过核函数低纬运算的结果等价于映射到高维时向量点积的值。</p><p>1、多项式核函数</p><p>对传入的样本数据点添加多项式项；新的样本数据点进行点乘，返回点乘结果；</p><p>多项式特征的基本原理：依靠升维使得原本线性不可分的数据线性可分；</p><p>2、高斯核函数</p><p>思想：按一定规律统一改变样本的特征数据得到新的样本，新的样本按新的特征数据能更好的分类，由于新的样本的特征数据与原始样本的特征数据呈一定规律的对应关系，因此根据新的样本的分布及分类情况，得出原始样本的分类情况。</p><p>高斯核本质是在衡量样本和样本之间的“相似度”，在一个刻画“相似度”的空间中，让同类样本更好的聚在一起，进而线性可分。</p><p><strong>限制：</strong>(1) SVM算法对大规模训练样本难以实施*</p><p>​ <em>(2) 用SVM解决多分类问题存在困难</em></p><h3 id="配置样例">配置样例</h3><p>1315</p><p>1397</p><h3 id="核心代码解析">核心代码解析</h3><ul><li><p>LabelEncoder()函数： 标签编码，类别标签数值化</p></li><li><p>transform_labels_str2num() 函数： 标签到数值</p></li><li><p>transform_labels_() 函数： 输入数值，输出标签文本</p></li><li><p>GridSearchCV() 函数：网格搜索参数，通过循环遍历，尝试每一种参数组合，返回最好的得分值的参数组合。</p></li><li><p>SVC() 函数： 创建模型训练器</p></li><li><p>process()函数： 模型推理</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是对著名对话机器人开源框架Rasa NLU Sklearn classifier架构的解析。Rasa是一套开源机器学习框架，用于构建基于上下文的AI小助手和聊天机器人。Rasa有两个主要模块：Rasa NLU 用于对用户消息内容的语义理解；Rasa Core 用于对话管理（Dialogue management）。本文主要针对Rasa NLU Sklearn classifier做细节上的说明。&lt;/p&gt;
&lt;p&gt;本文更多关注算法，主要内容如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Rasa NLU DIET Classifier解析</title>
    <link href="http://yoursite.com/2022/10/21/Rasa%20NLU%20DIET%20Classifier%E8%A7%A3%E6%9E%90/"/>
    <id>http://yoursite.com/2022/10/21/Rasa%20NLU%20DIET%20Classifier%E8%A7%A3%E6%9E%90/</id>
    <published>2022-10-21T03:42:07.492Z</published>
    <updated>2022-10-21T03:50:01.522Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对著名对话机器人开源框架Rasa NLU classifier中最受欢迎的DIET Classifier的解析。Rasa是一套开源机器学习框架，用于构建基于上下文的AI小助手和聊天机器人。Rasa有两个主要模块：Rasa NLU 用于对用户消息内容的语义理解；Rasa Core 用于对话管理（Dialogue management）。本文主要针对Rasa NLU classifier 中的DIET Classifier做详细的说明。</p><p>本文更多关注算法，主要内容如下：</p><a id="more"></a><ul><li>Rasa NLU Classifier架构</li><li>主流技术支持情况</li></ul><h3 id="diet-classifier架构">DIET Classifier架构</h3><h4 id="section">321</h4><h3 id="模型支持说明">模型支持说明</h3><p>DIET支持的Huggingface模型类型如下表：</p><table><thead><tr class="header"><th><strong>模型类型</strong></th><th><strong>模型名称</strong></th><th><strong>默认加载的预训练模型</strong></th></tr></thead><tbody><tr class="odd"><td>BERT</td><td>bert</td><td>rasa/LaBSE ( bert-base-uncased )</td></tr><tr class="even"><td>GPT</td><td>gpt</td><td>openai-gpt</td></tr><tr class="odd"><td>GPT2</td><td>gpt2</td><td>gpt2</td></tr><tr class="even"><td>XLNet</td><td>xlnet</td><td>xlnet-base-cased</td></tr><tr class="odd"><td>DistilBERT</td><td>distilbert</td><td>distilbert-base-uncased</td></tr><tr class="even"><td>RoBERTa</td><td>roberta</td><td>roberta-base</td></tr></tbody></table><p>对在HuggingFace 中上传的所有预训练模型（<a href="https://huggingface.co/models?pipeline_tag=text-classification&amp;sort=downloads" target="_blank" rel="noopener">Huggingface模型列表</a>），Rasa DIET可以支持满足以下条件的所有模型：</p><p>点击<a href="https://huggingface.co/models?pipeline_tag=text-classification&amp;sort=downloads" target="_blank" rel="noopener">Huggingface模型列表</a>-&gt;选中一个模型-&gt;点击进入模型页面-&gt;点击Files and version</p><ul><li>检查 config.json 中的 model_type 是否列在上表的 <strong>模型名称</strong> 列中</li><li>检查文件 tf_model.h5 是否存在</li><li>模型使用默认tokenizer, config.json 中不包含支持自定义的 tokenizer_class</li></ul><p>对满足上述条件的模型，通过2.1.3.3中描述的方式可开箱即用。</p><h3 id="diet支持huggingface的配置样例">DIET支持Huggingface的配置样例</h3><p>在Rasa2.0中，若想在DIET架构中使用Huggingface提供的预训练模型，除在rasa的config文件中指定使用DIETClassifier外，还需要配合使用对应的模块：</p><ol type="1"><li>HFTransformersNLP</li></ol><p>主要参数：model_name: 预训练模型config.json 中的 model_type的值</p><p>​ model_weights: <a href="https://huggingface.co/models?pipeline_tag=text-classification&amp;sort=downloads" target="_blank" rel="noopener">Huggingface模型列表</a>提供的预训练模型名称</p><ol type="1"><li>LanguageModelTokenizer：确保训练数据token对应的token_id与预训练模型的token_id保持一致</li><li>LanguageModelFeaturizer：生成经预训练模型转换后的特征向量，做为架构后续模块的输入。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">language: en</span><br><span class="line">pipeline:</span><br><span class="line">- name: HFTransformersNLP</span><br><span class="line">  model_weights: &quot;rasa&#x2F;LaBSE&quot;</span><br><span class="line">  model_name: &quot;bert&quot;</span><br><span class="line">- name: LanguageModelTokenizer</span><br><span class="line">- name: LanguageModelFeaturizer</span><br><span class="line">- name: DIETClassifier</span><br><span class="line">  epochs: 20</span><br><span class="line">  num_transformer_layers: 2</span><br><span class="line">  transfomer_size: 256</span><br><span class="line">  use_masked_language_model: True</span><br><span class="line">  drop_rate: 0.25</span><br><span class="line">  weight_sparsity: 0.7</span><br><span class="line">  batch_size: [64, 256]</span><br><span class="line">  embedding_dimension: 100</span><br><span class="line">  hidden_layer_sizes:</span><br><span class="line">    text: [512, 128]</span><br></pre></td></tr></table></figure><ul><li>DIET样例代码包位置：examples/hf_demo</li><li>DIET样例代码调用方式：项目根目录/main.py</li><li>涉及的源码改动：</li></ul><p>如按 ‘样例代码调用方式’ 直接跑报错... set from_pt=true, 请修改: 项目根目录/rasa/nlu/utils/hugging_face/hf_transformers.py: class HFTransformersNLP中的def _load_model_instance中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.model &#x3D; model_class_dict[self.model_name].from_pretrained(self.model_weights, cache_dir&#x3D;self.cache_dir)</span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.model &#x3D; model_class_dict[self.model_name].from_pretrained(self.model_weights, cache_dir&#x3D;self.cache_dir, from_pt&#x3D;True)</span><br></pre></td></tr></table></figure><h3 id="diet核心代码解析">DIET核心代码解析</h3><p><strong>rasa.nlu.model.Trainer.train：</strong>遍历pipeline所有components，对每个component调用component.train方法完成训练。在component遍历到DIETClassifier之前，HFTransformersNLP等组件已经提取好了DIETClassifier训练需要的特征。遍历至DIETClassifier后，DIETClassifier开始利用已经提取好的特征进入训练。</p><p><strong>rasa.nlu.classifiers.DIETClassifier.train:</strong> 该方法主要完成三件事：</p><ul><li><p>语料准备：通过DIETClassifier类中的方法preprocess_train_data，将训练数据和之前提取的特征整理成符合RasaModelData格式的model_data。RasaModelData格式为。。。。。之后将整理好的model_data按batch_size整理成data_generator供batch训练用。</p></li><li><p>指定模型：将DIETClassifier类的成员self.model通过初始化DIET类完成指定DIET模型训练。</p></li><li><ul><li><p>DIET模型类继承自TransformerRasaModel类：自定义了</p></li><li><p>TransformerRasaModel继承自RasaModel：自定义了。。。 要求实现。。。</p></li><li><p>RasaModel继承自TmpKerasModel：通过重写tf.keras.Model中的train_step(), test_step(), predict_step(), save()和load()方法，实现自定义的Rasa模型.</p></li><li><ul><li>train_step()使用自定义的batch_loss并对该loss做了正则化。batch_loss需由其子类实现。</li><li>predict_step()使用自定义的batch_predict()。需由其子类实现。</li><li>save()只使用tf.keras.Model.save_weights()。</li><li>load()生成模型结构后加载weights.</li></ul></li><li><p>TmpKerasModel继承自tf.keras.models.Model：重写了tf.keras.models.Model的fit方法来使用自定义的数据适配器。将数据转写成CustomDataHandler后由其处理迭代 epoch 级别的 <code>tf.data.Iterator</code> 对象。</p></li></ul></li><li><p>训练</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是对著名对话机器人开源框架Rasa NLU classifier中最受欢迎的DIET Classifier的解析。Rasa是一套开源机器学习框架，用于构建基于上下文的AI小助手和聊天机器人。Rasa有两个主要模块：Rasa NLU 用于对用户消息内容的语义理解；Rasa Core 用于对话管理（Dialogue management）。本文主要针对Rasa NLU classifier 中的DIET Classifier做详细的说明。&lt;/p&gt;
&lt;p&gt;本文更多关注算法，主要内容如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Rasa NLU架构解析</title>
    <link href="http://yoursite.com/2022/10/21/Rasa%20NLU%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90/"/>
    <id>http://yoursite.com/2022/10/21/Rasa%20NLU%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90/</id>
    <published>2022-10-21T03:20:31.880Z</published>
    <updated>2022-10-21T03:37:43.328Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对著名对话机器人开源框架Rasa NLU架构的解析。Rasa是一套开源机器学习框架，用于构建基于上下文的AI小助手和聊天机器人。Rasa有两个主要模块：Rasa NLU 用于对用户消息内容的语义理解；Rasa Core 用于对话管理（Dialogue management）。本文主要针对Rasa NLU各部分做细节上的说明。</p><p>本文更多关注算法，主要内容如下：</p><a id="more"></a><ul><li>Rasa NLU总体架构图</li><li>Rasa NLU训练流程解析</li><li>Rasa NLU推理流程解析</li></ul><h1 id="rasa-nlu-总体架构图">Rasa NLU 总体架构图</h1><p>274</p><p><strong>注：（1）FallbackClassifier应出现在某一个意图分类器之后，利用其输出的结果，即intent、confidence、intent ranking，如果意图的置信度比预设的threshold低，或排名前两位的意图的置信度的差距小于预设的ambiguity_threshold，则将该输入的意图分类为“nlu_fallback”</strong></p><h1 id="rasa-nlu训练流程解析"><strong>Rasa NLU训练流程解析</strong></h1><p>571</p><p><strong>rasa.model_training.train_async</strong>: 读取config, domain和训练data到file_importer: TrainingDataImporter, 并输入到_train_async_internal训练Rasa model (nlu and core).</p><p><strong>rasa.model_training._train_async_internal:</strong> 判定模型需要重新训练的部分并将判定结果写入fingerprint_comparison作为_do_training方法的参数fingerprint_comparison_result的值输入_do_training完成相应部分的训练, 训练结束后将模型打包成trained_model，通过trained_model输入TrainingResult返回回至上层。</p><p><strong>rasa.model_training._do_training:</strong> 通过fingerprint_comparison_result带入的结果判断是否重新训练nlu, core和nlg, 并进入相应模块进行训练。</p><p><strong>rasa.model_training._train_nlu_with_validated_data：</strong>按rasa.nlu.train.train各参数要求读取和整理参数值，输入rasa.nlu.train.train开始nlu模块的训练。</p><p><strong>rasa.nlu.train.train:</strong> 通过初始化trainer=rasa.nlu.model.Trainer(...), 构建config.yml中pipeline下的所有组件。读取TrainingDataImporter中的nlu数据后，将数据输入trainer.train开始训练。</p><p><strong>rasa.nlu.model.Trainer.train:</strong> 遍历pipeline所有components，对每个component调用component.train方法完成训练。</p><h1 id="rasa-nlu推理流程解析">Rasa NLU推理流程解析</h1><p>1552</p><p><strong>rasa.model_testing.test_nlu：</strong>nlu测试入口，使用get_model函数加载model并解压（unpack），创建结果输出目录，调用测试过程</p><p><strong>rasa.nlu.test.run_evaluation：</strong>测试过程入口函数，加载nlu模型初始化Interpreter实例，加载测试数据，调用get_eval_data进行测试</p><p><strong>rasa.nlu.test.get_eval_data：</strong>在测试数据上运行模型，并提取真实标签和预测结果，输入interpreter实例和测试数据，返回意图测试结果（包括意图的标签和预测结果，原始消息，即message，及预测结果的置信度），response测试结果（包括response的目标值和预测结果），还有实体测试结果（实体的目标值，预测结果，和对应的token）</p><p><strong>rasa.nlu.model.Interpreter.parse：</strong>一个interpreter对应一个训好的pipeline，其parse方法依次调用pipeline中的每一个component的process方法，来对输入文本一次进行解析和分类等操作，并返回处理结果（包括意图和实体）</p><p>每个component都有一个process入口方法，用于测试和实际预测，在process方法中再调用各component的内部方法（包含真正的处理逻辑），上图虚线框中即展示了一个基本的pipeline预测示例。</p><p>pipeline中Rasa自带的classifiers和extractors各组件（component）的具体介绍后续文章中介绍。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是对著名对话机器人开源框架Rasa NLU架构的解析。Rasa是一套开源机器学习框架，用于构建基于上下文的AI小助手和聊天机器人。Rasa有两个主要模块：Rasa NLU 用于对用户消息内容的语义理解；Rasa Core 用于对话管理（Dialogue management）。本文主要针对Rasa NLU各部分做细节上的说明。&lt;/p&gt;
&lt;p&gt;本文更多关注算法，主要内容如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Rasa NLU classifier解析</title>
    <link href="http://yoursite.com/2020/10/21/Rasa%20NLU%20classifier%E8%A7%A3%E6%9E%90/"/>
    <id>http://yoursite.com/2020/10/21/Rasa%20NLU%20classifier%E8%A7%A3%E6%9E%90/</id>
    <published>2020-10-21T06:55:26.000Z</published>
    <updated>2022-10-21T05:33:38.476Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对著名对话机器人开源框架Rasa NLU classifier架构的解析。Rasa是一套开源机器学习框架，用于构建基于上下文的AI小助手和聊天机器人。Rasa有两个主要模块：Rasa NLU 用于对用户消息内容的语义理解；Rasa Core 用于对话管理（Dialogue management）。本文主要针对Rasa NLU classifier 做总体上的说明。</p><p>本文更多关注算法，主要内容如下：</p><a id="more"></a><ul><li>Rasa NLU Classifier架构</li><li>主流技术支持情况</li></ul><h3 id="rasa-nlu-classifier架构">Rasa NLU Classifier架构</h3><p>285</p><h3 id="主流技术支持情况">主流技术支持情况</h3><table><colgroup><col style="width: 20%" /><col style="width: 10%" /><col style="width: 15%" /><col style="width: 53%" /></colgroup><thead><tr class="header"><th><strong>主流技术</strong></th><th><strong>是否支持</strong></th><th><strong>支持模块</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr class="odd"><td>Huggingface Transformer</td><td>部分</td><td>DIETClassifier</td><td>见2.1.3.2</td></tr><tr class="even"><td>Wide&amp;Deep</td><td>是</td><td>DIETClassifier</td><td>稀疏和稠密特征融合</td></tr><tr class="odd"><td>transformer</td><td>是</td><td>DIETClassifier</td><td>transformer层数可配置</td></tr><tr class="even"><td>DNN</td><td>是</td><td>DIETClassifier</td><td>DNN层数固定不可配置</td></tr><tr class="odd"><td>SVM</td><td>是</td><td>SKLearnClassifier</td><td>支持网络搜索优化配置</td></tr><tr class="even"><td>其他传统机器学习模型</td><td>是</td><td>SKLearnClassifier</td><td>SKLearn支持的所有模型</td></tr><tr class="odd"><td>Mitie Linear SVM</td><td>是</td><td>MitieClassifier</td><td>使用自有的稀疏线性核</td></tr><tr class="even"><td>字符串匹配</td><td>是</td><td>KeywordClassifier</td><td>不是关键词而是样例句完全匹配</td></tr><tr class="odd"><td>CNN</td><td>否</td><td>无</td><td>DIET只支持在预训练模型后添加transformer层，现有rasa无法搭建诸如textCNN, bert+bilsm+crf这类经典模型</td></tr><tr class="even"><td>单双向RNN ( LSTM, GRU )</td><td>否</td><td>无</td><td></td></tr><tr class="odd"><td>GCN</td><td>否</td><td>无</td><td>图卷积神经网络</td></tr></tbody></table><p>问题：pipeline中可以叠加使用多个classifier吗（除fallback）？如果被KeywordClassifier模块命中，可不可以直接跳过其他 classifier）</p><p>回答：单个pipeline中classifier可以叠加，例如KeywordIntentClassifier可以添加在主classifier后，这样Keyword的结果将覆盖classifier结果。<a href="https://forum.rasa.com/t/keyword-based-intent-classification/22027/7" target="_blank" rel="noopener">参考资料</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是对著名对话机器人开源框架Rasa NLU classifier架构的解析。Rasa是一套开源机器学习框架，用于构建基于上下文的AI小助手和聊天机器人。Rasa有两个主要模块：Rasa NLU 用于对用户消息内容的语义理解；Rasa Core 用于对话管理（Dialogue management）。本文主要针对Rasa NLU classifier 做总体上的说明。&lt;/p&gt;
&lt;p&gt;本文更多关注算法，主要内容如下：&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Rasa" scheme="http://yoursite.com/tags/Rasa/"/>
    
      <category term="Machine leanring" scheme="http://yoursite.com/tags/Machine-leanring/"/>
    
      <category term="[object Object]" scheme="http://yoursite.com/tags/object-Object/"/>
    
  </entry>
  
  <entry>
    <title>Bidirectional LSTM-CRF Models for Sequence Tagging</title>
    <link href="http://yoursite.com/2020/07/15/Bidirectional%20LSTM-CRF%20Models%20for%20Sequence%20Tagging/"/>
    <id>http://yoursite.com/2020/07/15/Bidirectional%20LSTM-CRF%20Models%20for%20Sequence%20Tagging/</id>
    <published>2020-07-14T16:02:19.000Z</published>
    <updated>2020-07-20T07:30:49.082Z</updated>
    
    <content type="html"><![CDATA[<p>本文是对论文<a href="https://arxiv.org/abs/1508.01991" target="_blank" rel="noopener">Bidirectional LSTM-CRF Models for Sequence Tagging</a>的总结。文章系统地比较了基于LSTM网络的各种序列标记模型的性能。 并在当时首次将BI-LSTM-CRF模型应用于NLP基准序列标记任务。 其中，BI-LSTM-CRF模型在词性标注，分块和命名实体识别任务上表现最优。模型具有鲁棒性且对单词嵌入的依赖性较小，甚至可以无需借助词嵌入达到一定的精度。</p><a id="more"></a><p>本文的主要内容包括：</p><ul><li>基于LSTM的序列标模型</li><li>模型训练</li><li>数据和特征</li><li>结论</li></ul><h3 id="基于lstm的序列标模型">基于LSTM的序列标模型</h3><hr /><p>RNN模型：对每一个时刻 <span class="math display">\[\begin{split} { h ( t ) = f ( U x ( t ) + W h ( t - 1 ) ) }\quad\quad\quad(1)\\{ y ( t ) = g ( V h ( t ) ) }\quad\quad\quad\quad\quad\quad\quad\quad\quad(2) \\f ( z ) = \frac { 1 } { 1 + e ^ { - z } }\quad\quad\quad\quad\quad\quad\quad\quad\quad(3)\\g ( z _ { m } ) = \frac { e ^ { z _ { m } } } { \sum _ { k } e ^ { z _ { k } } }\quad\quad\quad\quad\quad\quad\quad\quad\quad(4)\end{split} \\\]</span></p><p>LSTM模型：对每一个时刻 <span class="math display">\[\begin{split}{ i _ { t } = \sigma ( W _ { x i } x _ { t } + W _ { h i } h _ { t - 1 } + W _ { c i } c _ { t - 1 } + b _ { i } ) }\quad\quad\quad(5)\\{ f _ { t } = \sigma ( W _ { x f } x _ { t } + W _ { h f } h _ { t - 1 } + W _ { c f } c _ { t - 1 } + b _ { f } ) }\quad\quad(6)\\{ c _ { t } = f _ { t } c _ { t - 1 } + i _ { t } \tanh ( W _ { x c } x _ { t } + W _ { h c } h _ { t - 1 } + b _ { c } ) }\quad(7)\\{o _ { t } = \sigma ( W _ { x o } x _ { t } + W _ { h o } h _ { t - 1 } + W _ { c o } c _ { t } + b _ { o } ) } \quad\quad\quad(8) \\h _ { t } = o _ { t } \tanh ( c _ { t } )\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad(9)\end{split} \\\]</span></p><h4 id="lstm-networks">LSTM Networks</h4><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/p4b63XAxeBU0dFwQicUt3HwUsITeHuXVtzX1ZS5rLZ..Hrtcfk0V84DB9eKfT3OOI7QpR9rSLQvhNjnuJkwJtQ!!/b&amp;bo=OgTCAgAAAAADB9w!&amp;rf=viewer_4" style="zoom:50%;" /></p><h4 id="bidirectional-lstm-networks">Bidirectional LSTM Networks</h4><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/p4b63XAxeBU0dFwQicUt3K6yjEyF3D1Rq.kUnElZmBPsDTlWY78KZTgCtLHw7lWx5W8QJrGijQlmamMOHGx5VQ!!/b&amp;bo=fATKAgAAAAADB5I!&amp;rf=viewer_4" style="zoom:50%;" /></p><p>####CRF networks</p><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/.iXrRpyf8uMJ6D8uriNaY*b4M.jf8mtmeO1a4mBliFpVsNjtp2z.xlEzdgQniKlU3H2kzsdpGISNwD*Mb93XvZJZisBGlTSxpEZGsjesQ70!/b&amp;bo=CgSGAgAAAAADF7g!&amp;rf=viewer_4" style="zoom:50%;" /></p><h4 id="lstm-crf-network">LSTM-CRF network</h4><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/.iXrRpyf8uMJ6D8uriNaYwtafhcQrEiYVk4KojfCDocds.cW2nwy2hoHG1ffQnSF7i3K*Xh0OGQ8*DNG3S6J0bIAMbf7CBpf9*9rtQ0JHzs!/b&amp;bo=ZgTEAgAAAAADF5Y!&amp;rf=viewer_4" style="zoom:50%;" /></p><h4 id="bi-lstm-crf-networks">BI-LSTM-CRF networks</h4><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/.iXrRpyf8uMJ6D8uriNaY735vNnTzKc89nnFFq7myydvShikC*8ilxfyLFRkW8gjuBd*xnFFciMXn8Vg82aVss8V6d29RuEyoKgz5RVxoFQ!/b&amp;bo=WATQAgAAAAADF7w!&amp;rf=viewer_4" style="zoom:50%;" /></p><h3 id="模型训练">模型训练</h3><hr /><p>模型训练过程如下：</p><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/p4b63XAxeBU0dFwQicUt3HqR4GLXCSB8cXTogTTEzdMYIzA.*ahxBCmqHjVvf0GdUTM337RxB06rZRKVjzI.tw!!/b&amp;bo=lAT8AgAAAAADB0w!&amp;rf=viewer_4" style="zoom:50%;" /></p><p>其中，batch_size = 100.</p><h3 id="数据和特征">数据和特征</h3><hr /><h4 id="数据">数据</h4><p>文章通过三个任务来比较模型，三个任务对应的数据为：</p><ul><li>POS tagging：Penn TreeBank (PTB)</li><li>chunking：CoNLL 2000</li><li>named entity tagging：CoNLL 2003</li></ul><p>具体如下：</p><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/.iXrRpyf8uMJ6D8uriNaY2AqS4uWtKlg9XQn2VKzqbOCzvvElTySw9eaHkbpc4uk3AK2SwXiXrsAHb8o6KBxSGCAliqbPSlr6CrncFRtLCk!/b&amp;bo=wAeqAgAAAAADF10!&amp;rf=viewer_4" style="zoom:50%;" /></p><p>####特征</p><p>文章中使用的特征主要有三类：</p><ul><li>Spelling features</li><li>Context features</li><li>Word embedding</li></ul><p>其中，拼写特征和上下文特征是直接加在输出层的，如下图：</p><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/p4b63XAxeBU0dFwQicUt3LFWXhKSDP9co7Jb7PPUAVil9g0yQjwXKtNShO1.g4*qMZ0wgLMPz1B8lmuNL1HLgA!!/b&amp;bo=tgTUAgAAAAADB0Y!&amp;rf=viewer_4" style="zoom:50%;" /></p><h3 id="实验对比结果">实验对比结果</h3><hr /><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/.iXrRpyf8uMJ6D8uriNaY*fUauSN0L7NpfoyMVmUMoN3z5XEnYLXYeK0GLtKS0D6ieUVduzw2wId8GAgGnecdegjozAc5YAUptf4b0aPCao!/b&amp;bo=rgjKAwAAAAADF10!&amp;rf=viewer_4" style="zoom:38%;" /></p><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/.iXrRpyf8uMJ6D8uriNaY9dt8feZUghcG3Z7LrSRluq5*J2S9JRq3yxrMJ9OUTlbuJxmb95RPibQXyba9ylqYfgPTbJWI9F*b46sI0VCZ6g!/b&amp;bo=Lgj.AQAAAAADF.s!&amp;rf=viewer_4" style="zoom:38%;" /></p><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/.iXrRpyf8uMJ6D8uriNaY5JLTWbbIqCCH8*URg2T4ijGUEGUo3rEdQWRnHblS9ffhl34sbGtyPfDjwAnx2CDfvrs2geYx6esGbbofJGseZc!/b&amp;bo=FwU4BAAAAAADJyw!&amp;rf=viewer_4" style="zoom:60%;" /></p><p><img src="http://m.qpic.cn/psc?/V13FFsWG1SefP8/.iXrRpyf8uMJ6D8uriNaY1p2S.PY3NG6.7nig5peCNYGbkE4LNLhsJAuLO1VO*t2tW0.wa12K.e1tq20gBLqhGVJVE*VMZTRHBcgZ.HFxVc!/b&amp;bo=xgauAgAAAAADF14!&amp;rf=viewer_4" style="zoom:40%;" /></p><h3 id="结论">结论</h3><hr /><p>文章的主要贡献：</p><ul><li>系统对比了基于LSTM的各种模型在序列标注任务中的表现</li><li>首次应用双向LSTM+CRF模型在NLP序列标注语料集上</li><li>实验证明双向LSTM+CRF在序列标注任务上较其他模型表现最优</li></ul><h3 id="参考文献">参考文献</h3><hr /><p><a href="https://arxiv.org/abs/1508.01991" target="_blank" rel="noopener">Bidirectional LSTM-CRF Models for Sequence Tagging</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是对论文&lt;a href=&quot;https://arxiv.org/abs/1508.01991&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bidirectional LSTM-CRF Models for Sequence Tagging&lt;/a&gt;的总结。文章系统地比较了基于LSTM网络的各种序列标记模型的性能。 并在当时首次将BI-LSTM-CRF模型应用于NLP基准序列标记任务。 其中，BI-LSTM-CRF模型在词性标注，分块和命名实体识别任务上表现最优。模型具有鲁棒性且对单词嵌入的依赖性较小，甚至可以无需借助词嵌入达到一定的精度。&lt;/p&gt;
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
      <category term="CRF" scheme="http://yoursite.com/tags/CRF/"/>
    
      <category term="sequence tagging" scheme="http://yoursite.com/tags/sequence-tagging/"/>
    
  </entry>
  
</feed>
