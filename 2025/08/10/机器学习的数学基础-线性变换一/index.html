<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="在大多数线性代数课程中，矩阵是课程的核心。而在机器学习中，我们则始终与矩阵打交道。问题是：矩阵并不能说明一切。仅仅看矩阵很难理解其中的规律。例如，为什么矩阵乘法的定义如此复杂？为什么像\(𝐵 &#x3D; 𝑇^{−1}𝐴𝑇\)这样的关系很重要？为什么有些矩阵可逆，而有些则不可逆？ 为了真正理解其中的奥秘，我们必须探究矩阵的起源：线性变换。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习的数学基础-线性变换(一)">
<meta property="og:url" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/index.html">
<meta property="og:site_name" content="Adline125&#39;s Blog">
<meta property="og:description" content="在大多数线性代数课程中，矩阵是课程的核心。而在机器学习中，我们则始终与矩阵打交道。问题是：矩阵并不能说明一切。仅仅看矩阵很难理解其中的规律。例如，为什么矩阵乘法的定义如此复杂？为什么像\(𝐵 &#x3D; 𝑇^{−1}𝐴𝑇\)这样的关系很重要？为什么有些矩阵可逆，而有些则不可逆？ 为了真正理解其中的奥秘，我们必须探究矩阵的起源：线性变换。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page118formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page118formula2.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page118formula3.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page118formula4.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page119figure4.1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page119formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page119figure4.2.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page120formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page120formula2.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page120formula3.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page120formula4.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page121formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page121formula2(4.3).png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page121formula3.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p121formula4.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p122formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p122formula2.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p123formula1(4.4).png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p123formula2.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p123formula3.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p123formula4.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p124formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p124formula2.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p124formula3.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p124formula4.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p125formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p125formula2.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p126formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p126formula2.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p126formula3.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p126formula4.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p127formula1.png">
<meta property="og:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/p127formula2.png">
<meta property="article:published_time" content="2025-08-10T06:54:36.000Z">
<meta property="article:modified_time" content="2025-11-26T07:32:25.914Z">
<meta property="article:author" content="Adline125">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/page118formula1.png">

<link rel="canonical" href="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>机器学习的数学基础-线性变换(一) | Adline125's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Adline125's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Adline125's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">NLP Engineer, Google Developers Expert</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/icon.png">
      <meta itemprop="name" content="Adline125">
      <meta itemprop="description" content="北京程序媛一枚，主攻NLP.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Adline125's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习的数学基础-线性变换(一)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-10 14:54:36" itemprop="dateCreated datePublished" datetime="2025-08-10T14:54:36+08:00">2025-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-11-26 15:32:25" itemprop="dateModified" datetime="2025-11-26T15:32:25+08:00">2025-11-26</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>在大多数线性代数课程中，矩阵是课程的核心。而在机器学习中，我们则始终与矩阵打交道。问题是：矩阵并不能说明一切。仅仅看矩阵很难理解其中的规律。例如，为什么矩阵乘法的定义如此复杂？为什么像<span class="math inline">\(𝐵 = 𝑇^{−1}𝐴𝑇\)</span>这样的关系很重要？为什么有些矩阵可逆，而有些则不可逆？</p>
<p>为了真正理解其中的奥秘，我们必须探究矩阵的起源：线性变换。</p>
<a id="more"></a>
<p>本文的主要内容包括：</p>
<ul>
<li><strong>什么是线性变换？</strong></li>
<li><strong>线性变换和矩阵</strong></li>
<li><strong>矩阵运算回顾</strong></li>
<li><strong>逆线性变换</strong></li>
<li><strong>核与像</strong></li>
</ul>
<p>“我的眼睛为什么会痛？” “你以前从来没用过。” ——莫菲斯第一次从“母体”醒来时对尼奥说</p>
<p>我们必须探究矩阵的起源：线性变换。就像尼奥一样，理解其中的奥秘可能会有点痛苦，但它会在以后给我们带来巨大的回报。让我们开始吧！</p>
<h2 id="什么是线性变换">1 什么是线性变换？</h2>
<p>随着内积、正交性和正交/标准正交基的引入，我们对特征空间的结构有了全面的了解。然而，在机器学习中，我们的兴趣主要在于数据的变换。</p>
<p>从这个角度来看，神经网络只是一个由更小的部分（称为层）组成的函数，每一步都将数据变换到一个新的特征空间。线性变换是机器学习模型的关键组成部分之一。</p>
<p>你可能见过形式为𝑓 (𝐱) = 𝐴𝐱的函数，但这只是看待它们的其中一种方式。本节将从几何角度开始，然后转向你可能已经熟悉的代数表示。为了理解神经网络如何学习强大的高级数据表示，了解变换的几何学至关重要。</p>
<p>那么，什么是线性变换？让我们不要犹豫，立即进入定义！</p>
<blockquote>
<p>定义 4.1.1（线性变换）</p>
<p>设 𝑈 和 𝑉 是两个向量空间（在同一个标量场上），𝑓 ∶ 𝑈 → 𝑉 是它们之间的函数。如果满足以下条件，则称 𝑓 是线性的</p>
<p><img src="./机器学习的数学基础-线性变换一/page118formula1.png" style="zoom:50%;" /></p>
<p>对所有向量 𝐱、𝐲 ∈ 𝑈 和所有标量 𝑎、𝑏成立。</p>
</blockquote>
<p>这就是线性代数被称为线性代数的原因。本质上，线性变换是两个向量空间之间的映射，它保留了代数结构：加法和标量乘法。（向量空间之间的函数通常被称为变换，因此我们将使用这个术语。）</p>
<blockquote>
<p>备注 4.1.1 线性本质上是将两个性质合二为一：对于所有向量 𝐱、𝐲 和所有标量 𝑎，𝑓 (𝐱 + 𝐲) = 𝑓 (𝐱) + 𝑓 (𝐲) 和 𝑓 (𝑎𝐱) = 𝑎𝑓 (𝐱)。由此可知 (4.1)可进一步写成</p>
<p><img src="./机器学习的数学基础-线性变换一/page118formula2.png" style="zoom:50%;" /></p>
</blockquote>
<p>从定义中可以立即看出两个性质。首先，由于</p>
<p><img src="./机器学习的数学基础-线性变换一/page118formula3.png" style="zoom:50%;" /></p>
<p>𝑓 (𝟎) = 𝟎 对每个线性变换都成立。此外，线性变换的复合仍然是线性的，正如</p>
<p><img src="./机器学习的数学基础-线性变换一/page118formula4.png" style="zoom:50%;" /></p>
<p>显示了任何线性 𝑓 和 𝑔 以及标量 𝑎 和 𝑏。</p>
<p>像往常一样，让我们看一些例子来建立直觉。</p>
<p><strong>例 1.</strong> 对于任何标量 𝑐，缩放变换 𝑓 (𝐱) = 𝑐𝐱 是线性的</p>
<p>这可能是最简单的例子，它可以在所有向量空间中定义。</p>
<p><img src="./机器学习的数学基础-线性变换一/page119figure4.1.png" style="zoom:50%;" /></p>
<p>​ 图 4.1：缩放作为线性变换</p>
<p>很容易看出缩放是线性的：</p>
<p><img src="./机器学习的数学基础-线性变换一/page119formula1.png" style="zoom:50%;" /></p>
<p><strong>例 2.</strong> 在<span class="math inline">\(ℝ^2\)</span>中，绕原点旋转𝛼角度也是线性的</p>
<p><img src="./机器学习的数学基础-线性变换一/page119figure4.2.png" style="zoom:50%;" /></p>
<p>​ 图 4.2：欧氏平面中的旋转作为线性变换</p>
<p>为了证明旋转确实是线性的，我们先直接看一个定义：平面向量<span class="math inline">\(𝐱 = (𝑥_1, 𝑥_2)\)</span> 的旋转角为 𝛼，其表达式为</p>
<p><img src="./机器学习的数学基础-线性变换一/page120formula1.png" style="zoom:50%;" /></p>
<p>由 (4.1) 式很容易得到证明。我知道这看起来有点突然，但相信我，旋转公式将会详细解释。你可以用一些基本的三角学知识来解释，或者等到我们稍后用矩阵来解释。</p>
<p>一般来说，线性变换与空间几何有着密切的联系。稍后，我们将详细研究<span class="math inline">\(ℝ^2\)</span>的线性变换，重点关注像这样的几何变换。（注意，旋转在高维空间中会稍微复杂一些，因为它们需要一个旋转轴。）</p>
<p><strong>例3：</strong>在任何向量空间𝑉和非零向量𝐯∈𝑉中，由𝑓 (𝐱) = 𝐱 + 𝐯定义的平移不是线性的，正如𝑓 (𝟎) = 𝐯 ≠ 𝟎。</p>
<p>我们将在本节后面看到更多示例。现在，我们来讨论线性变换的一些一般性质。对于任何线性变换 𝑓 ∶ 𝑈 → 𝑉，图像</p>
<p><img src="./机器学习的数学基础-线性变换一/page120formula2.png" style="zoom:50%;" /></p>
<p>始终是𝐕的子空间（参见第 1.2.7 节）。这很容易验证：如果 <span class="math inline">\(𝐯_1, 𝐯_2 ∈ im 𝑓\)</span>，则存在 <span class="math inline">\(𝐮_1, 𝐮_2 ∈ 𝑈\)</span>，使得 <span class="math inline">\(𝑓 (𝐮_1) = 𝐯1\)</span> 且 <span class="math inline">\(𝑓 (𝐮_2) = 𝐯_2\)</span>，如下式所示</p>
<p><img src="./机器学习的数学基础-线性变换一/page120formula3.png" style="zoom:50%;" /></p>
<p>为了增加一个抽象层次，我们将看到所有线性变换的集合形成一个向量空间。</p>
<blockquote>
<p>定理 4.1.1 设 𝑈 和 𝑉 是同一域 𝐹 上的两个向量空间。则所有线性变换的集合</p>
<p><img src="./机器学习的数学基础-线性变换一/page120formula4.png" style="zoom:50%;" /></p>
<p>也是 𝐹 上的向量空间，具有函数加法和标量乘法的通常定义。</p>
</blockquote>
<p>它的证明只是一个枯燥的清单，只是简单回顾了向量空间定义（定义 1.1.1）中的各项内容。我建议你至少过一遍，巩固一下对向量空间的理解，但其实没什么特别的。</p>
<h3 id="线性变换和矩阵">1.1 线性变换和矩阵</h3>
<p>正如我们所见，线性变换的定义有点抽象。然而，有一种简单而富有表现力的方法来刻画它们。</p>
<p>为了说明这一点，设 𝑓 ∶ 𝑈 → 𝑉 是两个向量空间 𝑈 和 𝑉 之间的线性变换。假设<span class="math inline">\(\{𝐮_1, … , 𝐮_𝑚\}\)</span> 是 𝑈 中的基，而 <span class="math inline">\(\{𝐯_1, … , 𝐯_𝑛\}\)</span> 是 𝑉 中的基。由于每个 𝐱 ∈ 𝑈 都可以写成如下形式</p>
<p><img src="./机器学习的数学基础-线性变换一/page121formula1.png" style="zoom:50%;" /></p>
<p>𝑓 的线性意味着</p>
<p><img src="./机器学习的数学基础-线性变换一/page121formula2(4.3).png" style="zoom:50%;" /></p>
<p>这意味着<span class="math inline">\(𝑓 (𝐱)\)</span> 是<span class="math inline">\(𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑚)\)</span> 的线性组合。换句话说，每个线性变换都完全由基向量的像决定。为了扩展这个想法，假设对于每个<span class="math inline">\(𝐮_𝑗\)</span>，对于某些标量<span class="math inline">\(𝑎_{𝑖,𝑗}\)</span>，我们有</p>
<p><img src="./机器学习的数学基础-线性变换一/page121formula3.png" style="zoom:50%;" /></p>
<p>这些𝑛 × 𝑚 数完全描述了𝑓。为了符号简单，我们将它们存储在一个𝑛 × 𝑚 大小的表中，称为矩阵，我们将其表示为<span class="math inline">\(𝐴_𝑓\)</span>：</p>
<p><img src="./机器学习的数学基础-线性变换一/p121formula4.png" style="zoom:50%;" /></p>
<p>这意味着线性变换可以用矩阵来表示。这种联系在机器学习中被广泛应用。</p>
<p>进一步展开（4.3），对于每个<span class="math inline">\(𝐱 = ∑^𝑚_{𝑗=1} 𝑥_𝑗𝐮_𝑗\)</span>，我们有</p>
<p><img src="./机器学习的数学基础-线性变换一/p122formula1.png" style="zoom:50%;" /></p>
<p>因此，𝐱 的图像可以表示为<span class="math inline">\(𝐴_𝑓 𝐱\)</span>：</p>
<p><img src="./机器学习的数学基础-线性变换一/p122formula2.png" style="zoom:50%;" /></p>
<p>这里需要注意两点。首先，我们隐式地选择将向量表示为列而不是行。这是一个影响深远的决定，将影响本书后面的许多计算。我们会继续指出这一点。</p>
<p>其次，矩阵表示取决于基的选择！假设<span class="math inline">\(𝑃 = \{𝐩_1, … , 𝐩_𝑛\} ⊂ 𝑈\)</span> 是矩阵的基，我们将这种依赖关系表示为下标，写作<span class="math inline">\(𝐴_{𝑓,𝑃}\)</span>。</p>
<p>为了避免混淆，我们几乎只用标准正交基来定义线性变换。在实际场景中，这更容易理解正在发生的事情。所以，每当我写下“设𝐴是线性变换𝑓的矩阵”这样的话，就隐含地假设了𝐴的基函数形式为<span class="math inline">\(𝐞_1 = (1, 0, … , 0), 𝐞_2 = (0, 1, … , 0), … , 𝐞_𝑛 = (0, 0, … , 1)\)</span>。</p>
<p>从哲学角度来说，你听说过柏拉图的洞穴寓言吗？在这个思想实验中，人们被假设生活在一个洞穴中，始终面朝一面墙，只能观察身后火焰投射的影子。他们所观察到的并用来构建世界内部表征的东西，与现实截然不同。将这个类比应用到线性代数中，矩阵就是我们在实际场景中观察和使用的影子。在许多入门课程中，线性变换是隐藏的，只教授矩阵微积分。我第一次接触这个主题的经历也类似：我上的第一门线性代数课就只讲矩阵。这门课复杂得令人困惑，简直是数学课里最复杂的了。（我可以向你保证，这门课确实非常复杂和令人困惑。）后来，当我发现可以从线性变换的角度来看待矩阵时，一切都豁然开朗了。</p>
<p>不了解矩阵背后的原理，就不可能掌握线性代数。如果你觉得我的方法太抽象，请记住：多年以后，当你成为一名实践数据科学家/机器学习工程师/研究员或其他任何职位时，深入研究这些原理将会带来巨大的回报。</p>
<p>让我们回到正题，继续讨论线性变换。最常用的矩阵是恒等变换 id ∶ 𝐱 ↦ 𝐱 的矩阵。我们将其表示为 𝐼。很容易看出</p>
<p><img src="./机器学习的数学基础-线性变换一/p123formula1(4.4).png" style="zoom:50%;" /></p>
<p>总而言之，对于矩阵 𝐴，线性变换可以通过 𝐱 ↦ 𝐴𝐱 给出。实际上，映射</p>
<p><img src="./机器学习的数学基础-线性变换一/p123formula2.png" style="zoom:50%;" /></p>
<p>定义了由 (4.2) 定义的线性变换空间 𝐿(𝑈, 𝑉) 与 𝑛 × 𝑚 矩阵集之间的一一对应关系，其中 𝑛 和 𝑚 是对应的维度。</p>
<h3 id="矩阵运算回顾">1.2 矩阵运算回顾</h3>
<p>函数可以相加和复合。由于线性变换和矩阵之间的联系，矩阵运算继承自相应的函数运算。</p>
<p>基于这一原则，我们定义了矩阵加法，使得两个线性变换之和的矩阵等于对应矩阵之和。</p>
<p>从数学上讲，如果 𝑓 , 𝑔 ∶ 𝑈 → 𝑉 是两个带矩阵的线性变换，𝑓 ↔︎ 𝐴 和 𝑔 ↔︎ 𝐵，那么</p>
<p><img src="./机器学习的数学基础-线性变换一/p123formula3.png" style="zoom:50%;" /></p>
<p>因此，相应的矩阵可以按元素相加：</p>
<p><img src="./机器学习的数学基础-线性变换一/p123formula4.png" style="zoom:50%;" /></p>
<p>矩阵之间的乘法由相应变换的组合来定义。</p>
<p>为了弄明白如何操作，我们先研究一个特殊情况。（一般来说，先研究特殊情况是个好主意，因为它们通常可以降低复杂性，并让你在不造成信息过载的情况下发现规律。）因此，设 𝑓 , 𝑔 ∶ 𝑈 → 𝑈 为两个线性变换，将 𝑈 映射到自身上。为了确定与𝑓 ◦ 𝑔 对应的矩阵元素，我们必须用所有基向量 <span class="math inline">\(𝐮_1, … , 𝐮_𝑛\)</span> 来表示 <span class="math inline">\(𝑓 (𝑔(𝐮_𝑗))\)</span>。为此，我们有</p>
<p><img src="./机器学习的数学基础-线性变换一/p124formula1.png" style="zoom:50%;" /></p>
<p>考虑我们如何定义变换矩阵，标量$ (∑^𝑛_{𝑘=1} 𝑎_{𝑖,𝑘}𝑏_{𝑘,𝑗}) $是 𝑓 ◦ 𝑔 矩阵第 𝑖 行第 𝑗 列的元素。因此，矩阵乘法可以定义为</p>
<p><img src="./机器学习的数学基础-线性变换一/p124formula2.png" style="zoom:50%;" /></p>
<p>一般情况下，只有当相应的线性变换可以组合时，我们才能定义矩阵的乘积。也就是说，如果𝑓 ∶ 𝑈 → 𝑉，则𝑔 必须从𝑉开始。将其转化为矩阵的语言，𝐴 的列数必须与𝐵 的行数匹配。因此，对于任何<span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑚}\)</span> 和<span class="math inline">\(𝐵 ∈ ℝ^{𝑚×𝑙}\)</span>，它们的乘积定义为</p>
<p><img src="./机器学习的数学基础-线性变换一/p124formula3.png" style="zoom:50%;" /></p>
<h3 id="逆线性变换">1.3 逆线性变换</h3>
<p>对于线性变换，可逆性问题非常重要。例如，你遇到过这样的方程组吗？</p>
<p><img src="./机器学习的数学基础-线性变换一/p124formula4.png" style="zoom:50%;" /></p>
<p>如果我们定义</p>
<p><img src="./机器学习的数学基础-线性变换一/p125formula1.png" style="zoom:50%;" /></p>
<p>上述系统可以写成𝐴𝐱 = 𝐛的形式。这些被称为线性方程，用于建模从金融到生物学的各种过程。你会如何写出这样一个方程的解？如果存在一个矩阵<span class="math inline">\(𝐴^{-1}\)</span>，使得<span class="math inline">\(𝐴^{-1}𝐴\)</span>是单位矩阵𝐼（由(4.4)式定义），那么将方程𝐴𝐱 = 𝐛从左乘以<span class="math inline">\(𝐴^{-1}\)</span>，将得到<span class="math inline">\(𝐱 = 𝐴^{-1}𝐛\)</span>形式的解。</p>
<p>矩阵<span class="math inline">\(𝐴^{-1}\)</span>被称为𝐴的逆矩阵。它可能并不总是存在，但当它存在时，由于多种原因，它极其重要。我们稍后会讨论线性方程，但首先，让我们学习一下可逆性的基础知识！以下是一般定义。</p>
<blockquote>
<p>定义 4.1.2（线性变换的逆）</p>
<p>设 𝑓 ∶ 𝑈 → 𝑉 是向量空间 𝑈 和 𝑉 之间的线性变换。如果存在一个线性变换 <span class="math inline">\(𝑓^{-1}\)</span> 使得 <span class="math inline">\(𝑓^{-1}◦ 𝑓\)</span> 和 <span class="math inline">\(𝑓 ◦ 𝑓^{-1}\)</span> 为恒等函数，则称 𝑓 可逆；即</p>
<p><img src="./机器学习的数学基础-线性变换一/p125formula2.png" style="zoom:50%;" /></p>
<p>对所有𝐮∈𝑈、𝐯∈𝑉成立。 <span class="math inline">\(𝑓^{-1}\)</span>称为𝑓的逆。</p>
</blockquote>
<p>并非所有线性变换都是可逆的。例如，如果𝑓将所有向量映射到零向量，则无法定义逆变换。</p>
<p>逆变换的存在需要满足某些条件。其中最重要的一个条件是将基的概念与可逆性联系起来。</p>
<blockquote>
<p>定理 4.1.2（线性变换的可逆性）</p>
<p>设 𝑓 ∶ 𝑈 → 𝑉 为线性变换，<span class="math inline">\(𝐮_1, … , 𝐮_𝑛\)</span> 为 𝑈 中的基。则 𝑓 可逆当且仅当$𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) $为 𝑉 中的基。</p>
</blockquote>
<p>以下证明很简单，但可能有点让人一时无法接受。第一次阅读时可以跳过，以后可以随时重新阅读。</p>
<blockquote>
<p>证明。与往常一样，“当且仅当"这类定理的证明由两部分组成，因为这些命题涉及两个蕴涵式。</p>
<ol type="a">
<li>首先，我们证明𝑓可逆，则$𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) <span class="math inline">\(是一个基。也就是说，我们需要证明\)</span>𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛)$ 线性无关，且每个𝐲 ∈ 𝑉都可以写成它们的线性组合。由于𝑓可逆，𝑓 (𝟎) = 𝟎，而且不存在非零向量𝐱 ∈ 𝑈 使得𝑓 (𝐱) = 𝟎。换句话说，𝟎 不能写成 $𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) $的非平凡线性组合，由此定理 1.2.2推断出它们之间的线性独立性。</li>
</ol>
<p>另一方面，可逆性意味着每个 𝐲 ∈ 𝑉 都可以表示为 𝐲 = 𝑓 (𝐱)，其中 𝐱 ∈ 𝑈。（假设 <span class="math inline">\(𝐱 = 𝑓^{−1}(𝐲)\)</span>。）由于 $𝐮_1, … ，𝐮_𝑛 <span class="math inline">\(是一个基，\)</span>𝐱 = ∑^𝑛_{𝑖=1} 𝑥_𝑖𝐮_𝑖$。因此，</p>
<p><img src="./机器学习的数学基础-线性变换一/p126formula1.png" style="zoom:50%;" /></p>
<p>可以证明 <span class="math inline">\(span(𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛)) = 𝑉\)</span>。</p>
<p>$𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) $的线性独立性以及它张成 𝑉 的事实表明它确实是基。</p>
<ol start="2" type="a">
<li>现在我们证明另一个蕴涵式：如果 <span class="math inline">\(𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛)\)</span> 是基，则 𝑓 可逆。</li>
</ol>
<p>如果$ 𝑓 (𝐮_1), … , 𝑓 (𝐮_𝑛) $确实是基，则每个 𝐲 ∈ 𝑉 都可以写成</p>
<p><img src="./机器学习的数学基础-线性变换一/p126formula2.png" style="zoom:50%;" /></p>
<p>这证明了全射性。关于单射性，如果对于某个𝐚，𝐛∈𝑈，𝐲 = 𝑓 (𝐚) = 𝑓 (𝐛)，那么，由于𝐚 和 𝐛 都可以写成<span class="math inline">\(𝐮_𝑖\)</span>基向量的线性组合，因此我们有</p>
<p><img src="./机器学习的数学基础-线性变换一/p126formula3.png" style="zoom:50%;" /></p>
<p>和</p>
<p><img src="./机器学习的数学基础-线性变换一/p126formula4.png" style="zoom:50%;" /></p>
<p>因此，<span class="math inline">\(𝟎 = ∑^𝑛_{𝑖=1}(𝑎_𝑖 − 𝑏_𝑖)𝐮_𝑖\)</span>，且由于$𝐮_1, … , 𝐮_𝑛 <span class="math inline">\(是 U 中的一个基，\)</span>𝑎_𝑖 = 𝑏_𝑖$ 必定成立。因此𝑓 是单射。</p>
</blockquote>
<p>该定理的一个推论是，如果𝑈和𝑉的维数不同，则线性变换𝑓 ∶ 𝑈 → 𝑉不可逆。我们也可以从矩阵的角度来看待可逆性。对于任何<span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>，如果相应的线性变换可逆，则存在一个矩阵<span class="math inline">\(𝐴^{−1} ∈ ℝ^{𝑛×𝑛}\)</span>使得<span class="math inline">\(𝐴^{−1}𝐴 = 𝐴𝐴^{−1} = 𝐼\)</span>。如果一个矩阵不是方阵，那么它在经典意义上不可逆。</p>
<h3 id="核与像">1.4 核与像</h3>
<p>关于线性变换的可逆性，有两个特殊的集合起着至关重要的作用：核和像。让我们来看一下！</p>
<blockquote>
<p>定义 4.1.3（线性变换的核和像）</p>
<p>设 𝑓 ∶ 𝑈 → 𝑉 为线性变换。其像和核定义为</p>
<p><img src="./机器学习的数学基础-线性变换一/p127formula1.png" style="zoom:50%;" /></p>
<p>和</p>
<p><img src="./机器学习的数学基础-线性变换一/p127formula2.png" style="zoom:50%;" /></p>
</blockquote>
<p>通常，我们将某个矩阵 𝐴 写为 im 𝐴 和 ker𝐴，指的是由 𝐱 ↦ 𝐴𝐱 定义的线性变换。</p>
<p>由于 𝑓 的线性性，很容易看出 im 𝑓 是 𝑉 的子空间，而 ker 𝑓 是 𝑈 的子空间。如上所述，它们与可逆性密切相关，我们接下来会看到。</p>
<blockquote>
<p>定理 4.1.3（线性变换的可逆性）</p>
<p>设 𝑓 ∶ 𝑈 → 𝑉 为线性变换。</p>
<p>（a）𝐴 为单射当且仅当 ker 𝑓 = {𝟎}。</p>
<p>（b）𝐴 为全射当且仅当 im 𝑓 = 𝑉。</p>
<p>（c）𝐴 为双射（即可逆），当且仅当 ker 𝑓 = {𝟎} 且 im 𝑓 = 𝑉。</p>
</blockquote>
<blockquote>
<p>证明：(a) 如果 𝑓 是单射，则 𝑈 中只能有一个向量映射到 𝟎。由于对于任何线性变换，𝑓 (𝟎) = 𝟎，因此 ker 𝑓 = {𝟎}。另一方面，如果有两个不同的向量 𝐱，𝐲 ∈ 𝑈，使得 𝑓 (𝐱) = 𝑓 (𝐲)，则 𝑓 (𝐱 − 𝐲) =𝑓 (𝐱) − 𝑓 (𝐲) = 𝟎，因此 𝐱 − 𝐲 ∈ ker 𝑓。因此，ker 𝑓 = {𝟎} 蕴涵 𝐱 = 𝐲，从而给出单射性。 （b）这只是全射性的定义。</p>
<p>（c）这是由上面（a）和（b）的结合立即得出的。</p>
</blockquote>
<p>因为矩阵定义了线性变换，所以讨论矩阵的逆是有意义的。</p>
<p>从代数角度来说，<span class="math inline">\(𝐴 ∈ ℝ^{𝑛×𝑛}\)</span>的逆是矩阵<span class="math inline">\(𝐴^{−1} ∈ ℝ^{𝑛×𝑛}\)</span>，使得<span class="math inline">\(𝐴^{−1}𝐴 = 𝐴𝐴^{−1} = 𝐼\)</span>成立。线性变换和矩阵之间的联系意味着<span class="math inline">\(𝐴^{−1}\)</span> 是<span class="math inline">\(𝑓^{−1}\)</span>的矩阵，所以这并不奇怪。</p>
<p>如果本节关于可逆性的内容感觉涉及太多代数，不用担心。稍后，在讨论变换的行列式时，我们将在本章后面从几何角度研究可逆性。关于矩阵，稍后我们将在5.1.6节中看到计算逆矩阵的通用方法。我们很快就会讲到这一点，但首先，我们先来看看基的选择如何决定矩阵的表示。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/02/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E5%9B%9B/" rel="prev" title="机器学习和深度学习概述(四)">
      <i class="fa fa-chevron-left"></i> 机器学习和深度学习概述(四)
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/09/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2(%E4%BA%8C)/" rel="next" title="机器学习的数学基础-线性变换(二)">
      机器学习的数学基础-线性变换(二) <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>

  
  
  




          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是线性变换"><span class="nav-number">1.</span> <span class="nav-text">1 什么是线性变换？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线性变换和矩阵"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 线性变换和矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#矩阵运算回顾"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 矩阵运算回顾</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逆线性变换"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 逆线性变换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核与像"><span class="nav-number">1.4.</span> <span class="nav-text">1.4 核与像</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Adline125"
      src="/images/icon.png">
  <p class="site-author-name" itemprop="name">Adline125</p>
  <div class="site-description" itemprop="description">北京程序媛一枚，主攻NLP.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Adline125" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Adline125" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:gglfxsld@gmail.com" title="E-Mail → mailto:gglfxsld@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Adline125</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>
<br/>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次 | 本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  var disqus_config = function() {
    this.page.url = "http://yoursite.com/2025/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%80/";
    this.page.identifier = "2025/08/10/机器学习的数学基础-线性变换一/";
    this.page.title = "机器学习的数学基础-线性变换(一)";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://Adline125.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
